<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>D2 Blog</title>
  <link rel="alternate" href="https://d2.naver.com" />
  <id>https://d2.naver.com/blog.atom</id>
  <icon>https://d2.naver.com/favicon.ico</icon>
  <updated>2023-12-20T01:30:27Z</updated>
  <entry>
    <title>네이버에는 테크 월드를 꿈꾸는 사람들이 있다! - Tech Radio : 보안 편</title>
    <link rel="alternate" href="https://d2.naver.com/news/4029141" />
    <category term="news" />
    <id>https://d2.naver.com/news/4029141</id>
    <updated>2023-12-22T14:26:03Z</updated>
    <content type="html">&lt;p&gt;&lt;img src="/content/images/2023/12/-----------2023-12-15------6-19-58.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id="techradio"&gt;&lt;strong&gt;Tech Radio? 네이버 사내 기술 팟캐스트!&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Tech Forum, Tech Radio, Tech Talk, Tech meetup 그리고 NAVER ENGINEERING DAY까지 네이버에서는 사내 기술 커뮤니케이션과 기술 교류를 위한 다양한 프로그램이 진행되고 있습니다.&lt;/p&gt;

&lt;p&gt;올해 처음 NAVER ENGINEERING DAY 발표 세션을 D2 채널로 공개하며 많은 분들의 호응을 얻었는데요,
그에 이은 &lt;strong&gt;네이버 사내 기술 팟캐스트 Tech Radio를 소개&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;풍부한 영상 컨텐츠로 다채로운 기술 소식을 접하게 되었지만 가끔은 넘쳐나는 영상이 피곤하게 느껴질 때도 있는 것 같습니다. 그렇다고 필요한 기술 소식을 놓칠 수는 없는데요, 이런 고민 끝에 부담없이 들을 수 있는 사내 기술 팟캐스트 Tech Radio를 시작하였습니다.&lt;/p&gt;

&lt;p&gt;외부 공개가 가능한 선에서 각 주제별 담당자와 나눈 이야기들을 질의 응답 형식으로 전달할 예정이니
앞으로도 많은 관심 부탁드립니다. 라디오지만 화려한 조명이 비추는 테크라디오 '보안' 편 만나보시죠!&lt;/p&gt;

&lt;h2 id="techradio"&gt;&lt;strong&gt;Tech Radio - 보안 편&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id="q"&gt;&lt;strong&gt;Q : 안녕하세요! 패널 분들 소개 부탁드리겠습니다.&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/-----------2023-12-15------6-09-31.png" alt="" /&gt;
&lt;span class="caption"&gt;&amp;lt;네이버 시큐리티 팀 박영석, 박현준, 김태우 님 (좌측부터)&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;안녕하세요! 저희는 네이버 시큐리티에서 일하고 있는 박영석, 박현준, 김태우 입니다. 
네이버 서비스에 취약성을 검사하고, 서비스가 실제 릴리즈 되기 전 &lt;strong&gt;어떤 문제들이 있는지 검사하여 안전하게 서비스를 유지하는 것을 목표&lt;/strong&gt;로 하고 있습니다. 그 밖에는 소스 코드와 사용된 오픈 소스의 취약점을 검사하고, 어뷰징(정상적인 이용 플로우를 벗어나 이상행위를 하는 사용자들을 탐지하여 조치) 분석 업무도 담당하고 있습니다.&lt;/p&gt;

&lt;h3 id="q"&gt;&lt;strong&gt;Q : 보안 업무는 어떻게 시작하게 되셨나요?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;김태우 님&lt;/strong&gt; : 대학교 때 알바를 하다가 연구실에서 OTP 프로그램을 만들고 있더라고요.
그 프로그램에서 OTP로 문자를 받으면 그 문자에 대한 숫자를 입력하는 패드를 만드는 거였는데요, 보안 연구실에서 하는 과제였기 때문에 그때부터 보안에 관심을 갖게 되었고, 또 취업을 준비하면서 &lt;strong&gt;어떤 업종이 있을까 찾아보다 보안 업종이 항상 1등 아니면 2등&lt;/strong&gt;으로 뜨는 거예요. 그게 이제 한 10년 좀 넘은 일인데 제가 찾아보니까 아직까지 그렇게 되어 있더라고요. (웃음)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님 :&lt;/strong&gt; 저는 어렸을 때 컴퓨터 게임 데이터를 조작해서, 그 능력치를 높이는 시도를 많이 했었거든요. 지금처럼 인터넷이 많이 상용화되지 않은 시절이라 정보가 많이 없었어요. 그래서 어떻게하면 내가 가진 캐릭터의 능력치를 올릴 수 있을까 여러가지 조작도 해보고 무언가 바꾸는 거에 되게 흥미를 많이 느꼈었거든요.
치트 엔진이랑 PC 툴스 이런 것도 쓰고, 지금처럼 64비트가 아니었으니까 능력치를 ff로 고쳐서 삼국지 같은 경우 장수의 능력치가 255로 바뀐다든지 뭐 이런 식으로.. 지금 생각하면 정말 아무것도 아닌데 그런 하나하나에 되게 재미를 느꼈거든요.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 저는 그렇게 만들어준 걸 다운 받아서 제 거에 잘 이용했습니다. (웃음)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님(계속)&lt;/strong&gt; : 그런걸 하다 서점에서 ‘게임 해킹’ 이런 책들을 많이 사봤거든요.
이 분야가 정말 재미있겠다라고 생각하고 있었는데 어느 날 제가 게임 해킹 책을 보고 있는 걸 보시더니 아버지가 많이 혼내셨어요. &lt;strong&gt;해커라는 이미지가 그때는 어르신들한테는 나쁜 이미지가 있어서 반대로 지키는 걸 공부해라&lt;/strong&gt; 하셔서 그쪽 분야를 대학교 와서도 공부하고 하다 보니까 여기까지 오게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 일반인들 입장에서 나쁜 길로 빠지면 해커 좋은 길로 빠지면 보안 담당자 이렇게 되는군요.&lt;/p&gt;

&lt;h3 id="q"&gt;&lt;strong&gt;Q : 보안 업무의 가장 중요한 기초에 대해 설명해 주실 수 있나요?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : &lt;strong&gt;버그 바운티&lt;/strong&gt;부터 설명을 드리면 좋을 것 같은데요. 생소하실 수도 있는데 &lt;a href="https://bugbounty.naver.com/ko/"&gt;https://bugbounty.naver.com/ko/&lt;/a&gt; 사이트가 있습니다. 해커나 외부에 있는 보안 전문가들이 &lt;strong&gt;서비스에서 취약점을 찾게 되면 그 찾은 내용을 보고서로 작성해서 제보&lt;/strong&gt;를 하게 됩니다.
그럼 제보된 내용이 저희 팀으로 들어오게 되고요. 어느 정도 파급력을 가졌냐 정말 심각한 취약점이냐 이런 것들을 평가합니다.
특히, 대학생분들이 많이 참여를 해주시는 것 같아요. 최근에는 외국인도 네이버 서비스에 대해 취약점을 제보하는 경우도 꽤 있고요. 국내는 굉장히 많은 큰 사이트들이 있는데 이렇게 자체적으로 버그 바운티를 운영하는 회사는 잘 없습니다. 그 범위도 계속해서 확장하고 있고요. &lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/-----------2023-12-15------4-49-53.png" alt="" /&gt;
&lt;span class="caption"&gt;&amp;lt;네이버 버그 바운티 진행절차&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id="q"&gt;&lt;strong&gt;Q: 버그 바운티 최대 포상금은 얼마인가요?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : &lt;strong&gt;포상금은 최대 2만 달러까지 지급하고 있으며 취약점별 심각도에 따라 지급되는 최대 금액이 버그바운티 약관에 명시&lt;/strong&gt;되어 있습니다. 저희가 가장 많은 금액을 드리는 취약점은 어카운트 테이크 오버(Account takeover)라는 한마디로 다른 사용자의 계정을 훔칠 수 있는 취약점이라고 보시면 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 공식적인 우리의 취약점을 찾아줘 이런 거네요.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : 맞습니다. 또 내부에서 서비스의 취약점이 있는지를 계속해서 보고, 찾으려고 노력하고 있지만 저희가 놓치는 부분도 있을 수 있거든요. 그래서 그런 부분을 &lt;strong&gt;외부 해커들의 도움을 받아서 찾게 되는 것&lt;/strong&gt;이죠.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 네이버 직원들도 할 수 있나요?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : 직원분들은 사내 버그 리포트하는 채널이 따로 있습니다. 따로 리워드는 안 나갑니다(웃음). 참고로 제가 만약에 네이버로 퇴사하고 바로 네이버 서비스 제보한다고 해서 돈이 지급 안 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 아, 또 그런 약관이 다 있군요. (&lt;del&gt;네이버 직원들도 좀 주셔야..아 아닙니다.&lt;/del&gt;)&lt;/p&gt;

&lt;h3 id="qux"&gt;Q.  &lt;strong&gt;프론트엔드 백엔드 또는 UX 부분에서 처리할 수 있는 보안이 각각 다를 것 같은데 각 기술 영역 별 보안 사례를 좀 말씀해 주세요.&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : UX는 사용자 경험을 바꿔서 보안을 더 향상시킨다로 볼 수 있는데 저 분야는 유저블 시큐리티(Usable security)라는 영역이 따로 있긴 합니다. 네이버랑 똑같은 사이트를 만들고, 사용자를 유인한 다음 아이디 패스워드를 입력하게 되면 해커들이 그걸 악용하는 기법을 피싱(Phishing)이라고 부르는데요, &lt;strong&gt;&lt;a href="https://whale.naver.com/"&gt;네이버 브라우저 웨일&lt;/a&gt;에는 세이프 브라우징이라는 기술이 접목&lt;/strong&gt;돼 있습니다.&lt;/p&gt;

&lt;p&gt;세이프 브라우징을 쓰게 되면 네이버 피싱 사이트에 사용자가 잘못 접속을 하더라도 '위험하니까 들어가지 마세요' 이런 경고창을 띄워주거든요. 그 경고창의 색이 흰색이었어요. 글로벌 브라우저랑 비교했을 때는 메시지가 약하게 보여 빨간색으로 바꿨거든요.&lt;/p&gt;

&lt;p&gt;빨간색 경고창이 탁! 뜨면서 잘못된 사이트인 것을 한 번에 각인시켜줄 수 있는 식으로 변경을 했고, 그런 부분들이 UX 부분에서 좀 더 보안을 향상시킬 수 있는 하나의 예시가 아닐까 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/-----------2023-12-15------5-39-43.png" alt="" /&gt;
&lt;span class="caption"&gt;&amp;lt;네이버 브라우저 웨일의 UX 보안 향상 사례)&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;김태우 님&lt;/strong&gt; : UX 부분에서 한 사례가 게임 보안 업무를 맡았을 때인데 봇(bot)이 되게 많았어요. (NCP라고 말할 수도 있는) mmorpg 게임 같은 경우에는 사람들이 직접 모여 게임 내에서 몹(mob)을 잡거나 하는 경우가 있잖아요. 그때 사람이 하는 게 아니고 뉴스에서 보면 작업장 같은데서 여러 개의 컴퓨터를 돌려놓고 어떤 자원을 수집한다거나 그런 걸 하잖아요.&lt;/p&gt;

&lt;p&gt;게임의 흥미도를 높이기 위해서는 그런 봇들이 적어야 하고, 일반 유저들이 많아야 되는데 그래서 개발자 입장에서는 그런 봇과 일반 유저들을 구분할 수 있는 방안이 필요하거든요. &lt;strong&gt;사람만이 할 수 있는 것을 찾기 위해 OTP를 게임 중간중간에 넣은 거&lt;/strong&gt;예요. 거기서 게임을 하다가 몇 분 만에 다시 이제 '어떤 숫자를 입력하세요' 그런 창이 자꾸 뜨니까 게임의 흥미도가 점점 떨어질 수밖에 없지만.. 그것도 UX 부분에서 해야만 하는 부분이었던 것 같습니다.&lt;/p&gt;

&lt;h3 id="q"&gt;Q : &lt;strong&gt;영화에서 해커들을 보면 터미널 명령어를 차자작 쳐서 건물 보안을 쉽게 뚫는 모습이 나오는데, 실제로 이렇게 인증 인가를 뚫는 것도 가능할까요?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : 가능은 한데요. 영화처럼 딱딱 해가지고 바로 뚫는다 그건 불가능에 가깝고요. 뭔가를 뚫는다는 건 그만큼 시스템에 대한 오래된 분석과 어디가 취약한지 알고 있는 상황에서 그 취약점을 이용한 코드를 짜서 인증을 뚫는 거라 영화에서는 바로 들어가서 노트북 설치하자마자 터미널에서 따닥 치면 바로 엘리베이터 열리고 이러잖아요.&lt;/p&gt;

&lt;p&gt;그건 영화적인 요소이니까 그런 게 가능하지만, &lt;strong&gt;실제로 그 따다다 해서 열리기 전까지 한 2~3개월은 분석을&lt;/strong&gt; 해야 되지 않을까.. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 세 분도 이런 경험이 있으신가요? 뭔가 해킹을 직접적으로 해봤다거나?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : 전 회사에서 스마트 폰, 스마트 tv 들에 대해서 보안 취약점 같은 것들을 찾고 모의해킹하는 업무를 했었는데 그 당시에 스마트 tv 관련된 취약점 뉴스가 핫하게 나온 적이 있었어요.
그래서 카메라가 내장되어 있는 스마트 TV를 한 달 정도 모의해킹해서, &lt;strong&gt;TV 뒷면의 USB 포트에 악성코드가 담긴 USB를 꽂기만 하면 해당 기기를 완전히 장악할 수 있는 취약점&lt;/strong&gt;을 찾았었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt;: 오, 영화 같네요&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : 발견한 취약점을 이용하면 실제 판매되고 있는 스마트TV 제품을 해킹해서 카메라 촬영이 가능하다고 보고를 드렸습니다. TV가 가정집 뿐만 아니라 사무실 내에서도 회의용도로 사용되기때문에 해킹으로 인한 프라이버시 침해는 매우 심각한 문제가 될 수 있습니다. &lt;strong&gt;대응은 이제 저희가 어떻게 고쳐야 된다는 이제 제안을 이제 개발팀에다 드리는 거죠&lt;/strong&gt;. 취약점은 모두 패치되었지만 그 이후로는 카메라 달린 스마트TV가 출시된걸 본적이 없는것 같아요. (다함께 웃음)&lt;/p&gt;

&lt;h3 id="q"&gt;Q : &lt;strong&gt;일상생활에서의 업무 습관 같은 게 있으실지 ?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;박영석 님&lt;/strong&gt; : 제가 어뷰징 탐지를 하고 있어서인지, 특히 어디 놀러갈 때 네이버 지도에서 맛집 찾으면 리스트가 쭉 뜨잖아요. 열심히 잡고 있긴 하지만 그래도 남아 있는 작업된 리뷰들이 좀 있긴 하거든요. 그래서 리뷰를 곧이곧대로 믿지 못하고 하나씩 보면서 &lt;strong&gt;어뷰즈 패턴이 존재하는지 꼼꼼히 보게 되는 편&lt;/strong&gt;인 것 같아요.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 혹시 ‘내돈내산’을 판별할 수 있는 꿀팁이 있나요?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박영석 님&lt;/strong&gt; : 요즘에 그런 작업하는 사람들이 일반 사용자들처럼 잘 숨어서, 꿀팁이랄 건 없고 그냥 저는 제 느낌을 믿는 것 같습니다. 느낌을 믿는.. 이거 좀 작업한 것 같은데? 이런 느낌이면 안 가고 (웃음)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;김태우 님&lt;/strong&gt; : 저도 예전에 PC방에서 축구 게임을 했는데 시간을 들여서 한 게임이기 때문에 저한테 되게 좋은 선수 카드가 많았거든요. 어느 날 다시 들어가보니 제 카드 다 없어진 거예요. 이게 무슨 일인가 생각을 해봤는데 PC방이라는 데가 공공장소잖아요. 그래서 &lt;strong&gt;공공장소에서 패스워드를 입력해서 로그인을 했고, 키로거(key logger)라는 악성 프로그램이 있는데 제가 입력하는 모든 키워드를 다 로깅&lt;/strong&gt;을 하는 거예요. &lt;/p&gt;

&lt;p&gt;제가 패스워드를 입력할 때 그 키로거를 통해서 다른 악성 유저가 제 패스워드를 가져가지 않았나 이렇게 의심하고 있거든요. 그런 식으로 패스워드가 유출되기도 하는 경우가 많은데, &lt;strong&gt;은행권 로그인할 때는 가상 키보드를 많이 사용하듯 그런 걸 활용하는 편이고&lt;/strong&gt; 공공장소에서는 웬만하면 컴퓨터를 사용하지 않습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 아 안 해요? 사용을 아예?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;김태우 님&lt;/strong&gt; :  어떤 프로그램이 깔렸을지 모르기 때문에 사용을 하지 않고, 사용을 한다고 하더라도 저만의 꼼수인데 제 패스워드 길이가 10자리라고 하면 처음에 한 60~70 자리를 문자열 아무거나 막 다 입력한 뒤에 제 패스워드가 아닌 것들 하나씩 하나씩 백스페이스로 지우면서 패스워드를 맞춰가는 그런 식으로 키로거를 회피하는 방법을 사용을 하고 있고요. 
사실 굉장히 피곤합니다. 그래서 불편하다는 단점이 있지만, &lt;strong&gt;제 중요한 개인 정보를 지키기 위해서&lt;/strong&gt; 이런 꼼수를 사용하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 되게 신선한 방법이네요. 혹시나 부모님들이나 이렇게 IT에 취약하신 분들께 피싱을 예방하기 위한 좋은 팁이 있나요?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : 피싱을 예방하기 위한 좋은 팁, 사실 쉽지가 않아요. 피싱 사이트가 딱 보면 저희도 구분이 안 갑니다. 육안상으로는 똑같아요. 실제 로그인이 되는 사이트도 있습니다. 피싱 사이트인데 자기 아이디 패스워드 쳤을 때만 로그인이 되고 틀린 걸 치면 틀렸다고 이렇게 표시하는 정말 정교하게 만들어진 피싱 사이트 있거든요.
그래서 사실 육안상으로 구분하기는 굉장히 쉽지 않고요, &lt;strong&gt;사이트 주소 같은 걸 한 번씩 확인&lt;/strong&gt;하신다든지 네이버면 네이버 닷컴 맞는지 이런 것들 확인하시면 조금 도움이 되실 것 같아요.
&lt;strong&gt;가장 좋은 방법은 &lt;a href="https://blog.naver.com/nv_account/221703712779"&gt;네이버의 2단계 인증&lt;/a&gt;을 적용&lt;/strong&gt;하시면 해커가 아이디/패스워드를 탈취했더라도 제 휴대전화 인증없이는 로그인이 안되기 때문에 확실하게 피싱을 예방하실 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://blog.naver.com/nv_account/221703712779"&gt;&lt;img src="/content/images/2023/12/-----------2023-12-15------6-40-52.png" alt="" title="" /&gt;&lt;/a&gt;
&lt;span class="caption"&gt;&amp;lt;네이버 2단계 인증 설정 안내&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id="q"&gt;Q : &lt;strong&gt;보안 업무를 하면서 기억에 남는 에피소드가 있나요?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;박영석 님&lt;/strong&gt; : 예전에 담당했던 PC방 악성 코드 건이 하나 있거든요. &lt;strong&gt;특정 PC방 IP에서 어뷰징으로 보이는 검색어가 들어온다 이렇게 처음 제보&lt;/strong&gt;가 온 거예요. 지금 없어졌지만 예전에는 연관 검색어가 있었잖아요. 그 당시에는 연관 검색어라고 해서 분당 맛집 검색을 먼저 하고, 조금 있다가 뒤에 상호명을 붙여서 그런 식으로 작업을 하게 되면 나중에는 '분당 맛집'이라고 치면 연관 검색어에 상호명이 뜨거나 이런 걸 노리고 작업을 한 케이스가 많았어요.&lt;/p&gt;

&lt;p&gt;PC방에서 그게 들어오는데 IP랑 PC방 상호명만 있고, 저희한테 의뢰를 한 거죠. 그래서 저희 팀원 몇 명이서 2~3주 정도 PC방을 돌아다녔어요. &lt;br /&gt;
이 PC방에서 검색어가 들어온다 하면은 그 PC방에 가고, 그 PC방 안에 IP들이 다 다를 거잖아요. 그럼 그 아이피를 찾아야죠. 어느 IP에서 검색어가 들어왔다 하면 이제 그 IP를 찾는 거예요. 찾고 있으면 알바생 분이 지금 여기서 뭐 하는 거냐고 그래서 쫓겨난 적도 있고 그런 식으로 PC방을 돌아다니면서 찾은 기억이 있고요.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 그러면 그 악성 코드가 깔려 있는 PC에서는 계속 주기적으로 매크로처럼 검색을 하는 거예요?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박영석 님&lt;/strong&gt; : 보통 PC방에서 시스템을 종료하고 다시 부팅을 하면 새로운 이미지를 불러와서 부팅이 되고, 그동안 했던 게 다 날아가잖아요. 근데 그 새로운 이미지를 가져와서 부팅을 할 때 딱 발생하는 거예요. 검색이 사용자 모르게 그런 식으로 짜여 있어서 알바도 사장들도 전혀 모르고, 저희가 돌아다니면서 패킷을 잡아야 되잖아요.
컴퓨터를 껐다가 켠 다음에 &lt;strong&gt;USB에 그런 분석 프로그램 같은 거 담아가지고 몰래 끼워놓고 부팅을 해가지고 패킷 보고 프로세스 살펴보고 어떤 악성 코드가 있나 그런 식&lt;/strong&gt;으로 되게 고생을 해서 잡았던 기억이 있거든요. 결국에는 찾았구요. 보니까 PC방 내 게임 런처 프로그램 안에다가 개발자가 악성 코드를 심어놔서 그게 깔린 PC방에서는 부팅을 할 때 그것도 랜덤하게 서버에서 명령 받아가지고 랜덤하게 검색어를 발생시키는 이런 케이스였어요.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 이건 진짜 어렵겠네요. 되게 어렵지만 잡고 나서는 뿌듯하겠어요.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박영석 님&lt;/strong&gt; : 네, 찾기 되게 힘들었고, 그래서 기억에 남는 에피소드를 말하라고 하면 이게 제일 먼저 생각나는 것 같아요. 그걸 잡고 검찰에 가서 협조를 하고 하는데 그 피의자를 마주친 적이 있었거든요. 보니까 되게 좋은 차 타고 다니더라고요. 그거 보면서, 현타도 오고…&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MC&lt;/strong&gt; : 근데 진짜 유혹이 있진 않으세요? 정말로 보안을 지키기 위해서 열심히 노력을 하시는 건데 반대로 그렇게 해커가 되면 뭔가 돈을 많이 벌 수 있다는 유혹도 있을 것 같은데?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : 고민을 해본 적도 없지만 그게 &lt;strong&gt;거의 무조건 잡히거든요. 안 잡힐 수가 사실 없기 때문에 범죄&lt;/strong&gt;이고, 그래서 아예 그런 생각을 안 하게 되는 것 같아요.&lt;/p&gt;

&lt;h3 id="q"&gt;Q : &lt;strong&gt;끝으로 네이버 보안 업무에 관심있는 분들께&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;박영석 님&lt;/strong&gt; : 어뷰징 담당자로 말씀드리자면 네이버에는 다른 회사나 스타트업 이런 데서 볼 수 없는 방대한 양의 로그가 있거든요. 데이터 관련 논문 중엔 데이터의 양이 전부다라고 하는 논문들이 있어요.
구글같은 곳의 논문들을 보면 데이터를 엄청 많이 쌓아서 신뢰성을 높인 논문들도 있는데, &lt;strong&gt;다양한 서비스의 큰 로그들을 한꺼번에 볼 수 있다는 게 되게 큰 장점&lt;/strong&gt;이라고 생각해서 지금도 일을 재밌게 하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;박현준 님&lt;/strong&gt; : 보안 쪽에서 오펜시브랑  디펜시브라는 용어가 있는데요 저희 팀은 오펜시브 한 쪽이거든요. 어떤 분들을 보게 되냐면 취약점을 찾는 거에만 매몰되시는 분들이 있어요.
저희가 사실 달성해야 될 목표는 문제를 해결하는 거거든요. &lt;strong&gt;보안 문제를 해결하고 대안을 제시&lt;/strong&gt;하는 거여야 되는데 자칫 잘못하면 내 개인적으로 '내가 취약점을 몇 개 찾았어', '나 이거 대단한 취약점을 찾았어' 여기에 매몰될 수도 있어요.
그 부분을 항상 경계해야 되고, &lt;strong&gt;서비스를 이해하고 그 서비스에 대한 취약점이 나왔을 때 현실적으로 문제를 해결할 수 있는 대안을 제시할 수 있는 분&lt;/strong&gt;이라면 훌륭할 것 같다는 생각이 들어요.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;김태우 님&lt;/strong&gt; : 올해 초 DEVIEW CAMPUS를 통해 학생분들의 질문을 받게 되었는데 그때 되게 재미있었던 질문 중에 하나가 보안은 고인물들이 많다던데 어떤가요? 그런 질문이 있었어요.
저도 어떻게 보면 고인물인데 이제 좀 있으면 이제 10년이 다 돼가거든요. 고인 상태에서 이제 썩은 물이 되지 않도록 항상 노력을 해야 된다는 생각을 가지고 있습니다.
저 뿐만 아니라 &lt;strong&gt;팀에 계신 분들 맡으신 업무에 대해 책임감과 전문성을 갖고 계시는 좋은 고인물들이 모여있는 곳이라 오시면 많은 부분을 배울 수 있을 것&lt;/strong&gt; 같습니다.&lt;/p&gt;

&lt;h3 id=""&gt;&lt;strong&gt;네이버 보안 팀 업무 살펴보기&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://naver-career.gitbook.io/kr/service/security/service-security"&gt;&lt;strong&gt;Service Security&lt;/strong&gt;&lt;/a&gt; &lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://naver-career.gitbook.io/kr/service/security/security-development"&gt;&lt;strong&gt;Security Development&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;CUT!&lt;/strong&gt;
&lt;img src="/content/images/2023/12/-----------2023-12-13------4-37-58-1.png" alt="" /&gt;
&lt;span class="caption"&gt;&amp;lt;네이버 사내 기술 팟캐스트 Tech Radio '보안 편' 녹음 현장&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt; &lt;br /&gt;
&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>HDFS 쓰기 파이프라인을 활용한 HBase의 WAL 쓰기 최적화</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/6445508" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/6445508</id>
    <updated>2023-12-19T13:08:01Z</updated>
    <content type="html">&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/e2XaBwu6uIc?si=huJDkYKArvUUNxRZ" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;  

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;네이버 검색에서는 검색 서비스 제공에 필요한 대규모 데이터를 HBase 기반의 데이터 저장소인 &lt;a href="https://deview.kr/2017/schedule/188"&gt;Cuve&lt;/a&gt;에 저장하고 있습니다. HBase는 Java 기반의 오픈 소스 NoSQL 분산 데이터베이스입니다. HDFS와 함께 사용되며 내구성(durability)과 지속성(persistence)을 보장합니다. 지연 시간이 매우 짧고 거의 실시간에 가까운 랜덤 읽기와 랜덤 쓰기를 지원합니다.&lt;/p&gt;

&lt;p&gt;HBase 쓰기 경로는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/05-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;그림 1 HBase 쓰기 경로(원본 출처: &lt;a href="https://blog.cloudera.com/apache-hbase-write-path/"&gt;Apache HBase Write Path&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;HBase는 쓰기 요청을 처리할 때 HDFS에 데이터를 바로 쓰지 않고 RegionServer의 MemStore라고 불리는 메모리 영역에 데이터를 먼저 저장합니다. MemStore에 저장된 데이터는 Flush 과정을 통해서 주기적으로 HDFS에 저장됩니다. HDFS에 데이터를 저장하기 전에 서버에 장애가 발생한다면 메모리 영역인 MemStore에 저장된 데이터는 유실될 수 있습니다. HBase는 데이터 유실을 방지하기 위해 WAL(Write-Ahead Log)에 모든 변경 사항을 기록합니다.&lt;/p&gt;

&lt;p&gt;WAL은 MySQL의 BIN 로그와 비슷하게 모든 변경 사항을 로그에 기록하여 데이터 내구성을 보장하는 방법입니다. 변경 사항은 일반적으로 영구적인 데이터 저장 장치(예: HDD, SSD 등)에 저장하는데 HBase는 HDFS에 저장합니다. 서버에 장애가 발생하여 메모리의 모든 데이터가 유실되어도 WAL을 이용해 복구할 수 있습니다.&lt;/p&gt;

&lt;p&gt;HBase 버전 1에서는 HDFS가 제공하는 &lt;code&gt;DFSOutputStream&lt;/code&gt;을 통해서 WAL 데이터를 HDFS에 저장했습니다. 하지만 HDFS 쓰기 파이프라인을 따라 데이터가 3개의 DataNode에 쓰이다 보니 지연 시간이 증가하는 문제와 WAL 데이터를 쓰는 과정에서 오류가 발생했을 때 파이프라인 복구 실패로 인해 사용자 요청 처리가 지연되는 문제가 있었습니다. Cuve에서도 HBase 버전 1 클러스터에서 WAL 데이터 쓰기 파이프라인 복구 실패로 사용자의 요청을 처리하지 못하여 SLA를 위반하는 장애가 발생했었습니다. HBase 버전 2에서는 HBase에 WAL 쓰기 전용 Fan-out DFSOutputStream이 구현되어 이러한 문제가 해결되었습니다.&lt;/p&gt;

&lt;p&gt;이 글에서는 Cuve에서 HBase 버전 1 기반으로 운영하던 HBase 클러스터에서 어떤 오류가 발생했는지 알아보고 HDFS 쓰기 파이프라인과 HBase의 Fan-out DFSOutputStream에서 HDFS 프로토콜을 어떻게 활용했는지 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;이 글은 HDFS와 HBase에 대한 기본적인 개념과 사용법에 익숙하다고 가정하고 있습니다. HDFS와 HBase의 구성 요소와 특징은 Hadoop 문서 &lt;a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"&gt;HDFS Architecture&lt;/a&gt;와 HBase 문서 &lt;a href="https://hbase.apache.org/book.html#arch.overview"&gt;Architecture Overview&lt;/a&gt;를 참고하기 바랍니다.&lt;/p&gt;

&lt;h2 id=""&gt;파이프라인 복구 실패로 인한 장애 상황&lt;/h2&gt;

&lt;p&gt;HBase 버전 1의 RegionServer는 HDFS가 제공하는 &lt;code&gt;DFSOutputStream&lt;/code&gt;을 통해 WAL 데이터를 쓴다. HDFS 클라이언트는 데이터를 쓰다가 DataNode에서 오류가 발생하면 클라이언트가 파일에 데이터를 계속 쓸 수 있도록 파이프라인을 복구한다. 네트워크 상태가 좋지 않거나 DataNode의 디스크가 고장 나는 경우 DataNode에서 오류가 발생할 수 있다.&lt;/p&gt;

&lt;p&gt;WAL 데이터를 쓰는 도중 DataNode에 오류가 발생하면 파이프라인 복구가 시작되는데, 파이프라인 복구가 실패하여 RegionServer가 사용자의 요청을 처리하지 못하는 현상이 발생했었다. 파이프라인 복구에 실패했을 때 어떤 현상이 발생하는지 Cuve 사례를 통해 알아보겠다.&lt;/p&gt;

&lt;p&gt;Cuve에서 운영하던 HBase 버전 1 클러스터의 RegionServer에서 WAL 데이터를 쓰는 도중 아래 RegionServer 오류 로그같이 &lt;code&gt;IOException&lt;/code&gt; 오류가 발생했었다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;RegionServer 오류 로그&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2023-XX-XX XX:XX:XX,XXX WARN  [DataStreamer for file ...:blk_...] hdfs.DFSClient: DataStreamer Exception  
java.io.IOException: Broken pipe  
        at org.apache.hadoop.hdfs.DFSPacket.writeTo(DFSPacket.java)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;파이프라인에서 오류가 발생하면 파이프라인 복구를 위해 오류가 발생한 DataNode는 파이프라인에서 제외되는데, 위와 같이 &lt;code&gt;OutputStream&lt;/code&gt;에 데이터를 쓸 때 오류가 발생한 경우 오류가 발생한 DataNode를 식별할 수 없다. HDFS 클라이언트는 &lt;code&gt;OutputStream&lt;/code&gt;에 데이터를 쓸 때 오류가 발생하면 아래 &lt;code&gt;DFSOutputStream&lt;/code&gt; 코드 일부와 같이 &lt;code&gt;tryMarkPrimaryDatanodeFailed()&lt;/code&gt; 메서드를 호출한다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;code&gt;DFSOutputStream&lt;/code&gt; 코드 일부&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;try {  
  one.writeTo(blockStream); // IOException이 발생한 위치
  blockStream.flush();
} catch (IOException e) {
  tryMarkPrimaryDatanodeFailed();
  throw e;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tryMarkPrimaryDatanodeFailed()&lt;/code&gt; 메서드는 아래 &lt;code&gt;tryMarkPrimaryDatanodeFailed&lt;/code&gt; 메서드 구현 내용과 같이 오류가 발생한 DataNode가 식별되지 않은 경우 항상 파이프라인의 첫 번째 DataNode를 오류가 발생한 DataNode로 설정한다. 그 이유는 클라이언트에서 오류가 발생했을 때 &lt;code&gt;errorIndex&lt;/code&gt;가 없으면 DataNode 오류가 아닌 클라이언트의 오류로 취급되는데,  클라이언트 오류로 취급되면 더 이상 재시도하지 않고 클라이언트가 종료될 수 있기 때문이다. &lt;code&gt;OutputStream&lt;/code&gt;에서 데이터를 쓰다가 발생한 오류는 클라이언트 오류가 아닌 DataNode 오류이기 때문에, 오류가 발생한 DataNode가 식별되지 않은 경우 첫 번째 DataNode를 오류가 발생한 DataNode로 설정함으로써 오류가 DataNode 오류로 처리되고 파이프라인을 복구하게 한다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;tryMarkPrimaryDatanodeFailed 메서드 구현 내용&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;synchronized void tryMarkPrimaryDatanodeFailed() {  
  if ((errorIndex == -1) &amp;amp;&amp;amp; (restartingNodeIndex.get() == -1)) {
    errorIndex = 0; // errorIndex = 오류가 발생한 DataNode의 인덱스
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tryMarkPrimaryDatanodeFailed()&lt;/code&gt; 메서드에 의해 첫 번째 DataNode를 오류가 발생한 DataNode로 인식한 HDFS 클라이언트는 파이프라인 복구를 위해 첫 번째 DataNode를 제외하고 새 파이프라인을 구성하려고 시도했다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;첫 번째 DataNode를 오류가 발생한 DataNode로 인식한 로그&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error Recovery for block ... in pipeline DatanodeInfoWithStorage[...], DatanodeInfoWithStorage[...], DatanodeInfoWithStorage[...]: datanode 0(DatanodeInfoWithStorage[...]) is bad.  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;하지만 파이프라인 구성에 실패했다. 이후 계속해서 파이프라인 복구를 다시 시도했지만 파이프라인 복구에 성공하지 못했다. 계속된 파이프라인 복구 실패로 인해 해당 RegionServer는 그림 2와 같이 RPC Handler가 꽉 차서 사용자의 요청을 제대로 처리하지 못했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/06-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;그림 2 장애 상황 일 때 &lt;code&gt;hbase.regionserver.ipc.numActiveHandler&lt;/code&gt; 지표&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;장애 상황 이후 NameNode, DataNode, RegionServer의 로그를 확인해 보니 실제 오류가 발생했던 DataNode는 파이프라인의 마지막 DataNode였다. 오류가 발생한 DataNode를 잘못 식별하여 파이프라인 복구가 계속 실패했던 것으로 추정된다.&lt;/p&gt;

&lt;p&gt;위와 같은 오류가 발생하면 운영자가 개입하여 해당 RegionServer를 재시작해야 오류가 해결되었다. 매번 운영자가 개입할 수 없기 때문에 자동화 처리도 했지만 근본적인 문제 해결은 아니었다. 따라서 장애 상황에 대한 이해를 높이고 해결 방법을 모색하고자 HDFS 쓰기 파이프라인과 동일한 문제가 상위 버전에서는 혹시 해결되었는지 알아보았다.&lt;/p&gt;

&lt;h2 id="hdfs"&gt;HDFS 쓰기 파이프라인&lt;/h2&gt;

&lt;p&gt;HDFS는 Hadoop의 기본(default) 파일 시스템이다. HDFS는 파일을 블록(Block)으로 나누어 DataNode에 저장하고 메타데이터는 NameNode에 저장한다. 데이터의 내결함성(fault tolerance)을 제공하기 위해 블록은 여러 DataNode에 복제되는데, 복제본의 수를 Replication Factor라고 하며 기본값은 3이다. DataNode에 물리적으로 저장된 블록은 Replica라고 부른다.&lt;/p&gt;

&lt;p&gt;Replica에는 다음과 같은 5가지 상태가 존재한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Finalized
&lt;ul&gt;&lt;li&gt;Replica의 데이터가 변경되지 않는 상태이다.&lt;/li&gt;
&lt;li&gt;Append를 위해 다시 Replica를 열지 않으면, 새로운 데이터가 Replica에 기록되지 않는다.&lt;/li&gt;
&lt;li&gt;Generation stamp(단조롭게 증가하는 숫자로, 블록의 오래된 Replica를 감지하기 위한 용도)가 동일한 Finalized Replica는 동일한 데이터를 가지고 있다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;RBW(Replica Being Written to)
&lt;ul&gt;&lt;li&gt;생성되거나 Append에 의해 데이터가 쓰이고 있는 Replica이다.&lt;/li&gt;
&lt;li&gt;열린 파일의 마지막 블록은 항상 RBW이다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;RWR(Replica Waiting to be Recovered)
&lt;ul&gt;&lt;li&gt;DataNode가 죽었다가 다시 시작된 경우 모든 RBW Replica는 RWR 상태로 변경된다.&lt;/li&gt;
&lt;li&gt;RWR Replica는 더 이상 쓸모가 없어져서 버려지거나 복구 과정에 참여한다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;RUR(Replica Under Recovery)
&lt;ul&gt;&lt;li&gt;복구 과정에 참여한 Replica이다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Temporary
&lt;ul&gt;&lt;li&gt;블록 복제(Replication 모니터나 Cluster Balancer에 의해 생성)를 위해 생성된 Replica이다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음 그림은 HDFS 쓰기 파이프라인과 컴포넌트들이 서로 통신할 때 사용하는 프로토콜을 보여준다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/07-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;그림 3 HDFS 쓰기 파이프라인과 프로토콜&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;컴포넌트들은 TCP/IP 위에 설계된 프로토콜을 사용해서 서로 통신한다. &lt;a href="https://github.com/apache/hadoop/blob/1019dde65bcf12e05ef48ac71e84550d589e5d9a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java"&gt;Client Protocol&lt;/a&gt;은 클라이언트와 NameNode 간의 통신을 위해 정의된 프로토콜이다. 클라이언트는 Client Protocol을 사용하여 새로운 파일을 만들거나 기존 파일을 관리(예: 블록 할당, 이름 변경, 삭제, 권한 설정 등)할 수 있다. 클라이언트가 데이터를 읽거나 쓰기 위해서는 DataNode와 통신을 해야 하는데 DataNode와 통신할 때는 &lt;a href="https://github.com/apache/hadoop/blob/1019dde65bcf12e05ef48ac71e84550d589e5d9a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java"&gt;DataTransfer Protocol&lt;/a&gt;을 사용한다. &lt;a href="https://github.com/apache/hadoop/blob/1019dde65bcf12e05ef48ac71e84550d589e5d9a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java"&gt;Datanode Protocol&lt;/a&gt;은 DataNode와 NameNode 간의 통신을 위해 정의된 프로토콜이다. DataNode에서 NameNode로 블록 리포트 등을 보낼 때 사용된다.&lt;/p&gt;

&lt;p&gt;각 Protocol의 요청과 응답 데이터는 Protocol Buffer를 통해 직렬화, 역직렬화된다. Protocol Buffer는 구조화된 데이터를 직렬화, 역직렬화하는 방법을 제공한다. &lt;code&gt;.proto&lt;/code&gt;  파일에 데이터가 어떻게 구조화되어 있는지 정의하고 Protobuf Compiler로 컴파일하면 데이터를 직렬화, 역직렬화할 수 있는 특수한 코드를 다양한 언어별로 생성할 수 있다. Protobuf Compiler가 생성한 코드를 사용하면 다양한 플랫폼과 언어에서 쉽게 데이터를 직렬화, 역직렬화가 가능하다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Client Protocol 주요 기능
&lt;ul&gt;&lt;li&gt;파일 관련&lt;/li&gt;
&lt;li&gt;&lt;code&gt;create&lt;/code&gt;: 네임스페이스에 새로운 파일 항목(Entry)을 만든다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;append&lt;/code&gt;: 파일 끝에 추가한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;setPermission&lt;/code&gt;: 파일이나 디렉터리에 권한을 설정한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;setOwner&lt;/code&gt;: 경로(파일이나 디렉터리)에 소유자를 설정한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;addBlock&lt;/code&gt;: 쓰기를 위해 열려있는 파일에 블록을 쓰기 위해 호출한다. 새로운 블록과 블록을 복제할 DataNode를 할당받는다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;complete&lt;/code&gt;: 클라이언트가 파일에 데이터 쓰기를 완료했을 때 호출한다.&lt;/li&gt;
&lt;li&gt;네임스페이스 관련&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rename&lt;/code&gt;: 네임스페이스의 파일이나 디렉터리 이름을 바꾼다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;delete&lt;/code&gt;: 파일이나 디렉터리를 삭제한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mkdirs&lt;/code&gt;: 새로운 디렉터리를 만든다.&lt;/li&gt;
&lt;li&gt;시스템 관련&lt;/li&gt;
&lt;li&gt;&lt;code&gt;renewLease&lt;/code&gt;: 파일에 대한 변경 권한을 잃지 않기 위해 NameNode에 살아있다고 보고한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;recoverLease&lt;/code&gt;: Lease를 복구한다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;DataTransfer Protocol 주요 기능
&lt;ul&gt;&lt;li&gt;&lt;code&gt;readBlock&lt;/code&gt;: 블록을 읽는다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;writeBlock&lt;/code&gt;: DataNode 파이프라인에 블록을 쓴다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;DataNode Protocol 주요 기능
&lt;ul&gt;&lt;li&gt;&lt;code&gt;registerDatanode&lt;/code&gt;: DataNode를 등록한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sendHeartbeat&lt;/code&gt;: NameNode에 DataNode가 살아있음을 알리기 위해 Heartbeat 요청을 보낸다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;blockReport&lt;/code&gt;: 블록 리포트를 보낸다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;새로운 파일 항목 생성&lt;/h3&gt;

&lt;p&gt;클라이언트가 HDFS에 새로운 파일을 생성하여 데이터를 쓰기 위해서는 먼저 네임스페이스에 새로운 파일 항목을 만들어야 한다. 새로운 파일 항목을 만들기 위해 클라이언트는 NameNode에 &lt;code&gt;create&lt;/code&gt; 요청(그림 3의 1)을 보낸다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L75"&gt;&lt;code&gt;create&lt;/code&gt; 요청&lt;/a&gt; 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message CreateRequestProto {  
  // 파일 경로
  src: "/test_dir/file.txt"
  // 클라이언트명
  clientName: "DFSClient_..."
  // File create semantic (CreateFlag)
  createFlag: 3
  // 부모 디렉터리 생성 여부
  createParent: true
  // block replication factor (dfs.replication)
  replication: 3
  // maximum block size (dfs.blocksize)
  blockSize: 5242880
  // Crypto protocol version
  cryptoProtocolVersion: ENCRYPTION_ZONES
  // Permision
  masked {
    perm: 420
  }
  unmasked {
    perm: 438
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NameNode는 &lt;code&gt;fileId&lt;/code&gt;(Inode ID)가 포함된 파일 상태 정보를 클라이언트에게 응답으로 보낸다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L88"&gt;&lt;code&gt;create&lt;/code&gt; 응답&lt;/a&gt; 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message CreateResponseProto {  
  // 파일 상태
  fs: message HdfsFileStatusProto {
    fileType: IS_FILE
    ...
    owner: "owner"
    group: "group"
    ...
    block_replication: 3
    blocksize: 5242880
    // Inode ID
    fileId: 17434
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="datanode"&gt;DataNode 할당&lt;/h3&gt;

&lt;p&gt;NameNode로부터 &lt;code&gt;create&lt;/code&gt; 응답을 받은 후 클라이언트는 데이터를 쓸 DataNode를 할당받아야 한다. 클라이언트는 DataNode를 할당받기 위해 NameNode에 &lt;code&gt;addBlock&lt;/code&gt;  요청(그림 3의 2)을 보낸다. 클라이언트는 &lt;code&gt;addBlock&lt;/code&gt; 요청 시 &lt;code&gt;create&lt;/code&gt; 응답으로 받았던 &lt;code&gt;fileId&lt;/code&gt;(Inode ID)와 블록 할당을 위한 힌트 정보를 보낸다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L174"&gt;&lt;code&gt;addBlock&lt;/code&gt; 요청&lt;/a&gt; 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message AddBlockRequestProto {  
  // 파일 경로
  src: "/test_dir/file.txt"
  // 클라이언트명
  clientName: "DFSClient_..."
  // 블록 할당 시 제외하고 싶은 노드
  excludeNodes: []
  // Inode ID
  fileId: 17434
  // 클라이언트가 선호하는 노드
  favoredNodes: ""
  // 블록 할당에 대한 힌트(AddBlockFlag)
  flags: ""
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NameNode는 &lt;code&gt;addBlock&lt;/code&gt; 응답으로 클라이언트에 블록 정보와 파이프라인 대상 DataNode 정보를 보낸다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L184"&gt;&lt;code&gt;addBlock&lt;/code&gt;  응답&lt;/a&gt; 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message AddBlockResponseProto {  
  block: message LocatedBlockProto {
    // 블록 정보
    b: message ExtendedBlockProto {
      // Block Pool ID
      poolId: "BP-..."
      // Block ID
      blockId: 1073742133
      generationStamp: 1309
      numBytes: 0
    }
    // 파일에서 블록의 첫 번째 바이트 오프셋
    offset: 0
    // 파이프라인 대상 DataNode 정보
    locs: [DatanodeInfoProto, DatanodeInfoProto, message DatanodeInfoProto {
      // DataNode IP 주소, 호스트명, 포트 정보
      id: message DatanodeIDProto {
        ipAddr: "x.x.x.x"
        hostName: "example"
        datanodeUuid: "..."
        xferPort: 0
        infoPort: 0
        ipcPort: 0
        infoSecurePort: 0
      }
      ...
    }]
    storageTypes: [DISK, DISK, DISK]
    storageIDs: [..., ... , ...]
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=""&gt;파이프라인 구성 및 데이터 쓰기&lt;/h3&gt;

&lt;p&gt;NameNode로부터 파이프라인 대상 DataNode 정보를 획득한 클라이언트는 데이터를 쓰기 위해 파이프라인 대상 DataNode들로 블록 생성 파이프라인을 구성하고 블록을 패킷(네트워크 패킷이 아니라 HDFS 데이터 쓰기에서 사용되는 클래스를 의미)으로 나누어 파이프라인의 DataNode에 데이터를 쓴다. 파이프라인을 구성하고 데이터를 쓰는 과정은 그림 4와 같이 3 단계로 이루어진다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/08-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;그림 4 블록 생성 파이프라인 단계(원본 출처: HDFS &lt;a href="https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf"&gt;Append/Hflush/Read 디자인 문서&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;

&lt;h4 id="1"&gt;1 단계: 파이프라인 설정&lt;/h4&gt;

&lt;p&gt;그림 4의 T0~T1은 파이프라인 설정 단계이다. 파이프라인을 따라 다운스트림 DataNode에게 &lt;code&gt;WRITE_BLOCK&lt;/code&gt; 요청을 전송한다.(그림 3의 3)&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/datatransfer.proto#L88"&gt;&lt;code&gt;writeBlock&lt;/code&gt; 요청&lt;/a&gt; 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message OpWriteBlockProto {  
  header: message ClientOperationHeaderProto {
    baseHeader: message ClientOperationHeaderProto {
      // 블록 정보
      block: message ExtendedBlockProto
      ...
    }
    // 클라이언트명
    clientName: "DFSClient_..."
  }
  // 파이프라인 대상 DataNode 정보(IP 주소, 호스트명, 포트 정보, ...)
  targets: [DatanodeInfoProto, DatanodeInfoProto]
  // 파이프라인 스테이지(BlockConstructionStage)
  stage: PIPELINE_SETUP_CREATE(블록 생성을 위한 파이프라인 설정)
  // 파이프라인 크기
  pipelineSize: 3
  // minimum number of bytes received.
  minBytesRcvd: 0
  // maximum number of bytes received.
  maxBytesRcvd: 0
  // 블록의 latest Generation Stamp
  latestGenerationStamp: 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;마지막 DataNode가 요청을 받은 후 파이프라인 업스트림으로 ACK가 전송된다.(그림 3의 4)&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/datatransfer.proto#L288"&gt;ack&lt;/a&gt; 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message BlockOpResponseProto {  
  // 파이프라인 상태
  status: SUCCESS
  // 연결 설정에 실패한 첫 번째 DataNode
  firstBadLink: ""
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;파이프라인 설정 단계가 끝나면 파이프라인을 따라 네트워크 연결이 설정되고 DataNode에 Replica가 준비된다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;writeBlock&lt;/code&gt; 요청에서 &lt;code&gt;stage&lt;/code&gt;가 &lt;code&gt;PIPELINE_SETUP_CREATE&lt;/code&gt;인 경우 DataNode는 새로운 RBW Replica를 만든다.
&lt;ul&gt;&lt;li&gt;&lt;code&gt;writeBlock&lt;/code&gt; 요청에서 &lt;code&gt;stage&lt;/code&gt;가 &lt;code&gt;PIPELINE_SETUP_APPEND&lt;/code&gt;인 경우 append를 위해 DataNode는 Finalized Replica를 RBW Replica로 바꾼다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="2"&gt;2 단계: 데이터 스트리밍&lt;/h4&gt;

&lt;p&gt;그림 4의 T2~T5는 데이터 스트리밍 단계이다. 그림 4의 T2에서 첫 번째 패킷이 전송되었고 T5에서 마지막 패킷의 ACK를 수신했다.&lt;/p&gt;

&lt;p&gt;파이프라인 설정이 완료되면 클라이언트는 파이프라인에 데이터를 쓰는데, 데이터는 먼저 클라이언트 버퍼에 저장된다. 버퍼가 꽉 차면 파이프라인으로 데이터가 전송된다.(그림 3의 5)&lt;/p&gt;

&lt;p&gt;이전 패킷의 ACK를 받기 전이라도 파이프라인을 통해 다음 패킷이 전송될 수 있다. 그림 4의 T3에서 &lt;code&gt;hflush&lt;/code&gt;가 호출되었다. &lt;code&gt;hflush&lt;/code&gt;가 명시적으로 호출된 경우에는 패킷이 채워지지 않았어도 파이프라인으로 전송된다. &lt;code&gt;hflush&lt;/code&gt;는 동기 작업이기 때문에 flush된 패킷의 ACK를 받기 전에는 데이터를 쓸 수 없다. 그림 4의 packet 2는 packet 1의 ACK를 수신한 그림 4의 T4 이후에 전송된다.&lt;/p&gt;

&lt;h4 id="3"&gt;3 단계: 파이프라인 종료&lt;/h4&gt;

&lt;p&gt;그림 3의 T6~T7은 파이프라인 종료 단계이다. 클라이언트는 모든 패킷의 ACK을 받은 후에 종료(close) 요청을 보낸다. 파이프라인의 모든 DataNode는 해당 Replica를 Finalized 상태로 변경하고 NameNode에 보고한다. NameNode는 Replica의 상태가 Finalized라고 보고한 DataNode의 수가 최소 복제 수 이상인 경우 블록의 상태를 완료(Complete)로 바꾼다. 파일을 닫으려면 파일의 모든 블록이 완료된 상태여야 한다&lt;/p&gt;

&lt;p&gt;모든 데이터를 다 쓴 클라이언트는 해당 파일에 쓰기 작업이 완료되었다는 것을 NameNode로 알리고 파일을 닫기 위해 NameNode에 &lt;code&gt;complete&lt;/code&gt; 요청(그림 3의 7)을 보낸다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L203"&gt;&lt;code&gt;complete&lt;/code&gt; 요청&lt;/a&gt; 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message CompleteResponseProto {  
  // 파일 경로
  src: "/test_dir/file.txt"
  // 클라이언트명
  clientName: "DFSClient_..."
  // 마지막 블록 정보
  last: message ExtendedBlockProto {
    poolId: "..."
    blockId: "..."
    generationStamp: ...
  }
  // Inode ID
  fileId: 17434
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;a href="https://github.com/apache/hadoop/blob/1e877761e8dadd71effef30e592368f7fe66a61b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientNamenodeProtocol.proto#L210"&gt;&lt;code&gt;complete&lt;/code&gt; 응답&lt;/a&gt; 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message CompleteResponseProto {  
  // 성공 여부
  result: true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="hdfs"&gt;HDFS 쓰기 파이프라인의 특징&lt;/h3&gt;

&lt;p&gt;지금까지 HDFS 쓰기 파이프라인에 대해 알아보았다. HDFS 쓰기 파이프라인은 각 노드의 네트워크 대역폭을 최대한 활용하여 모든 데이터를 복제하는 데 걸리는 시간을 최소화하는 방식이다.  왜 HDFS 쓰기 파이프라인이 각 노드의 네트워크 대역폭을 최대한 활용하는 방식인지 그림 5와 그림 6의 비교를 통해 알아보겠다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/09-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;그림 5 파이프라인을 통해 데이터를 전달하는 방식&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/10-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;그림 6 클라이언트가 모든 데이터를 전달하는 방식&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;HDFS 클라이언트를 포함하여 각 노드의 사용 가능한 대역폭이 1Gbps라고 가정하면 그림 5의 경우 복제본 데이터를 포함하여 전송하는 전체 데이터의 양은 3Gbps가 된다. 실제로는 DataNode 2와 DataNode 3가 동일 Rack 안에 있기 때문에 지연 시간이 짧고 사용 가능한 대역폭도 더 커서 더 빠르게 데이터가 전송될 것이다.&lt;/p&gt;

&lt;p&gt;하지만 그림 6과 같이 클라이언트가 데이터를 모든 DataNode에 전송하면 전송하는 전체 데이터의 양은 1Gbps가 된다. 일반적으로 HDFS에 저장하는 파일은 크기가 크다. 저장해야 하는 파일의 크기가 크기 때문에 복제를 위해 네트워크를 통해 전송해야 하는 데이터의 양도 많아진다.&lt;/p&gt;

&lt;p&gt;즉, 각 노드의 대역폭을 최대한 활용하는 파이프라인 방식이 큰 파일을 저장하는 HDFS에서 효율적이다.&lt;/p&gt;

&lt;h2 id="fanoutdfsoutputstreamwal"&gt;Fan-out DFSOutputStream를 통한 WAL 쓰기 최적화&lt;/h2&gt;

&lt;p&gt;HBase는 아래와 같이 4가지의 WAL Durability 설정을 제공하며, &lt;code&gt;SYNC_WAL&lt;/code&gt;이 기본값이다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SKIP_WAL&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;WAL을 비활성화한다.&lt;/li&gt;
&lt;li&gt;데이터 손실이 발생할 수 있는 옵션이다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ASYNC_WAL&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;클라이언트가 WAL에 쓴 데이터가 sync되는 것을 기다리지 않는다.&lt;/li&gt;
&lt;li&gt;데이터 손실이 발생할 수 있는 옵션이다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SYNC_WAL&lt;/code&gt;(기본값)
&lt;ul&gt;&lt;li&gt;클라이언트에 리턴하기 전에 데이터가 sync되길 기다린다.(HDFS의 &lt;code&gt;hflush&lt;/code&gt; 호출)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FSYNC_WAL&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;클라이언트에 리턴하기 전에 데이터가 fsync되길 기다린다.(HDFS의 &lt;code&gt;hsync&lt;/code&gt; 호출)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WAL Durability 설정이 &lt;code&gt;SYNC_WAL&lt;/code&gt;인 경우 HBase는 WAL에 데이터를 쓰고 데이터 손실을 방지하기 위해 HDFS의 &lt;code&gt;hflush&lt;/code&gt;를 호출해 데이터가 sync되길 기다린다. &lt;code&gt;hflush&lt;/code&gt;는 동기 작업으로, 클라이언트는 전송한 패킷의 ACK가 오길 기다린다.(&lt;a href="#2-단계-데이터-스트리밍"&gt;2 단계: 데이터 스트리밍&lt;/a&gt; 참고)&lt;/p&gt;

&lt;p&gt;WAL 데이터는 상대적으로 데이터의 크기가 작기 때문에 WAL 쓰기는 네트워크 대역폭의 영향은 덜 받지만, 전송한 패킷의 ACK가 오길 기다려야 하기 때문에 지연 시간이 긴 경우 WAL 쓰기 성능이 낮아질 수 있다. 따라서 WAL 쓰기 성능을 높이기 위해서는 지연 시간을 감소시키는 게 중요한데, 그림 5와 같이 파이프라인을 통해 데이터를 전달하면 ACK가 여러 노드를 거쳐서 클라이언트로 전달되기 때문에 지연 시간이 길어질 수 있다. 그림 6과 같이 클라이언트가 동시에 모든 데이터를 전송하고 ACK를 직접 받으면 지연 시간을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;HBase는 WAL 쓰기 성능을 개선하기 위해 Netty 기반으로 그림 6처럼 DataNode에 데이터를 동시에 쓰는 WAL 쓰기용 Fan-out DFSOutputStream을 개발했다. HBase는 다음과 같이 &lt;code&gt;hbase.wal.provider&lt;/code&gt;를 설정하여 WAL 구현체를 지정할 수 있는데 &lt;code&gt;hbase.wal.provider&lt;/code&gt;를 &lt;code&gt;asyncfs&lt;/code&gt;(HBase 2에서 기본값)로 설정한 경우 Fan-out DFSOutputStream이 사용된다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;asyncfs&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;HBase 2에서 기본값이다.&lt;/li&gt;
&lt;li&gt;HBase 2에서 추가되었으며 WAL 데이터를 블록 생성 파이프라인을 따라서 쓰지 않고 동시에(Fan-out) 쓰기 때문에 지연 시간을 줄일 수 있다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filesystem&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;HBase 1에서 기본값이다.&lt;/li&gt;
&lt;li&gt;DFSClient를 기반으로 만들어졌으며 블록 생성 파이프라인을 따라 데이터를 쓴다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;multiwal&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;여러 개의 asyncfs 또는 여러 개의 filesystem을 사용하는 설정이다.&lt;/li&gt;
&lt;li&gt;RegionServer에서 단일 WAL을 사용하면 병목 현상이 생길 수 있는데 여러 개의 WAL을 병렬로 쓸 수 있게 하여 총 처리량을 증가시킬 수 있는 방법이다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fan-out DFSOutputStream은 모든 DataNode에 동시에 데이터 쓰기를 진행하기 때문에 일반적으로 대기 시간이 단축된다. 또한 오류가 발생했을 때 파이프라인 복구를 수행하지 않고 새로운 WAL 파일을 만들어서 데이터를 다시 쓴다. 파이프라인 복구를 수행하지 않기 때문에 앞에서 언급한 파이프라인 복구 실패로 인한 문제가 발생하지 않는다. Fan-out DFSOutputStream의 구조는 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/11-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;그림 7 Fan-out DFSOutputStream 구조&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;새로운 WAL 파일이 요청되면 &lt;code&gt;FanOutOneBlockAsyncDFSOutputHelper&lt;/code&gt;는 HDFS 쓰기 파이프라인와 동일하게 Client Protocol의 &lt;code&gt;create&lt;/code&gt; 요청(그림 7의 1)을 보내 네임스페이스에 새로운 WAL 파일 항목을 만든다.  각 Protocol의 요청과 응답 데이터가 Protocol Buffer를 통해 직렬화, 역직렬화되기 때문에 HBase는 HDFS의 Protocol Buffer 코드를 통해 쉽게 동일한 요청을 만들고 응답을 파싱할 수 있다.&lt;/p&gt;

&lt;p&gt;NameNode로부터 응답을 받은 후 블록을 쓸 DataNode를 할당받기 위해 &lt;code&gt;FanOutOneBlockAsyncDFSOutputHelper&lt;/code&gt;는 &lt;code&gt;addBlock&lt;/code&gt; 요청(그림 7의 2)을 NameNode로 보낸다. NameNode로부터 블록을 쓸 DataNode를 할당받은 후에는 Netty Channel을 사용해서 DataNode와 연결을 맺고 &lt;code&gt;writeBlock&lt;/code&gt; 요청(그림 7의 3)을 보낸다. &lt;code&gt;FanOutOneBlockAsyncDFSOutputHelper&lt;/code&gt;가 보내는 &lt;code&gt;writeBlock&lt;/code&gt; 요청은 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;&lt;code&gt;FanOutOneBlockAsyncDFSOutputHelper&lt;/code&gt;에서 보내는 &lt;code&gt;writeBlock&lt;/code&gt; 요청 예&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message OpWriteBlockProto {  
  header: message ClientOperationHeaderProto {
    // 블록 정보
    block: message ExtendedBlockProto
    ...
  }
  // 클라이언트명
  clientName: "DFSClient_..."
  // 파이프라인 대상 DataNode 정보(IP 주소, 호스트명, 포트 정보, ...)
  targets: []
  // 파이프라인 스테이지(BlockConstructionStage)
  stage: PIPELINE_SETUP_CREATE
  // 파이프라인 크기
  pipelineSize: 1
  // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;FanOutOneBlockAsyncDFSOutputHelper&lt;/code&gt;가 보내는 &lt;code&gt;writeBlock&lt;/code&gt; 요청을 살펴보면 HDFS 쓰기 파이프라인에서 보내는 &lt;code&gt;writeBlock&lt;/code&gt; 요청과 다르게 파이프라인 대상 DataNode 정보가 없고 파이프라인 크기가 1이다. 이 요청을 받은 DataNode는 파이프라인 대상 DataNode 정보가 없기 때문에 자신을 파이프라인의 마지막 DataNode로 인식하고 다른 DataNode와 추가적인 연결을 만들지 않는다. 즉, DataNode끼리 블록 생성 파이프라인을 만들지 않는다.&lt;/p&gt;

&lt;p&gt;하지만 이 방식은 HDFS의 가시성(visibility)이 보장되지 않는다. 데이터를 쓰고 있는 파일의 경우 HDFS의 가시성 보장에 따라 파이프라인의 마지막 DataNode에 쓰인 데이터까지 클라이언트에서 사용 가능한 데이터가 되는데, Fan-out DFSOutputStream은 모든 DataNode가 파이프라인의 마지막 DataNode로 취급되기 때문에 아직 데이터를 쓰고 있는 WAL 파일을 읽을 경우 데이터 불일치가 발생할 수 있다. HBase는 이 문제를 해결하기 위하여 HDFS에 sync된 파일의 길이를 별도로 관리하여 내부 프로세스에서 데이터를 읽을 때 해당 길이까지만 데이터를 읽을 수 있도록 제한한다.&lt;/p&gt;

&lt;p&gt;DataNode와 기존 HDFS 쓰기 파이프라인에 파이프라인 설정 단계까지 마친  &lt;code&gt;FanOutOneBlockAsyncDFSOutputHelper&lt;/code&gt;는 클라이언트가 데이터를 쓸 수 있도록 &lt;code&gt;FanOutOneBlockAsyncDFSOutput&lt;/code&gt;을 생성한다.(그림 7의 4) 이후 &lt;code&gt;FanOutOneBlockAsyncDFSOutput&lt;/code&gt;은 Netty Channel을 이용하여 모든 DataNode에 동시에 WAL 데이터를 쓴다.(그림 7의 5)&lt;/p&gt;

&lt;p&gt;HBase는 데이터를 쓰고 있는 WAL의 파일 크기가 HDFS 블록 크기(&lt;code&gt;hbase.regionserver.hlog.blocksize&lt;/code&gt; 설정)의 50%(&lt;code&gt;hbase.regionserver.logroll.multiplier&lt;/code&gt; 설정)가 되거나 기존 파일에 데이터를 쓰다 오류가 발생하면 기존 WAL 파일을 닫고 새로운 WAL 파일을 만든다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hbase.regionserver.hlog.blocksize&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;WAL 파일의 HDFS 블록 크기(기본값: HDFS 기본 블록 크기의 2배)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hbase.regionserver.logroll.multiplier&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;WAL 파일의 크기가 HDFS 블록 크기의 multiplier만큼 도달하면 새로운 WAL 파일을 만든다.(기본값: 0.5)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;기존 WAL 파일을 닫고 새로운 WAL 파일을 만들 때 기존 &lt;code&gt;FanOutOneBlockAsyncDFSOutput&lt;/code&gt;은 닫고 새로운 &lt;code&gt;FanOutOneBlockAsyncDFSOutput&lt;/code&gt;을 만드는데, &lt;code&gt;FanOutOneBlockAsyncDFSOutput&lt;/code&gt;이 닫힐 때 &lt;code&gt;FanOutOneBlockAsyncDFSOutput&lt;/code&gt;은 DataNode와 연결을 정리하고 NameNode에 &lt;code&gt;complete&lt;/code&gt; 요청(그림 7의6)을 보내 현재 WAL 파일에 쓰기 작업이 완료되었다는 것을 알린다.&lt;/p&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;p&gt;이 글에서는 HDFS 쓰기 파이프라인과  HBase가 WAL 쓰기 최적화를 위해 개발한 Fan-out DFSOutputStream에 대해 알아보았다.&lt;/p&gt;

&lt;p&gt;Fan-out DFSOutputStream은 아직 일반적인 쓰기 작업에서는 사용할 수 없다. 일반적인 쓰기 작업에서 사용하기 위해서는 Fan-out DFSOutputStream이 여러 블록을 쓸 수 있도록 개선하고 HDFS 가시성이 보장되지 않는 문제를 해결해야 한다. 또한 추후 해당 기능을 적용하려면 그 전에 쓰기 작업이 네트워크 대역폭을 최대로 활용하는 것이 중요한지, 아니면 지연 시간을 줄이는 것이 중요한지 먼저 판단할 필요가 있다.&lt;/p&gt;

&lt;p&gt;HBase에서 WAL 성능은 사용자 요청 처리 시간에 영향을 많이 준다. 따라서 HBase는 WAL 성능을 높이기 위해서는 지연 시간을 줄이는 것이 필요했다. 이를 위해 HBase는 HDFS 프로토콜을 사용하여 Fan-out DFSOutputStream을 개발했다. 2.5.0 버전에는 패킷 처리 시간이 느린 DataNode를 빠르게 탐지하여 OutputStream에서 제거하는 기능이 추가되었는데(&lt;a href="https://issues.apache.org/jira/browse/HBASE-26347"&gt;HBASE-26347&lt;/a&gt; Support detect and exclude slow DNs in fan-out of WAL) 이러한 기능은 자체 개발한 Fan-out DFSOutputStream에서 ACK가 돌아오는 시간을 측정할 수 있었기 때문에 가능했다. 만약 HDFS 프로토콜에 대한 이해가 없었다면 이러한 기능을 추가하기 어려웠을 것이다.&lt;/p&gt;

&lt;p&gt;추후 기회가 된다면 각 컴포넌트가 프로토콜을 어떻게 처리하는지 알아보겠다. 이 글이 HDFS 쓰기 과정을 이해하는 데 조금이나마 도움이 되길 바란다.&lt;/p&gt;

&lt;h2 id=""&gt;참고 자료&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://issues.apache.org/jira/browse/HDFS-265"&gt;HDFS-265&lt;/a&gt; Revisit append&lt;/li&gt;
&lt;li&gt;&lt;a href="https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf"&gt;Append/Hflush/Read Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://issues.apache.org/jira/browse/HBASE-14790"&gt;HBASE-14790&lt;/a&gt; Implement a new DFSOutputStream for logging WAL only&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.cloudera.com/apache-hbase-write-path/"&gt;Apache HBase Write Path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hadoop.apache.org"&gt;https://hadoop.apache.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hbase.apache.org"&gt;https://hbase.apache.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt; &lt;br /&gt;
&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>AI 플랫폼을 위한 스토리지 JuiceFS 도입기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/4555524" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/4555524</id>
    <updated>2023-12-12T14:46:05Z</updated>
    <content type="html">&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/TmU7HqLHXVM?si=8QH7rHrgNaU-E43y" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;  

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;AiSuite는 네이버 개발자들이 사용하는 AI 플랫폼입니다. 네이버의 다양한 서비스가 AiSuite에서 개발 및 운영됩니다.&lt;/p&gt;

&lt;p&gt;AiSuite는 Kubernetes 기반의 컨테이너 환경을 제공해 고비용의 GPU 자원을 효율적으로 관리합니다. 또한 &lt;a href="https://www.kubeflow.org"&gt;Kubeflow&lt;/a&gt;를 지원하여 AI 개발뿐만 아니라 학습, 서빙을 연계하는 AI 파이프라인 구축이 가능합니다. &lt;a href="https://deview.kr/2021/sessions/459"&gt;C3&lt;/a&gt;, &lt;a href="https://deview.kr/2017/schedule/188"&gt;Cuve&lt;/a&gt;, &lt;a href="https://deview.kr/2021/sessions/515"&gt;CQuery&lt;/a&gt;와 같은 사내 데이터 플랫폼을 활용하는 Kubeflow 파이프라인 컴포넌트도 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/04.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;AI 플랫폼을 운영하면서 가장 어려운 것은 AI 워크로드에 적합한 스토리지를 제공하는 것입니다. LLM이 확산되면서 좋은 AI 모델을 생성하기 위해 필요한 데이터의 크기는 점점 더 커지고 있으며, 분산 학습을 위해서는 다수의 노드에서 동시에 접근할 수 있어야 합니다. 또한 &lt;a href="https://ai.meta.com/llama/"&gt;Llama 2&lt;/a&gt;, &lt;a href="https://www.mosaicml.com/mpt"&gt;MPT&lt;/a&gt; 등 빠르게 등장하는 다양한 LLM 오픈소스를 쉽게 적용해볼 수 있어야 합니다.&lt;/p&gt;

&lt;p&gt;정리해보면 AI 플랫폼에 적합한 스토리지의 요구 사항은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;대규모 데이터를 다룰 수 있어야 합니다.&lt;/li&gt;
&lt;li&gt;반복적인 학습을 위해서 높은 성능이 필요합니다.&lt;/li&gt;
&lt;li&gt;Kubernetes 영구 볼륨(persistent volume)으로 사용할 수 있어야 합니다. 즉, &lt;a href="https://kubernetes-csi.github.io/docs/introduction.html"&gt;Kubernetes CSI Driver&lt;/a&gt;를 지원해야 합니다.&lt;/li&gt;
&lt;li&gt;다양한 오픈소스, 라이브러리를 변경 없이 사용하기 위해 POSIX 호환성을 제공해야 합니다.&lt;/li&gt;
&lt;li&gt;분산 학습, 대규모 서빙을 위해서는 동시에 접근할 수 있어야 합니다(&lt;a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes"&gt;ReadWriteMany, ReadOnlyMany&lt;/a&gt; 참고).&lt;/li&gt;
&lt;li&gt;일관성(consistency) 문제가 없어야 합니다.&lt;/li&gt;
&lt;li&gt;운영 부담이 크지 않아야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;요구 사항을 모두 만족하는 스토리지를 마련하는 것은 쉽지 않습니다. 대규모이며 높은 성능으로 동시 접근, POSIX 호환까지 가능해야 합니다.&lt;/p&gt;

&lt;p&gt;외부 클라우드에서 찾아보면 &lt;a href="https://aws.amazon.com/ko/efs/"&gt;AWS EFS&lt;/a&gt;, &lt;a href="https://cloud.google.com/filestore"&gt;Google Filestore&lt;/a&gt;가 비슷합니다. 하지만 AWS S3, Google Cloud Storage 등의 Object Storage에 비해 큰 비용이 발생합니다(AWS S3와 EFS는 표준 요금 기준 10배 차이). 그뿐만 아니라, AiSuite는 네이버 사내에 구축되어 있으므로 AWS, GCP와 같은 외부 클라우드 스토리지를 사용할 수 없습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.ddn.com/products/lustre-file-system-exascaler"&gt;DDN EXAScaler&lt;/a&gt;와 같이 요구 사항을 만족하는 별도의 스토리지를 도입할 수 있지만 큰 비용이 발생합니다. 따라서 AiSuite에서는 대규모 학습 전용으로 부분적으로만 도입하고 있습니다.&lt;/p&gt;

&lt;p&gt;이러한 문제를 해결하기 위해 고민했던 내용과 새로운 스토리지를 도입한 경험을 설명합니다.&lt;/p&gt;

&lt;h2 id=""&gt;스토리지 검토&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://www.gluster.org/"&gt;GlusterFS&lt;/a&gt;, &lt;a href="https://docs.ceph.com/en/latest/cephfs/"&gt;CephFS&lt;/a&gt;와 같은 오픈소스 도입을 생각해볼 수 있지만 직접 운영하는 것은 부담이 크다. 따라서 네이버 사내에서 지원하는 스토리지를 우선으로 검토했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/05.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;하지만 앞의 요구 사항을 모두 만족하는 스토리지를 찾기는 어려웠다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;네이버의 C3 HDFS(Hadoop Distributed File System)는 대규모 데이터를 다룰 수 있다. 하지만 HDFS는 Kubernetes CSI Driver를 지원하지 않으므로 Kubernetes 영구 볼륨으로 사용할 수 없다.&lt;/li&gt;
&lt;li&gt;네이버의 Object Storage인 nubes도 대규모 데이터를 다룰 수 있으며, CLI, REST, S3, POSIX 등의 다양한 인터페이스를 지원한다. 하지만 Object Storage의 특성에 따라 POSIX API를 완벽히 지원하지는 않는다. 또한, Kubernetes CSI Driver를 지원하지 않아 Kubernetes 영구 볼륨으로 사용할 수 없다.&lt;/li&gt;
&lt;li&gt;Ceph-rbd는 &lt;a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes"&gt;ReadWriteMany, ReadOnlyMany&lt;/a&gt;를 지원하지 않아 동시에 여러 Pod에서 접근할 수 없다.&lt;/li&gt;
&lt;li&gt;NFS는 간단하게 구성할 수 있지만 확장성, HA 문제가 있다.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rancher/local-path-provisioner"&gt;local-path&lt;/a&gt;는 Kubernetes 노드의 디스크에 데이터를 저장한다. 빠르지만 동시 접근은 불가능하다. 또한 저장된 데이터가 각각의 노드에 위치하므로 이를 위한 스케줄링 또는 앱 레벨에서의 구현이 필요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="alluxio"&gt;Alluxio&lt;/h3&gt;

&lt;p&gt;Alluxio는 앞의 요구 사항을 만족할 수 있을까?&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.alluxio.io/"&gt;Alluxio&lt;/a&gt;는 Hadoop 클러스터에서 처리되어 HDFS에 보관된 데이터를 AiSuite에서 빠르고 쉽게 사용하기 위해 도입했다. 자세한 내용은 &lt;a href="https://d2.naver.com/helloworld/3863967"&gt;AI 플랫폼과 데이터 플랫폼을 이어주는 Alluxio 적용기&lt;/a&gt;를 참고하기 바란다.&lt;/p&gt;

&lt;h4 id="posix"&gt;불완전한 POSIX 호환&lt;/h4&gt;

&lt;p&gt;Alluxio는 Kubernetes 영구 볼륨으로 사용할 수 있지만 symbolic link, truncate, fallocate, append, xattr 등 일부 POSIX API는 지원하지 않는다. 예를 들어 Alluxio를 마운트한 경로 &lt;code&gt;/data&lt;/code&gt;에서 append는 다음과 같이 실패한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-shell"&gt;$ cd /data/
$ echo "appended" &amp;gt;&amp;gt; myfile.txt
bash: echo: write error: File exists  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;다양한 AI 오픈소스, 라이브러리는 로컬 파일 시스템에 데이터가 위치하는 것을 기본으로 구현된다. 지원되지 않는 POSIX API가 있으면 정상 작동하지 않을 수 있다. 이로 인해 Alluxio의 경우 데이터를 &lt;a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#resource-emphemeralstorage-consumption"&gt;임시 스토리지(emphemeral storage)&lt;/a&gt;에 복사한 후 사용해야 하는 경우가 있다. 그 결과 AI 개발이 불편하고 느려진다.&lt;/p&gt;

&lt;h4 id=""&gt;원본 저장소와의 불일치&lt;/h4&gt;

&lt;p&gt;Alluxio는 독립적인 스토리지라기보다는 원본 저장소에 대한 캐싱 스토리지에 가깝다. 원본 저장소가 HDFS일 때, 다음과 같이 Alluxio를 거치지 않는 HDFS 변경으로 인해 Alluxio와 HDFS 사이의 불일치가 발생한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/06.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://www.alluxio.io/blog/two-ways-to-keep-files-in-sync-between-alluxio-and-hdfs"&gt;https://www.alluxio.io/blog/two-ways-to-keep-files-in-sync-between-alluxio-and-hdfs&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Alluxio에서 얼마나 자주 원본 저장소와 동기화할지 설정할 수도 있다. 자세한 내용은 &lt;a href="https://docs.alluxio.io/os/user/stable/en/core-services/Unified-Namespace.html#ufs-metadata-sync"&gt;UFS Metadata Sync&lt;/a&gt;를 참고하기 바란다. 하지만 동기화가 자주 발생하면 원본 저장소로 메타데이터에 대한 과도한 요청이 발생한다.&lt;/p&gt;

&lt;p&gt;AiSuite는 Hadoop 기반의 데이터 플랫폼과 연동하기 위해 HDFS를 원본 저장소로 하는 Alluxio를 운영하고 있는데, 짧은 주기의 동기화로 인해 HDFS 메타데이터를 관리하는 &lt;a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#NameNode_and_DataNodes"&gt;NameNode&lt;/a&gt; 부하가 증가한다.&lt;/p&gt;

&lt;h4 id=""&gt;운영 부담&lt;/h4&gt;

&lt;p&gt;Alluxio는 다음과 같이 master와 worker 서버로 구성되는 별도의 클러스터를 운영해야 한다는 부담도 있다. 그뿐만 아니라, AiSuite의 모든 사용자가 공유하기 때문에 문제가 발생하면 전체 사용자에게 영향을 줄 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/07.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://docs.alluxio.io/os/user/stable/en/overview/Architecture.html"&gt;https://docs.alluxio.io/os/user/stable/en/overview/Architecture.html&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id="juicefs"&gt;JuiceFS&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://juicefs.com/en/"&gt;JuiceFS&lt;/a&gt;는 기존의 저장소와 DB를 활용하는 분산 파일 시스템이다. JuiceFS를 살펴보면서 왜 JuiceFS를 적용하게 되었는지 설명하겠다.&lt;/p&gt;

&lt;h4 id=""&gt;구성&lt;/h4&gt;

&lt;p&gt;JuiceFS의 구성은 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/08.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://juicefs.com/docs/community/architecture/"&gt;https://juicefs.com/docs/community/architecture/&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;메타데이터 엔진(Metadata Engine): 파일의 메타데이터(파일명, 크기 등)를 관리한다. Redis, TiKV, MySQL/MariaDB, PostgreSQL 등의 &lt;a href="https://juicefs.com/docs/community/databases_for_metadata"&gt;다양한 DB&lt;/a&gt;를 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;데이터 스토리지(Data Storage): 데이터가 실제 저장되는 저장소이다. S3, OpenStack Swift, Ceph, MinIO, HDFS 등의 &lt;a href="https://juicefs.com/docs/community/reference/how_to_set_up_object_storage#supported-object-storage"&gt;다양한 저장소&lt;/a&gt;를 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;클라이언트(Client): 메타데이터 엔진 및 데이터 스토리지와 연동되어 파일 I/O 오퍼레이션을 수행한다. 여러 인터페이스를 지원하여 다양한 환경에서 사용할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JuiceFS는 이미 사용 중이거나 익숙한 저장소, DB를 사용해 Kubernetes 환경에 적합한 스토리지로 사용할 수 있어, 새로운 스토리지를 구축하고 운영하는 부담이 없다. 데이터 스토리지 역할의 저장소와 메타데이터 엔진 역할의 DB만 준비되어 있다면 별도의 서버 구동 없이 클라이언트만 있으면 된다.&lt;/p&gt;

&lt;p&gt;예를 들어, S3 Object Storage와 Redis가 준비되어 있으면 JuiceFS를 활용해 고성능의 다양한 기능을 갖춘 스토리지로 사용할 수 있다. 이는 JuiceFS에 주목한 이유이다. 네이버 사내에서 지원되는 저장소와 DB를 활용하면 쉽게 스토리지를 구축할 수 있다.&lt;/p&gt;

&lt;h4 id=""&gt;기능&lt;/h4&gt;

&lt;p&gt;JuiceFS가 제공하는 기능은 다음과 같다. 동시 접근이 가능하며 POSIX 및 Kubernetes 환경을 지원한다. 위에서 언급했던 AI 플랫폼을 위한 스토리지 요구 사항을 만족한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;POSIX 호환: 로컬 파일 시스템처럼 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;HDFS 호환: &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;HDFS API&lt;/a&gt;를 지원하여 Spark, Hive 등의 데이터 처리 프레임워크에서도 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;S3 호환: &lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 gateway&lt;/a&gt;를 구동하면 S3 호환 인터페이스로도 접근할 수 있다.&lt;/li&gt;
&lt;li&gt;클라우드 네이티브: &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;CSI Driver&lt;/a&gt;를 지원하여 Kubernetes 영구 볼륨으로 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;분산: 다수의 서버에서 동시에 공유할 수 있다.&lt;/li&gt;
&lt;li&gt;강력한 일관성: 커밋된 변경은 즉시 모든 서버에서 유효하다.&lt;/li&gt;
&lt;li&gt;뛰어난 성능: 자세한 내용은 &lt;a href="https://juicefs.com/docs/community/benchmark/"&gt;Performance Benchmark&lt;/a&gt;를 참고한다.&lt;/li&gt;
&lt;li&gt;데이터 보안: &lt;a href="https://juicefs.com/docs/community/security/encryption/"&gt;데이터 암호화&lt;/a&gt;를 지원한다.&lt;/li&gt;
&lt;li&gt;파일 잠금: BSD 잠금(flock), POSIX 잠금(fcntl)을 지원한다.&lt;/li&gt;
&lt;li&gt;데이터 압축: &lt;a href="https://lz4.github.io/lz4"&gt;LZ4&lt;/a&gt;, &lt;a href="https://facebook.github.io/zstd"&gt;Zstandard&lt;/a&gt;를 지원하여 저장소 공간을 절약할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://juicefs.com/docs/community/introduction/#features"&gt;https://juicefs.com/docs/community/introduction/#features&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id=""&gt;파일 시스템&lt;/h4&gt;

&lt;p&gt;JuiceFS는 파일을 다루기 위해 다음과 같은 개념을 도입했다. 물리적으로 떨어져 느리고 수정하기 어려운 Object Storage의 단점을 보완한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Chunk&lt;/strong&gt;: 각 파일은 64MB 단위의 Chunk로 분리해 관리한다. 대규모 파일의 경우에도 오프셋을 기반으로 동시에 읽거나 쓸 수 있다. 대규모 데이터를 다루기에 효과적이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Slice&lt;/strong&gt;: 각 Chunk는 하나 또는 여러 Slice로 이루어진다. Slice는 각 쓰기마다 생성되어 동일한 Chunk에 겹쳐질 수 있다. Chunk를 읽을 때는 최신 Slice를 우선해 읽는다. 다만, Slice가 많아지면 읽기 성능이 저하되므로 주기적으로 Slice를 하나로 병합한다. 이로써 JuiceFS는 유연하게 파일을 변경할 수 있어, Object Storage가 데이터 수정이 어렵다는 단점을 보완한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Block&lt;/strong&gt;: 실제 저장소에는 Slice가 기본값 4MB(16MB까지 설정 가능) 단위의 Block으로 분리되어 저장된다. Chunk, Slice는 논리적인 개념이며 실제 저장소에서 확인할 수 있는 데이터는 Block이다. 작은 Block으로 나누고 동시에 처리함으로써 멀리 떨어져 느린 Object Storage의 단점을 보완한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/09.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://github.com/juicedata/juicefs"&gt;https://github.com/juicedata/juicefs&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;메타데이터 엔진에는 파일명, 파일 크기 등의 메타 데이터가 관리된다. 또한 파일과 실제 저장소에 저장된 데이터 간의 매핑 정보가 포함되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/10.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://github.com/juicedata/juicefs"&gt;https://github.com/juicedata/juicefs&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id=""&gt;캐싱&lt;/h4&gt;

&lt;p&gt;성능 향상을 위해 JuiceFS에는 여러 단계의 캐싱 레이어가 있다.&lt;/p&gt;

&lt;p&gt;읽기 요청 시 커널 페이지 캐시, 클라이언트 프로세스 캐시, 로컬 디스크 캐시로부터 읽기를 시도한 후, 없으면 저장소로부터 데이터를 읽어온다. 저장소로 읽어온 데이터는 비동기적으로 각 캐싱 레이어에 캐싱되고 이후 동일한 데이터는 빠르게 가져온다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/11.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://juicefs.com/docs/community/guide/cache"&gt;https://juicefs.com/docs/community/guide/cache&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2 id="alluxiojuicefs"&gt;Alluxio와 JuiceFS 비교&lt;/h2&gt;

&lt;p&gt;먼저 도입했던 Alluxio는 우리가 원하는 스토리지 요구 사항을 만족하지는 못했다. JuiceFS는 가능할까? 다음은 Alluxio와 JuiceFS를 비교한 표이다.&lt;/p&gt;

&lt;table&gt;  
&lt;thead&gt;  
  &lt;tr&gt;
    &lt;th&gt;기능&lt;/th&gt;
    &lt;th&gt;Alluxio&lt;/th&gt;
    &lt;th&gt;JuiceFS&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;  
&lt;tbody&gt;  
  &lt;tr&gt;
    &lt;td&gt;스토리지 형식&lt;/td&gt;
    &lt;td&gt;Object&lt;/td&gt;
    &lt;td&gt;Block&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;캐시 단위(granularity)&lt;/td&gt;
    &lt;td&gt;64 MiB&lt;/td&gt;
    &lt;td&gt;4 MiB&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;다층 캐시&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Hadoop 호환&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;S3 호환&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Kubernetes CSI Driver&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Hadoop 데이터 지역성&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;완전한 POSIX 호환&lt;/td&gt;
    &lt;td&gt;✕&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;원자적 메타데이터 작업&lt;/td&gt;
    &lt;td&gt;✕&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;강력한 일관성&lt;/td&gt;
    &lt;td&gt;✕&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;데이터 압축&lt;/td&gt;
    &lt;td&gt;✕&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;데이터 암호화&lt;/td&gt;
    &lt;td&gt;✕&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;부담 없는 운영&lt;/td&gt;
    &lt;td&gt;✕&lt;/td&gt;
    &lt;td&gt;✓&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;언어&lt;/td&gt;
    &lt;td&gt;Java&lt;/td&gt;
    &lt;td&gt;Go&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;오픈소스 라이선스&lt;/td&gt;
    &lt;td&gt;Apache License 2.0&lt;/td&gt;
    &lt;td&gt;Apache License 2.0&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;오픈소스화&lt;/td&gt;
    &lt;td&gt;2014년&lt;/td&gt;
    &lt;td&gt;2021년 1월&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://juicefs.com/docs/community/comparison/juicefs"&gt;https://juicefs.com/docs/community/comparison/juicefs&lt;/a&gt;&lt;em&gt;vs&lt;/em&gt;alluxio/&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;JuiceFS와 Alluxio 모두 다양한 인터페이스를 지원하며 캐싱에 의한 성능 개선이 가능하다.&lt;/p&gt;

&lt;p&gt;JuiceFS는 Alluxio와 비교해 다음과 같은 장점이 있다.&lt;/p&gt;

&lt;h3 id="posix"&gt;완전한 POSIX 호환&lt;/h3&gt;

&lt;p&gt;Alluxio는 일부 POSIX API를 지원하지 않지만 JuiceFS는 POSIX를 완벽하게 지원하므로 로컬 파일 시스템처럼 사용할 수 있다. JuiceFS에 저장된 학습 데이터, 코드를 변경하지 않고도 다양한 AI 오픈소스, 라이브러리를 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;다음은 POSIX 호환성 테스트인 &lt;a href="https://github.com/pjd/pjdfstest"&gt;pjdfstest&lt;/a&gt; 결과이다. &lt;a href="https://aws.amazon.com/ko/efs/"&gt;AWS EFS&lt;/a&gt;, &lt;a href="https://cloud.google.com/filestore"&gt;Google Filestore&lt;/a&gt;와 비교해도 POSIX를 더 잘 지원한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/12.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;출처: &lt;a href="https://juicefs.com/en/blog/engineering/posix-compatibility-comparison-among-four-file-system-on-the-cloud"&gt;https://juicefs.com/en/blog/engineering/posix-compatibility-comparison-among-four-file-system-on-the-cloud&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=""&gt;강력한 일관성&lt;/h3&gt;

&lt;p&gt;Alluxio가 원본 저장소를 미러링한 캐싱에 가까운 반면 JuiceFS는 독립적인 스토리지이다. JuiceFS의 경우 메타데이터는 메타데이터 엔진에서 관리하며 외부에 의존하지 않는다. 데이터 스토리지는 Block 데이터를 저장하는 용도로만 사용한다. 따라서 Alluxio처럼 원본 저장소와의 동기화 문제가 발생하지 않는다.&lt;/p&gt;

&lt;h3 id=""&gt;운영 부담 감소&lt;/h3&gt;

&lt;p&gt;Alluxio는 master, worker 서버를 구동하고 운영해야 한다는 부담이 있다. 또한 전체 사용자가 이를 공유하므로 Alluxio에 문제가 발생하면 전체 사용자에게 영향을 준다는 문제도 있다.&lt;/p&gt;

&lt;p&gt;JuiceFS는 기존의 익숙한 저장소, DB를 그대로 메타데이터 엔진, 데이터 스토리지로 구성할 수 있으며, JuiceFS 클라이언트만 있으면 별도의 서버 구동 없이 사용할 수 있다. 또한 각 사용자가 개별적으로 메타데이터 엔진, 데이터 스토리지를 마련해서 사용할 수 있으므로 서로 영향을 주지 않는다.&lt;/p&gt;

&lt;h2 id="juicefs"&gt;JuiceFS 구축 방안&lt;/h2&gt;

&lt;p&gt;JuiceFS를 사용하기 위해서는 메타데이터 엔진 역할의 DB와 데이터 스토리지 역할의 저장소를 마련해야 한다. 앞에서 설명한 대로, JuiceFS는 다양한 &lt;a href="https://juicefs.com/docs/community/databases_for_metadata/"&gt;DB&lt;/a&gt;와 &lt;a href="https://juicefs.com/docs/community/reference/how_to_set_up_object_storage#supported-object-storage"&gt;저장소&lt;/a&gt;를 지원한다. 직접 DB와 저장소를 별도로 구축해서 사용할 수도 있지만 운영 부담을 줄이려면 가능한 한 사내 플랫폼을 활용하는 방법이 좋다.&lt;/p&gt;

&lt;p&gt;AiSuite는 다음과 같이 사내 플랫폼을 통해 JuiceFS를 지원한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/13.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;JuiceFS로 기여한 내용을 포함해 구체적으로 검토한 내용을 설명하겠다.&lt;/p&gt;

&lt;h3 id=""&gt;메타데이터 엔진&lt;/h3&gt;

&lt;p&gt;네이버에서는 &lt;a href="https://d2.naver.com/helloworld/614607"&gt;nBase-ARC&lt;/a&gt; Redis 서비스를 사용하거나 MySQL을 지원받아 쉽게 메타데이터 엔진을 마련할 수 있다. 또는 개발, 테스트를 위해서 Redis, PostgreSQL 등을 &lt;a href="https://github.com/bitnami/charts"&gt;Helm chart&lt;/a&gt;로 직접 설치해 사용할 수도 있다.&lt;/p&gt;

&lt;p&gt;JuiceFS 기본적으로 메타데이터를 1시간 간격으로 데이터 스토리지에 자동 백업하며, 주기는 설정할 수 있다. 따라서 메타데이터 엔진의 데이터가 유실되어도 복구가 가능하나 메타데이터 백업 주기에 따라 일부는 유실될 수 있다. 자세한 내용은 &lt;a href="https://juicefs.com/docs/community/metadata_dump_load/#backup-automatically"&gt;Automatic backup&lt;/a&gt;을 참고하기 바란다.&lt;/p&gt;

&lt;h3 id=""&gt;데이터 스토리지&lt;/h3&gt;

&lt;p&gt;네이버에서는 HDFS , nubes Obejct Storage에 대규모 데이터를 저장할 수 있다. 이를 활용하면 대용량의 안정적인 데이터 스토리지를 마련할 수 있다.&lt;/p&gt;

&lt;h4 id="nubesobejctstorage"&gt;nubes Obejct Storage&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://deview.kr/2021/sessions/484"&gt;nubes&lt;/a&gt;는 네이버의 Object Storage이다. JuiceFS에서 지원하는 데이터 스토리지는 아니지만, &lt;a href="https://min.io"&gt;MinIO&lt;/a&gt; 인터페이스로 접근할 수 있는 nubes-s3-proxy를 통해 데이터 스토리지로 사용할 수 있다.&lt;/p&gt;

&lt;h4 id="hdfs"&gt;HDFS&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://juicefs.com/docs/community/reference/how_to_set_up_object_storage/#hdfs"&gt;HDFS&lt;/a&gt;는 JuiceFS에서 기본으로 지원하는 저장소이다. 하지만 Kerberos가 적용된 대규모의 multi-tenant HDFS를 사용하기 위해서는 다음과 같은 개선이 필요했다.&lt;/p&gt;

&lt;h5 id="kerberoskeytabhttpsgithubcomjuicedatajuicefsissues3283"&gt;Kerberos keytab 파일 지원(&lt;a href="https://github.com/juicedata/juicefs/issues/3283"&gt;https://github.com/juicedata/juicefs/issues/3283&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;네이버 사내의 HDFS에는 Kerberos가 적용되어 있다. 따라서 JuiceFS가 HDFS를 사용할 때 Kerberos 인증이 필요하다. 기존 JuiceFS는 HDFS 인증을 위해 &lt;a href="https://web.mit.edu/kerberos/krb5-1.12/doc/basic/ccache_def.html"&gt;credential cache&lt;/a&gt;를 &lt;code&gt;KRB5CCNAME&lt;/code&gt; 환경 변수로 설정했다. 하지만 이는 일정 시간이 지나면 만료되어 유효하지 않게 된다. 이를 해결하기 위해 credential cache 대신 &lt;code&gt;KRB5KEYTAB&lt;/code&gt;, &lt;code&gt;KRB5PRINCIPAL&lt;/code&gt; 환경 변수에 &lt;a href="https://web.mit.edu/kerberos/krb5-devel/doc/basic/keytab_def.html"&gt;keytab&lt;/a&gt;을 설정할 수 있도록 개선했다.&lt;/p&gt;

&lt;h5 id="base64keytabhttpsgithubcomjuicedatajuicefsissues3817"&gt;base64 인코딩된 keytab 지원(&lt;a href="https://github.com/juicedata/juicefs/issues/3817"&gt;https://github.com/juicedata/juicefs/issues/3817&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;AiSuite는 다수의 사용자가 공유하는 muti-tenant Kubernetes 클러스터로, 각자 원하는 메타데이터 엔진, 데이터 스토리지를 사용해 JuiceFS를 사용하도록 하는 것이 목표이다. 사용자는 직접 &lt;a href="https://juicefs.com/docs/csi/guide/pv/#community-edition"&gt;Kubernetes Secret&lt;/a&gt;을 작성해서 메타데이터 엔진, 데이터 스토리지로 접근할 수 있는 경로 및 인증 정보 등을 설정해야 한다. 하지만 &lt;code&gt;KRB5KEYTAB&lt;/code&gt;은 파일 경로일 뿐 사용자가 실제 자신의 keytab 파일을 전달할 수는 없었다. 이를 해결하기 위해 keytab 파일을 base64 인코딩한 문자열을 &lt;code&gt;KRB5KEYTAB_BASE64&lt;/code&gt; 환경 변수에 설정할 수 있도록 개선했다.&lt;/p&gt;

&lt;h5 id="hdfshttpsgithubcomjuicedatajuicefsissues3526"&gt;사용자별 HDFS 경로 설정 지원(&lt;a href="https://github.com/juicedata/juicefs/issues/3526"&gt;https://github.com/juicedata/juicefs/issues/3526&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;네이버 사내의 HDFS는 다수의 사용자가 공유하고 각자 할당된 HDFS 경로에만 권한이 부여된다. 하지만 기존의 JuiceFS는 데이터 저장을 위한 HDFS 경로를 지정할 수 없어 항상 root 하위에 데이터를 저장해야 했으며 그 결과 사용자는 권한이 없는 경로를 사용하는 문제가 생겼다. 이를 해결하기 위해 사용자별 HDFS 경로를 설정할 수 있도록 개선했다.&lt;/p&gt;

&lt;h5 id="hdfshdfsnameservicehttpsgithubcomjuicedatajuicefsissues3576"&gt;HDFS 경로 hdfs://nameservice 지원(&lt;a href="https://github.com/juicedata/juicefs/issues/3576"&gt;https://github.com/juicedata/juicefs/issues/3576&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;네이버 사내의 HDFS는 대규모 운영을 위해 &lt;a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/Federation.html"&gt;HDFS Federation&lt;/a&gt;으로 여러 네임노드와 네임스페이스로 이루어진다. 기존 JuiceFS는 &lt;code&gt;nn1.example.com:8020&lt;/code&gt;와 같이 네임노드 경로를 직접 명시해야 했는데, 사용자가 직접 이를 확인해서 설정하기는 불편했다. 이를 해결하기 위해 &lt;code&gt;hdfs://nameservice&lt;/code&gt;와 같이 네임스페이스를 설정할 수 있도록 개선했다.&lt;/p&gt;

&lt;h3 id="csidriver"&gt;CSI Driver&lt;/h3&gt;

&lt;p&gt;AiSuite는 muti-tenant Kubernetes 클러스터로, 각 사용자는 &lt;a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"&gt;Kubernetes namespace&lt;/a&gt;로 구분된다. 사용자 간 JuiceFS를 공유하면 서로 영향을 줄 수 있어 안정성이 떨어지고 운영이 어려워진다. 따라서 사용자가 각자 메타데이터 엔진, 데이터 스토리지를 마련하고 독립적으로 JuiceFS를 사용할 수 있도록 하는 것이 목표이다. 또한 관리자의 개입 없이 사용자가 직접 PVC(PersistentVolumeClaim)를 정의해 사용할 수 있도록 &lt;a href="https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/"&gt;Dynamic Volume Provisioning&lt;/a&gt;을 지원해야 운영 부담을 줄이고 사용자도 편리하게 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 위해 다음과 같은 개선이 필요했다.&lt;/p&gt;

&lt;h5 id="secrethttpsgithubcomjuicedatajuicefscsidriverissues698"&gt;템플릿 Secret 지원(&lt;a href="https://github.com/juicedata/juicefs-csi-driver/issues/698"&gt;https://github.com/juicedata/juicefs-csi-driver/issues/698&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;사용자는 &lt;a href="https://juicefs.com/docs/csi/guide/pv/#community-edition"&gt;Secret&lt;/a&gt;을 작성해서 각자 마련한 메타데이터 엔진, 데이터 스토리지로 접근할 수 있는 경로 및 인증 정보 등을 설정해야 한다. 그리고 이러한 Secret을 참조할 수 있도록 &lt;a href="https://kubernetes.io/docs/concepts/storage/storage-classes/"&gt;StorageClass&lt;/a&gt;에 설정해야 한다. 설정한 Secret은 Dynamic Volume Provisioning에 사용된다.&lt;/p&gt;

&lt;p&gt;하지만 기존의 JuiceFS CSI Driver는 StorageClass에 하나의 고정된 Secret만 설정할 수 있었다. 이를 해결하기 위해 &lt;code&gt;${pvc.name}&lt;/code&gt;, &lt;code&gt;${pvc.namespace}&lt;/code&gt;, &lt;code&gt;${pvc.annotations['&amp;lt;annotation&amp;gt;']}&lt;/code&gt;와 같이 사용자가 생성한 PVC에서 Secret을 참조할 수 있도록 개선했다.&lt;/p&gt;

&lt;h5 id="secretfinalizerhttpsgithubcomjuicedatajuicefscsidriverissues707"&gt;Secret Finalizer 지원(&lt;a href="https://github.com/juicedata/juicefs-csi-driver/issues/707"&gt;https://github.com/juicedata/juicefs-csi-driver/issues/707&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;사용자의 Secret은 PVC 생성뿐만 아니라 PVC 삭제 시에도 JuiceFS 데이터를 삭제하기 위해 사용된다. 만약 PVC를 삭제하기 전에 이와 연관된 Secret가 제거되면 JuiceFS 데이터는 정리되지 않고 계속 남아 있게 된다. 이러한 문제를 막기 위해 PVC가 삭제되기 전까지는 연관된 Secret 이 제거되지 않도록 &lt;a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/finalizers/"&gt;Finalizer&lt;/a&gt;를 설정했다. StorageClass의 &lt;a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource"&gt;&lt;code&gt;parameters&lt;/code&gt;&lt;/a&gt;에 &lt;code&gt;secretFinalizer: "true"&lt;/code&gt;를 설정하면 활성화된다.&lt;/p&gt;

&lt;h5 id="pvcmountoptionshttpsgithubcomjuicedatajuicefscsidriverissues758"&gt;PVC 메타데이터를 참조하는 mountOptions 설정 지원(&lt;a href="https://github.com/juicedata/juicefs-csi-driver/issues/758"&gt;https://github.com/juicedata/juicefs-csi-driver/issues/758&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;AiSuite는 AI 학습, 서빙, 데이터 처리 등의 다양한 AI 워크로드가 존재한다. 이에 따른 최적의 성능을 위해서는 작업에 따라 개별 JuiceFS 설정이 필요하다. 예를 들어, AI 학습을 위한 ReadOnly 데이터를 사용하는 경우 &lt;code&gt;--open-cache&lt;/code&gt; 설정을 추가해 읽기 성능을 높일 수 있다. 자세한 내용은 &lt;a href="https://juicefs.com/docs/community/guide/cache/#client-memory-metadata-cache"&gt;Metadata cache in client memory&lt;/a&gt;를 참고하기 바란다.&lt;/p&gt;

&lt;p&gt;기존의 JuiceFS는 StorageClass에 고정된 설정만 적용되었다. 이를 &lt;code&gt;${.PVC.namespace}&lt;/code&gt;, &lt;code&gt;${.PVC.name}&lt;/code&gt;, &lt;code&gt;${.PVC.labels.foo}&lt;/code&gt;, &lt;code&gt;${.PVC.annotations.bar}&lt;/code&gt;와 같이 사용자가 생성한 PVC를 참조할 수 있도록 개선했다.&lt;/p&gt;

&lt;h2 id="juicefs"&gt;JuiceFS 사용 방안&lt;/h2&gt;

&lt;p&gt;JuiceFS를 Kubernetes에서 지원하기 위해 관리자는 JuiceFS CSI Driver를 배포하며, 사용자는 각자 Secret, PVC를 정의해야 한다. multi-tenant Kubernetes인 AiSuite에서 어떻게 배포하고 제공하는지 자세한 예시와 함께 설명하겠다.&lt;/p&gt;

&lt;h3 id=""&gt;배포 방법&lt;/h3&gt;

&lt;p&gt;JuiceFS CSI Driver를 설치하면 표준적인 Kubernetes 볼륨 사용 방식에 따라 사용할 수 있으며 Helm, kubectl로 설치할 수 있도록 지원된다. 자세한 내용은 &lt;a href="https://juicefs.com/docs/csi/getting_started"&gt;JuiceFS CSI Driver Installation&lt;/a&gt;을 참고하기 바란다. 배포에는 Kubernetes 관리자 권한이 요구된다.&lt;/p&gt;

&lt;p&gt;사용자마다 각자 자신의 메타데이터 엔진, 데이터 스토리지를 사용하도록 StorageClass는 아래와 같이 설정했다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-yaml"&gt;apiVersion: storage.k8s.io/v1  
kind: StorageClass  
metadata:  
  name: juicefs
provisioner: csi.juicefs.com  
parameters:  
  # 사용자가 각자 생성한 Secret을 참조할 수 있도록 설정한다.
  # 사용자는 PVC의 'csi.juicefs.com/secret-name' annotations에 Secret명을 설정해야 한다.
  csi.storage.k8s.io/provisioner-secret-name: ${pvc.annotations['csi.juicefs.com/secret-name']}
  csi.storage.k8s.io/provisioner-secret-namespace: ${pvc.namespace}
  csi.storage.k8s.io/node-publish-secret-name: ${pvc.annotations['csi.juicefs.com/secret-name']}
  csi.storage.k8s.io/node-publish-secret-namespace: ${pvc.namespace}
  csi.storage.k8s.io/controller-expand-secret-name: ${pvc.annotations['csi.juicefs.com/secret-name']}
  csi.storage.k8s.io/controller-expand-secret-namespace: ${pvc.namespace}
  juicefs/clean-cache: "true"
  # secretFinalizer를 활성화하여, 사용자가 정의한 Secret이 임의로 삭제되지 않도록 한다.
  secretFinalizer: "true"
  # pathPattern으로 경로를 지정하면 원하는 경로를 마운트할 수 있다.
  # 사용자는 PVC의 'csi.juicefs.com/subdir' annotations에 원하는 경로를 설정할 수 있다.
  pathPattern: "${.PVC.annotations.csi.juicefs.com/subdir}"
allowVolumeExpansion: true  
reclaimPolicy: Delete  
mountOptions:  
  # 필요한 옵션을 각자 설정할 수 있도록 한다.
  # 사용자는 PVC의 'csi.juicefs.com/additional-mount-options' annotations에 필요한 JuiceFS 옵션을 설정할 수 있다.
  - ${.PVC.annotations.csi.juicefs.com/additional-mount-options}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=""&gt;사용 방법&lt;/h3&gt;

&lt;p&gt;사용자는 각자 마련된 메타데이터 엔진, 데이터 스토리지에 대한 경로 및 인증 정보 등을 Secret으로 생성해야 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-yaml"&gt;apiVersion: v1  
kind: Secret  
metadata:  
  name: myjfs
type: Opaque  
stringData:  
  # JuiceFS 파일 시스템 이름
  name: myjfs
  # MINIO_ROOT_USER
  access-key: user
  # MINIO_ROOT_PASSWORD
  secret-key: password
  # 메타데이터 엔진 역할의 Redis 경로
  metaurl: redis://:@redis.user1.svc.cluster.local:6379/0
  # minio
  storage: minio
  # bucket1
  bucket: http://nubes-s3-proxy.user1.svc.cluster.local:10000/bucket1
  # https://juicefs.com/docs/community/command_reference/#format
  format-options: trash-days=0,block-size=16384
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PVC를 정의한다. 추가로 다음과 같은 annotation을 설정해야 한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;csi.juicefs.com/secret-name&lt;/code&gt;: 참조되는 Secret명을 명시한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;csi.juicefs.com/subdir&lt;/code&gt;:  새로운 볼륨이라면 PVC명을 명시한다. 기존의 JuiceFS 경로를 마운트해야 한다면 원하는 경로를 지정할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;csi.juicefs.com/additional-mount-options&lt;/code&gt;: 워크로드에 맞는 JuiceFS 마운트 옵션을 설정을 추가할 수 있다. 자세한 내용은 &lt;a href="https://juicefs.com/docs/community/command_reference/#mount"&gt;mount&lt;/a&gt;를 참고하기 바란다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class="language-yaml"&gt;apiVersion: v1  
kind: PersistentVolumeClaim  
metadata:  
  name: myjfs
  annotations:
    csi.juicefs.com/secret-name: myjfs # 앞에서 생성한 Secret 이름
    csi.juicefs.com/subdir: myjfs # juicefs 파일 시스템에서의 경로
    csi.juicefs.com/additional-mount-options: "writeback,upload-delay=1m" # 필요하다면 JuiceFS 설정을 추가한다
spec:  
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 100Gi
  storageClassName: juicefs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Secret, PVC를 생성하면 일반적인 볼륨 사용 방식과 동일하게 사용할 수 있다. 다음은 위에서 생성한 &lt;code&gt;myjfs&lt;/code&gt; PVC를 &lt;code&gt;/data&lt;/code&gt;에 마운트하는 Pod의 예시이다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-yaml"&gt;apiVersion: v1  
kind: Pod  
metadata:  
  name: example
spec:  
  containers:
  - name: app
...
    volumeMounts:
    - mountPath: /data
      name: juicefs-pv
  volumes:
  - name: juicefs-pv
    persistentVolumeClaim:
      claimName: myjfs
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=""&gt;성능 테스트&lt;/h2&gt;

&lt;p&gt;JuiceFS &lt;a href="https://juicefs.com/docs/community/benchmark/#throughput"&gt;Performance Benchmark&lt;/a&gt;는 다음과 같이 &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt;, &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt;와 비교해 성능이 높다고 소개하고 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/14.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;하지만 EFS, S3FS가 아닌 nubes Object Storage, HDFS를 데이터 스토리지로 사용한 경우의 성능 확인이 필요하다.&lt;/p&gt;

&lt;p&gt;JuiceFS의 성능은 어떤 저장소를 데이터 스토리지로 사용하는지에 따라 다를 것이다. 또한 JuiceFS Fuse로 인한 성능 저하도 확인이 필요하다. Fuse는 UserSpace를 거치므로 성능 저하가 발생할 수 있다.&lt;/p&gt;

&lt;p&gt;테스트의 목적은 데이터 스토리지를 직접 사용한 경우와 비교했을 때 성능 저하가 있는지 확인하는 것이다. 큰 차이가 없다면 성능 저하 없이 POSIX 호환, 동시 접근 등의 다양한 기능을 지원할 수 있다.&lt;/p&gt;

&lt;h3 id=""&gt;순차적 읽기/쓰기&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://juicefs.com/docs/community/performance_evaluation_guide/#fio-standalone-performance-test"&gt;Fio Standalone Performance Test&lt;/a&gt;를 참고해 다음과 같이 테스트를 수행했다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;메타데이터 엔진으로는 Redis를 사용했다.&lt;/li&gt;
&lt;li&gt;단일 노드에서 &lt;a href="https://github.com/axboe/fio"&gt;fio&lt;/a&gt;를 사용해 &lt;code&gt;--numjobs&lt;/code&gt; 옵션을 조정하면서 테스트했다.&lt;/li&gt;
&lt;li&gt;단일 노드의 최대 네트워크 대역폭은 1200MB/s이다. 즉, 이 테스트에서 가능한 최대 수치이다.&lt;/li&gt;
&lt;li&gt;기본적으로 Object Storage는 POSIX를 지원하지 않는다. 따라서 &lt;a href="https://github.com/axboe/fio"&gt;fio&lt;/a&gt;가 아닌 nubes Object Storage 성능에 최적화된 다른 방법으로 &lt;code&gt;read(1 job)&lt;/code&gt;, &lt;code&gt;write(1 job)&lt;/code&gt; 항목만 측정했다.&lt;/li&gt;
&lt;li&gt;JuiceFS 설정에서 Block 크기만 16MB로 설정하고 그 외의 옵션은 기본값을 사용했다.&lt;/li&gt;
&lt;li&gt;JuiceFS 캐싱은 고려하지 않았다. 즉, 새로운 데이터를 읽고 쓰는 테스트만 진행했다.&lt;/li&gt;
&lt;li&gt;Alluxio의 경우 fio 실행 시 &lt;code&gt;fio: posix_fallocate fails: Not supported&lt;/code&gt;와 같이 실패하여 테스트에서 제외했다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/15.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;결과는 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;읽기의 경우 nubes에 비해 juicefs+nubes, juicefs+hdfs의 성능이 좋으며 동시 수행 개수에 비례해서 증가한다. Chunk로 인해 동시 읽기에 유리하기 때문으로 보인다.&lt;/li&gt;
&lt;li&gt;쓰기의 경우 nubes에 비해 juicefs+nubes, juicefs+hdfs가 비슷하거나 낮다. 동시 수행 개수가 늘어나면 저하된다. 다수의 Slice로 인한 부담으로 추측된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;파일 생성&lt;/h3&gt;

&lt;p&gt;이번에는 1만 개의 작은 파일들을 생성했을 때의 시간을 비교했다. 데이터 스토리지로 사용하는 nubes가 메타데이터를 다루는 본연의 성능을 측정하고, JuiceFS와 비교한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;메타데이터 엔진으로는 Redis를 사용했다.&lt;/li&gt;
&lt;li&gt;100바이트 파일 1만 개를 10개의 프로세스에서 &lt;code&gt;cp&lt;/code&gt; 명령으로 복사했을 때 초당 파일 생성 수를 측정했다.&lt;/li&gt;
&lt;li&gt;기본적으로 Object Storage는 POSIX를 지원하지 않는다. 따라서 &lt;code&gt;cp&lt;/code&gt;가 아닌 nubes Object Storage 성능에 최적화된 다른 방법으로 nubes 항목을 측정했다.&lt;/li&gt;
&lt;li&gt;JuiceFS의 &lt;code&gt;writeback&lt;/code&gt; 옵션을 설정한 경우도 측정했다. 이 옵션은 우선 로컬에만 반영되며, 이후 비동기적으로 데이터 스토리지에 저장된다. 자세한 설명은 &lt;a href="https://juicefs.com/docs/cloud/guide/cache/#client-write-cache"&gt;client-write-cache&lt;/a&gt;를 참고하기 바란다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/16.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;결과는 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nubes와 juicefs+nubes는 큰 차이가 없었다. 즉, nubes에 데이터 스토리지로 JuiceFS를 사용해도 성능 저하는 없다.&lt;/li&gt;
&lt;li&gt;HDFS와 연동하는 juicefs+hdfs와 alluxio는 HDFS의 메타데이터를 다루는 네임노드의 성능에 수렴하는 것으로 보인다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;writeback&lt;/code&gt; 옵션을 사용하면 수십 배의 성능 향상이 있다. 하지만 &lt;code&gt;writeback&lt;/code&gt; 옵션을 활성화하면 데이터 유실의 가능성이 생기므로, 임시적인 데이터를 위한 용도에 적합하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;결론&lt;/h3&gt;

&lt;p&gt;JuiceFS의 성능은 기본적으로는 데이터 스토리지로 사용하는 저장소의 성능에 수렴한다. 성능 저하 없이 POSIX 호환, 동시 접근 등의 다양한 기능을 지원한다. 또한, 워크로드나 사용 방식에 따라서는 데이터 스토리지 저장소 본연의 성능보다 좋을 수도 있다. 여기에서는 테스트하지 못했지만, 캐싱된 데이터를 읽는 경우에는 로컬 디스크로부터 읽게 되므로 성능 개선이 가능하다. 또는 임시 데이터를 쓰는 경우에는 &lt;code&gt;writeback&lt;/code&gt; 옵션을 적용해 성능을 향상시킬 수도 있다.&lt;/p&gt;

&lt;p&gt;JuiceFS는 워크로드에 따라 적용해볼 수 있는 다양한 캐싱 옵션을 지원한다. 자세한 내용은 &lt;a href="https://juicefs.com/docs/cloud/guide/cache/"&gt;cache&lt;/a&gt;를 참고하기 바란다.&lt;/p&gt;

&lt;h2 id=""&gt;정리&lt;/h2&gt;

&lt;h3 id="juicefs"&gt;사내 스토리지 + JuiceFS&lt;/h3&gt;

&lt;p&gt;AiSuite에서는 사내에서 지원하는 HDFS, nubes Object Storage를 활용해 JuiceFS를 구축했다. 이로써 AI 워크로드에 적합한 스토리지를 제공하면서 운영 부담도 줄일 수 있었다. 앞에서 검토한 사내 스토리지를 다시 정리해보면 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/12/17.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;AiSuite에서는 HDFS보다는 nubes Object Storage를 데이터 스토리지로 사용하는 것을 권장한다. HDFS의 경우 파일 개수가 많으면 HDFS 메타데이터를 관리하는 네임노드에 부담이 되는데, JuiceFS는 파일을 작은 Block으로 나누어서 저장하므로 많은 파일이 HDFS에 생성된다. 최대 설정 가능한 Block 크기인 16MB이더라도 1TB 데이터 저장을 위해서는 62,500개 이상의 파일이 생성된다. 최대 Block 크기를 64MB로 상향할 수 있을지 검토했지만, Block이 커지면 비효율적으로 작동한다. 자세한 내용은 &lt;a href="https://github.com/juicedata/juicefs/discussions/3451"&gt;Increase the maximum of blockSize to 64MB&lt;/a&gt;을 참고하기 바란다.&lt;/p&gt;

&lt;h3 id=""&gt;활용 이점&lt;/h3&gt;

&lt;p&gt;AI 플랫폼인 AiSuite에서는 AI 워크로드에 적합한 스토리지로 JuiceFS를 검토했다. JuiceFS는 공유 가능한 Kubernetes 영구 볼륨으로, 다음과 같은 다양한 활용 이점이 있다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;대용량의 공유 가능한(ReadWriteMany, ReadOnlyMany) 볼륨 사용이 가능하다.&lt;/li&gt;
&lt;li&gt;고성능(캐싱 효과)으로 hostPath, local-path를 대체할 수 있다. Stateful 앱의 클라우드 네이티브 전환을 쉽게 할 수 있다.&lt;/li&gt;
&lt;li&gt;AI 분산 학습 시 공유 가능한 워크스페이스, 체크포인트, 로그 저장소로 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;AI 학습 시 요구되는 수많은 작은 파일을 다룰 수 있다(HDFS/Alluxio의 대안).&lt;/li&gt;
&lt;li&gt;HDFS, nubes Object Storage 사내 저장소를 활용할 수 있으므로 운영 부담이 적다.&lt;/li&gt;
&lt;li&gt;사용자별 데이터 스토리지, 메타데이터 엔진 구동으로 서로 영향을 주지 않는다.&lt;/li&gt;
&lt;li&gt;다양한 데이터 스토리지, 메타데이터 엔진을 지원하여 대부분의 k8s 환경에 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;고비용의 공유 스토리지 &lt;a href="https://aws.amazon.com/ko/efs/"&gt;AWS EFS&lt;/a&gt;, &lt;a href="https://cloud.google.com/filestore"&gt;Google filestore&lt;/a&gt;, &lt;a href="https://www.ddn.com/products/lustre-file-system-exascaler"&gt;DDN exascaler&lt;/a&gt;를 대체할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;마치며&lt;/h3&gt;

&lt;p&gt;지금까지 JuiceFS를 소개하고 네이버에서 어떻게 적용했는지 설명했다. JuiceFS를 활용해 기존의 레거시 스토리지를 고성능의 다양한 기능을 갖춘 AI 워크로드에 적합한 스토리지로 전환할 수 있었다.&lt;/p&gt;

&lt;p&gt;JuiceFS는 &lt;a href="https://juicefs.com/docs/community/reference/how_to_set_up_object_storage#supported-object-storage"&gt;다양한 저장소&lt;/a&gt;와 &lt;a href="https://juicefs.com/docs/community/databases_for_metadata"&gt;다양한 DB&lt;/a&gt;를 지원한다. 이 글에서는 네이버 사내 on-premise 환경의 적용 사례를 설명했지만, AWS, Google Cloud 등의 Public Cloud 환경에서도 적용해볼 수 있다.&lt;/p&gt;

&lt;p&gt;비슷한 고민을 하는 분들에게 도움이 되었으면 한다.&lt;/p&gt;

&lt;p&gt;&lt;br&gt; &lt;br /&gt;
&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>One-Source Multi-Use, 스마트플레이스 일본 진출 작업기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/0983091" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/0983091</id>
    <updated>2023-12-12T12:54:35Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(10월)에서 발표되었던 세션을 공개합니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/_r8Ug43AJN0?si=pc4_PQ2aGFEQ_mD8" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;스마트플레이스 서비스 소개&lt;/li&gt;
&lt;li&gt;One-source Multi-use를 위한 디자인패턴&lt;/li&gt;
&lt;li&gt;One-source Multi-use를 위한 분기
&lt;ul&gt;&lt;li&gt;국가분기 유틸&lt;/li&gt;
&lt;li&gt;파일 구조&lt;/li&gt;
&lt;li&gt;공용 컴포넌트에 국가특화로직 넣기&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;국가별 번역적용 (Airport &amp;amp; LS Manager)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 1년에 3번씩 열리고 있는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY 2023의 그 마지막 영상을 공개합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>FE News 12월 소식</title>
    <link rel="alternate" href="https://d2.naver.com/news/1632281" />
    <category term="news" />
    <id>https://d2.naver.com/news/1632281</id>
    <updated>2023-12-06T14:23:50Z</updated>
    <content type="html">&lt;p&gt;&lt;img src="/content/images/2023/12/-----------2023-07-06------4-16-49-1--1-.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id="12"&gt;&lt;strong&gt;[12월 주요내용]&lt;/strong&gt;&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;2023년도 개발자 에코시스템 현황&lt;/li&gt;
&lt;li&gt;Declarative UI 생각하기&lt;/li&gt;
&lt;li&gt;KLED: 한국어를 지원하는 퍼지 검색 라이브러리&lt;/li&gt;
&lt;li&gt;MOBX + STANDARD DECORATORS&lt;/li&gt;
&lt;li&gt;UI Design Tips&lt;/li&gt;
&lt;li&gt;OpenNext&lt;/li&gt;
&lt;li&gt;performance.now() 2023&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;등 그외 다양하고 알찬 내용들을 모았습니다.
&lt;br/&gt;&lt;/p&gt;

&lt;h2 id="fenews12httpsgithubcomnaverfenewsblobmasterissues202312md"&gt;&lt;strong&gt;&lt;a href="https://github.com/naver/fe-news/blob/master/issues/2023-12.md"&gt;&gt;&gt; FE News 12월 보러가기&lt;/a&gt;&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="fenewsbr"&gt;&lt;strong&gt;◎ FE News란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;네이버 FE 엔지니어들이 엄선한 양질의 FE 및 주요한 기술 소식들을 큐레이션해 공유하는 것을 목표로 하며, 이를 통해 국내 개발자들에게 지식 공유에 대한 가치 인식과 성장에 도움을 주고자 하는 기술소식 공유 프로젝트 입니다.&lt;/p&gt;
  
  &lt;p&gt;매월 첫째 주 수요일, 월 1회 발행 되고 있으니 많은 관심 부탁드립니다.&lt;br/&gt;
  ▷ &lt;a href="https://fenews.substack.com/embed"&gt;구독하기&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>중요한 것은 사용자의 의도를 꺾지 않으려는 마음 (동시편집에서 Text.Style Operation 개선 및 Multi User Undo/Redo 구현하기)</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/6014816" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/6014816</id>
    <updated>2023-12-05T11:02:00Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(10월)에서 발표되었던 세션을 공개합니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/CZxHd1rjJHg?si=7ud5YqJG26-0GxTL" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;li&gt;Text.Style Operation 개선하기
&lt;ul&gt;&lt;li&gt;사용자의 의도를 보존하는 정책 정의&lt;/li&gt;
&lt;li&gt;Yorkie 기존 동작 방식&lt;/li&gt;
&lt;li&gt;Peritext 알고리즘 소개&lt;/li&gt;
&lt;li&gt;Text.Style Operation 개선 적용&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Multi User Undo/Redo 구현하기
&lt;ul&gt;&lt;li&gt;사용자의 의도를 보존하는 Undo/Redo 정의&lt;/li&gt;
&lt;li&gt;Local Undo, Global Redo 구현&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;마무리&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 1년에 3번씩 열리고 있는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY 2023의 일부 세션을 7주에 걸쳐 공개할 예정으로 그 여섯 번째 세션 영상을 공개합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>거기 말고 이 호텔 어때? - 호텔 서비스 추천 시스템 도입기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/2184045" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/2184045</id>
    <updated>2023-12-12T12:54:58Z</updated>
    <content type="html">&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/LB-CU3e1wUM?si=kWIDQQ69WuVQ3DGJ" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;  

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;추천 시스템에 대한 글은 많지만, 이를 실제 서비스에 적용하기는 어렵지 않으셨나요? 이 글에서는 추천에 대한 개념 설명에서 시작하여, 추천이 이루어지는 과정, 네이버 호텔 서비스 내에서 머신 러닝을 사용하여 연관 호텔 추천 서비스를 도입한 과정을 말씀드리겠습니다.&lt;/p&gt;

&lt;h2 id=""&gt;작업 배경&lt;/h2&gt;

&lt;p&gt;기존에도 모델링 팀으로부터 받는 개인화 추천 결과는 있었다. 하지만 흔히 쇼핑몰에서 볼 수 있는, 이 상품과 유사한 상품(item to item)을 노출할 수 있는 추천 알고리즘이 필요했다. 또한 호텔 도메인에 보다 적합한 추천 서비스를 직접 개발할 필요가 있었다.&lt;/p&gt;

&lt;h2 id=""&gt;협업 필터링&lt;/h2&gt;

&lt;p&gt;추천에 관심이 있다면 협업 필터링(collaborative filtering, CF)이란 알고리즘에 대해 들어보았을 것이다. 사용자의 선호도 데이터를 취합해서 관심사를 예측해 아이템을 추천하는 방법이다. 단, 사용자의 취향이 과거,현재, 미래에 크게 변하지 않는다는 전제 조건이 필요하다. 즉, 이미 존재하는 데이터를 기반으로 유사도를 계산하기 때문에, 독특한 취향의 고객, 신규 고객의 경우 추천이 어렵다는 단점이 있다.&lt;/p&gt;

&lt;p&gt;그림1에 A, B, C, D 사용자가 있다. A는 글래드 여의도, L7 홍대 호텔을 선호한다. B는 글래드 여의도, 서울신라호텔, L7 홍대 호텔, C는 L7 홍대, D는 신주쿠 워싱턴 호텔 도쿄를 선호한다. 이를 아이템이 행에 오도록 벡터화해 표로 나타내면 그림2와 같다(user based의 경우에는 사용자가 행).&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/04-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;글래드 여의도 호텔(1 1 0 0)과 유사한 호텔은 서울신라호텔(0 1 0 0)과 L7 홍대(1 1 1 0)임을 알 수 있다.&lt;/p&gt;

&lt;h2 id=""&gt;협업 필터링의 종류&lt;/h2&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/05-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;협업 필터링은 모델 기반, 메모리 기반으로 나눌 수 있다. 데이터가 많아 메모리 기반으로 처리하기 어려울 때 모델 기반을 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;모델 기반 협업 필터링은 사용할 피드백 데이터에 따라 나눌 수 있다. 피드백의 종류에는 명시적 피드백(explicit feedback)과 암시적 피드백(implicit feedback)이 있다. 명시적 피드백은 사용자의 직접적인 액션인 좋아요/싫어요, 암시적 피드백은 클릭, 찜하기와 같은 사용자의 간접적인 액션을 의미한다. 암시적 피드백의 경우에는 사용자가 실수로 누른 경우도 있고 뚜렷한 불호의 성격이 없기 때문에 데이터에 잡음이 있다.&lt;/p&gt;

&lt;p&gt;암시적 피드백을 사용하는 잠재 요인(latent factor) 모델에는 행렬 분해(matrix factorization)가 있으며, 행렬 분해를 최적화하기 위한 알고리즘으로는 ALS(alternating least squares), SGD(stochastic gradient descent, 확률적 경사하강법)이 있다.&lt;/p&gt;

&lt;p&gt;호텔 데이터는 1주일 기준으로 사용자 76만 명, 호텔 수 6만 개 정도의 큰 데이터 였고 사용자의 클릭과 예약 로그를 사용했기 때문에 잠재 요인 모델을 사용했으며, SGD로 최적화하기에는 &lt;a href="https://inst.eecs.berkeley.edu/~ee127/sp21/livebook/l_ncp_main.html"&gt;Non-Convex Problems&lt;/a&gt;에 해당해 학습 속도가 떨어지므로 ALS를 선택했다.&lt;/p&gt;

&lt;h2 id=""&gt;행렬 분해&lt;/h2&gt;

&lt;p&gt;메모리 기반 협업 필터링은 그림2와 같은 행렬을 메모리에 두고 유사도를 계산해야 한다. 또한, 평가하지 않은 아이템에 대해서는 선호도가 없고, 아이템과 사용자 수가 많아지면 추천 속도가 느려지고, 데이터의 sparsity 현상으로 제대로 된 추천을 할 수 없다는 단점이 있다. 이러한 단점을 보완하기 위해 AI 학습으로 행렬을 생성하는 방법이 행렬 분해다.&lt;/p&gt;

&lt;p&gt;행렬 분해는 하나의 행렬을 보다 단순한 행렬의 곱으로 표현하는 기법이다. 행렬을 잠재 요인 차원으로 분해하고, 행렬 내적합 결과와 실제 결과를 비교하면서 학습시킴으로써, 사용자가 선택하지 않은 아이템에 대해서 평점을 예측하고 행렬을 생성한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/06-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;그림4에서는 잠재 요인 차원 수를 2로 지정하여 4X4 행렬을 4X2, 2X4 행렬로 분해한다. 분해한 행렬의 P, Q에 초기에는 아주 작은 랜덤 값을 설정한다. 행렬의 실제 값 $$$r_{ui}$$$를 내적합으로 구한 값 $$$x_{u}^{t}\times y_{i}$$$와 비교하여 손실을 계산한다.&lt;/p&gt;

&lt;h3 id=""&gt;손실 함수&lt;/h3&gt;

&lt;p&gt;예측 평점의 오차를 최대한 작게 하는 손실 함수(loss function)는 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/09-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;단, 암시적 피드백의 경우 &lt;a href="http://yifanhu.net/PUB/cf.pdf"&gt;논문&lt;/a&gt;을 참고하면 손실 함수를 다음과 같이 수정해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/10-1.png" alt="image" /&gt;&lt;/p&gt;

&lt;p&gt;P는 실제 평점을 의미한다. C는 신뢰도 값으로, 원래는 평점이 남아있지 않으면 0으로 설정하지만, 여기서는 실제로는 선호하지만 평점이 없는 데이터일 수 있기 때문에 손실 함수에 추가했다.&lt;/p&gt;

&lt;p&gt;$$$\lambda$$$는 정규화(regularization) 파라미터 값으로, 가중치가 한쪽으로 쏠리지 않게 한다.&lt;/p&gt;

&lt;h3 id=""&gt;최적화&lt;/h3&gt;

&lt;p&gt;두 개의 행렬 X와 Y의 내적으로 이루어지기 때문에 SGD의 경우 앞서 말했듯이 non-convex 문제가 된다. 그래서 X와 Y를 한 번에 최적화하지 않고 둘 중 하나를 상수 취급함으로써 convex 문제로 변환하는데, 이를 &lt;strong&gt;ALS(alternating least squares)&lt;/strong&gt;라고 한다.&lt;/p&gt;

&lt;p&gt;Y를 상수로 두고 수식2를 미분하면 다음과 같은 식을 얻는다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/12-1.png" alt="image" /&gt;&lt;/p&gt;

&lt;p&gt;좌변이 0일 때 최소가 되므로 좌변을 0으로 두고 계산하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/13-1.png" alt="image" /&gt;&lt;/p&gt;

&lt;p&gt;반대로 X를 상수로 두고 계산하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/14-1.png" alt="image" /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 얻은 최적화 함수를 번갈아가면서 학습시키는 것이 ALS 알고리즘이다. 두 개로 분리해서 계산하므로 병렬 처리가 가능해 시간 측면에서 이점이 있다. 또한, 수정한 손실 함수가 암시적 피드백에 기존보다 적합하다.&lt;/p&gt;

&lt;p&gt;여기서 학습에 사용하는 파라미터를 정리하면 다음과 같다. 이 파라미터는 하이퍼 파라미터라 불리며, 학습할 데이터의 성격에 맞게 수정하는 작업이 필요하다.&lt;/p&gt;

&lt;table role="table"&gt;  
&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;파라미터&lt;/th&gt;  
&lt;th&gt;설명&lt;/th&gt;  
&lt;th&gt;기본 사용값&lt;/th&gt;  
&lt;/tr&gt;  
&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;Cui&lt;/td&gt;  
&lt;td&gt;1+αr: 신뢰도를 나타내는 변수. α 값만 변경 가능.&lt;/td&gt;  
&lt;td&gt;1.0&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;iteration&lt;/td&gt;  
&lt;td&gt;학습 반복 횟수.&lt;/td&gt;  
&lt;td&gt;20&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;latent factor&lt;/td&gt;  
&lt;td&gt;잠재 요인 차원 수.&lt;/td&gt;  
&lt;td&gt;100&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;regualization parameter&lt;/td&gt;  
&lt;td&gt;정규화 파라미터. 오버 피팅을 막기 위해 사용.&lt;/td&gt;  
&lt;td&gt;0.01&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;h3 id=""&gt;행렬 분해 효과&lt;/h3&gt;

&lt;p&gt;행렬 분해를 사용함으로써 병렬 처리로 속도를 향상시킬 수 있으며 저장 공간을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;다음 그림과 같이 기존의 방법으로는 2,000,000만큼의 저장 공간이 필요한 경우, latent factor 값이 100이면 300,000으로 저장 공간을 줄일 수 있다. 즉, 기존 대비 6~7배 가량 이득을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/15-1.png" alt="" /&gt;&lt;/p&gt;

&lt;h2 id=""&gt;평가 지표&lt;/h2&gt;

&lt;p&gt;추천 시스템의 평가 지표에는 오프라인 지표와 온라인 지표가 있으며, 오프라인 지표는 크게 ranking과 prediction으로 나눌 수 있다. ranking은 추천 결과가 실제 결과와 얼마나 유사한지 알 수 있는 지표이며, prediction은 행렬 분해를 통해 예측한 평점과 실제 평점을 비교한 지표이다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ranking: Precision@K, AP@K, MAP@K, Recall@K 등&lt;/li&gt;
&lt;li&gt;prediction : MAE, RMSE&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="precisionk"&gt;Precision@K&lt;/h3&gt;

&lt;p&gt;Precision@K는 추천 시스템이 추천한 K개의 아이템 중에서 사용자가 선호한 아이템의 비율을 의미한다.&lt;/p&gt;

&lt;p&gt;다음 그림에서 추천 시스템에게 5개의 아이템을 추천받았고, 사용자는 추천받은 아이템 A, B, C, D, E 중에서 A, B, D를 선호했다. 이 경우 Precision@5 값은 0.6이다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/16-1.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id="apkaverageprecisionatk"&gt;AP@K(average precision at K)&lt;/h3&gt;

&lt;p&gt;AP@K는 앞에서 설명한 Precision@K와 달리, 사용자가 선호한 아이템을 몇 번째로 추천했는지가 지표에 반영된다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/17-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;rel(i)는 i번째로 추천한 아이템을 사용자가 선호했는지 여부를 0 또는 1로 나타내며, Precision@i에 이 값을 곱함으로써 해당 순위에만 영향을 준다. m은 사용자가 선호한 아이템의 개수를 나타낸다.&lt;/p&gt;

&lt;p&gt;사용자가 선호한 아이템이 1개라고 가정했을 때, 똑같이 3개의 아이템을 추천했어도 사용자가 선호한 아이템을 첫 번째로 추천한 경우에, 두 번째나 세 번째로 추천한 경우보다 AP 점수가 높아진다.&lt;/p&gt;

&lt;h3 id="mapkmeanaverageprecisionatk"&gt;MAP@K(mean average precision at K)&lt;/h3&gt;

&lt;p&gt;MAP@K는 AP@K의 평균을 의미한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/18-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 각 사용자의 AP@3 값은 각각 0.5, 0.16이며, 이 둘의 평균인 MAP@3 값은 0.33이다. 사용자가 선호하는 아이템을 더 높은 순위로 추천했을 때 MAP 점수가 높아진다.&lt;/p&gt;

&lt;h3 id="maemeanabsoluteerror"&gt;MAE(mean absolute error)&lt;/h3&gt;

&lt;p&gt;MAE는 실제 평점과 예측 평점 간 절대 오차의 평균이다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/19-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;MAE는 직관적이고 해석이 용이하지만 오차가 큰 이상치에 쉽게 영향을 받는다는 단점이 있다.&lt;/p&gt;

&lt;h3 id="rmserootmeansquareerror"&gt;RMSE(root mean square error)&lt;/h3&gt;

&lt;p&gt;MSE(mean sqaured error)는 오차 제곱의 평균으로, 제곱으로 인해서 단위가 커진다는 단점이 있다. 또한, 1 미만인 오차는 더 작아지고 그 이상의 오차는 더 커져 오차의 왜곡 현상이 발생한다.&lt;/p&gt;

&lt;p&gt;RMSE는 MSE의 제곱근으로, 실제 값과 단위가 유사해지고 오차의 왜곡 현상이 완화된다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/20-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;RMSE는 미분이 가능하다는 점에서 다른 머신러닝 학습에서도 많이 사용된다.&lt;/p&gt;

&lt;h2 id=""&gt;학습 데이터 수집 및 전처리&lt;/h2&gt;

&lt;p&gt;모델 선택과 학습에 앞서 사용할 데이터를 선택해야 한다. 방문 로그, 검색 로그, 구매 로그를 수집한 데이터를 사용했다. 각 로그마다 가중치를 부여하여 사용자의 선호도 점수를 계산했다.&lt;/p&gt;

&lt;h2 id=""&gt;모델 선택&lt;/h2&gt;

&lt;p&gt;GPU 인프라와 &lt;a href="https://www.kubeflow.org"&gt;Kubeflow&lt;/a&gt;를 지원하는 사내 플랫폼을 사용하고, Python으로 구현된 ALS 모델과 Apache Spark를 사용한 &lt;a href="https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html"&gt;ALS&lt;/a&gt; 라이브러리 두 가지를 비교해 어떤 것을 사용할지 결정하기로 했다.&lt;/p&gt;

&lt;p&gt;첫 번째 테스트에서는 학습 데이터 기간은 1주일, 테스트 데이터 기간은 1일로 설정했으며, 샘플링을 하지 않고 기간으로 구분했다(예: 2023-10-01~2023-10-08: train / 2023-10-09 :test). 평가 지표로는 Precision@K와 MAP@K를 사용했고 결과는 두 모델 모두 만족스럽지 못했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/21-2.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;데이터 기간이 너무 짧아 평가가 제대로 이루어지지 않았다고 판단하여, 데이터 기간을 2주로 증가시켜 테스트했다. 이때는 8:2 비율로 train set, test set을 구분하여 진행했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/22.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;Spark ALS의 경우 결과 값이 나오지 않았고, Python으로 구현된 모델의 경우 괜찮은 결과 값을 가져다 주었다. 뿐만 아니라 Spark ALS의 경우에는 GC가 발생하여 작업에 11시간이 소요된 반면, GPU 장비에서 동작한 모델은 5분 안에 학습이 완료되었다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/23.png" alt="image" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/24.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;해당 테스트 결과로, GPU 장비를 사용하여 ALS 알고리즘을 사용하고 학습에 필요한 파이프라인은 Kubeflow를 사용하는 방법을 선택했다.&lt;/p&gt;

&lt;h3 id=""&gt;모델 성능 향상&lt;/h3&gt;

&lt;p&gt;매일 학습하는 모델의 성능을 향상시키려면 ALS의 손실 함수에서 사용하는 하이퍼 파라미터 값을 최적화해야 한다. 이를 위해 Kubeflow에서 제공하는 Katib을 사용해 봤다. Katib은 Kubernetes 환경에서 AutoML을 지원하는 도구이며, &lt;a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization"&gt;Hyperparameter Tuning(HP)&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Neural_architecture_search"&gt;Neural Architecture Search(NAS)&lt;/a&gt; 등을 수행할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;자세한 설명은 &lt;a href="https://www.kubeflow.org/docs/components/katib/overview/"&gt;Katib 공식 문서&lt;/a&gt;를 참고한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;필자는 다음과 같이 설정하여 실행했다. 목표 값(objective)은 평가 지표인 precision, map 값으로 설정했고, 탐색 알고리즘(search algorithm)은 random으로 설정했다. 파라미터는 잠재 요인(factors), 반복 횟수(iteration), 정규화(regularization) 값을 사용했다. 메트릭 수집은 StdOut, File, Custom 중에서 설정 가능하며, 필자는 StdOut으로 설정했다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-yaml"&gt;apiVersion: kubeflow.org/v1beta1  
kind: Experiment  
metadata:  
  name: random-experiment-for-htl-als
  namespace: ''
spec:  
  maxTrialCount: 12
  parallelTrialCount: 3
  maxFailedTrialCount: 3
  resumePolicy: LongRunning
  objective:
    type: maximize
    goal: 0.7
    objectiveMetricName: precision
    additionalMetricNames:
      - map
    metricStrategies:
      - name: precision
        value: max
      - name: map
        value: max
  algorithm:
    algorithmName: random
    algorithmSettings: []
  parameters:
    - name: factors
      parameterType: int
      feasibleSpace:
        min: '200'
        max: '400'
        step: '100'
    - name: iteration
      parameterType: int
      feasibleSpace:
        min: '30'
        max: '40'
        step: '5'
    - name: regularization
      parameterType: discrete
      feasibleSpace:
        list:
          - '50'
          - '100'
          - '200'
          - '300'
  metricsCollectorSpec:
    collector:
      kind: StdOut
    source:
      filter:
        metricsFormat:
          - "([\\w|-]+)\\s*=\\s*((-?\\d+)(\\.\\d+)?)"
  trialTemplate:
    metadata:
      name: htl-als-katib
      namespace: kubeflow
    primaryContainerName: training-container
    successCondition: status.conditions.#(type=="Complete")#|#(status=="True")#
    failureCondition: status.conditions.#(type=="Failed")#|#(status=="True")#
    retain: false
    trialParameters:
      - name: factors
        reference: factors
        description: ''
      - name: regularization
        reference: regularization
        description: ''
      - name: iteration
        reference: iteration
        description: ''
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
            ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위 작업을 진행하여 다음과 같이 최적의 하이퍼 파라미터 값을 구했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/25.png" alt="" /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Best trial's params factors: 400 iteration: 35 regularization: 300&lt;/p&gt;
  
  &lt;p&gt;Best trial performance precision: 0.64528 map: 0.10847&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table role="table"&gt;  
&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;&lt;/th&gt;  
&lt;th&gt;기본 사용 값&lt;/th&gt;  
&lt;th&gt;Katib 사용 후&lt;/th&gt;  
&lt;/tr&gt;  
&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;iteration&lt;/td&gt;  
&lt;td&gt;20&lt;/td&gt;  
&lt;td&gt;35&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;factor&lt;/td&gt;  
&lt;td&gt;100&lt;/td&gt;  
&lt;td&gt;400&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;regualization&lt;/td&gt;  
&lt;td&gt;0.01&lt;/td&gt;  
&lt;td&gt;300&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;precision@1000&lt;/td&gt;  
&lt;td&gt;0.46&lt;/td&gt;  
&lt;td&gt;0.64528&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;map@1000&lt;/td&gt;  
&lt;td&gt;0.09&lt;/td&gt;  
&lt;td&gt;0.10847&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;h3 id=""&gt;서비스 적용&lt;/h3&gt;

&lt;p&gt;실제 서비스 적용 시 학습할 때와 동일하게 방문 로그, 검색 로그, 구매 로그를 사용했으며 각 로그마다 가중치를 부여하여 행렬을 생성한다. 최신성을 반영하기 위해 매일 모델을 학습시키며 최근 1달의 데이터를 사용한다. train set과 test set은 8:2 비율로 분리했으며, distinct 사용자 수와 호텔 수는 다음과 같다.&lt;/p&gt;

&lt;table role="table"&gt;  
&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;&amp;nbsp;&lt;/th&gt;  
&lt;th&gt;사용자 수&lt;/th&gt;  
&lt;th&gt;호텔 수&lt;/th&gt;  
&lt;/tr&gt;  
&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;train set&lt;/td&gt;  
&lt;td&gt;200만&lt;/td&gt;  
&lt;td&gt;9만&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;test set&lt;/td&gt;  
&lt;td&gt;100만&lt;/td&gt;  
&lt;td&gt;5만&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;total&lt;/td&gt;  
&lt;td&gt;250만&lt;/td&gt;  
&lt;td&gt;10만&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;p&gt;해당 데이터에 ALS 알고리즘을 적용하기 위해 Spark를 사용하여 데이터 전처리 작업을 진행한다. 전처리한 데이터는 HDFS에 업로드하고, Kubeflow 클러스터 내에서 해당 HDFS 경로 볼륨을 마운트하여 학습을 진행한다.&lt;/p&gt;

&lt;p&gt;Kubeflow에서 job operator를 사용해 아래의 작업을 실행한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-yaml"&gt;apiVersion: batch/v1  
kind: Job  
metadata:  
  name: htl-als-model
spec:  
  template:
    metadata:
      annotations:
        sidecar.istio.io/inject: 'false'
    spec:
      initContainers:
        - name: init-code
          image: alpine/git:latest
          command: [ "sh", "-c" ]
          args:
            - |
              cd /workspace
              sh pull_from_git.sh master
          volumeMounts:
            - mountPath: /workspace
              name: workspace
            - mountPath: /root/.ssh
              name: ssh-config
      containers:
        - name: train
          image: pull.reg.navercorp.com/vertical/hotel/kubeflow/htl-als-model:20230616
          resources:
            limits:
              memory: '8Gi'
              cpu: '4'
              nvidia.com/gpu: '1'
            requests:
              memory: '8Gi'
              cpu: '4'
              nvidia.com/gpu: '1'
          command: [ "sh", "-c" ]
          args:
            - |
              execution_date=$(date -d "1 day ago" +%Y-%m-%d)
              sh /workspace/train_model.sh $execution_date
          volumeMounts:
            - mountPath: /workspace
              name: workspace
            - mountPath: /htl-als-pvc
              name: htl-als-pvc
      restartPolicy: Never
      volumes:
        - name: htl-als-pvc
          persistentVolumeClaim:
            claimName: htl-als-pvc
        - name: workspace
          emptyDir: { }
        - name: ssh-config
          secret:
            secretName: ssh-config
            defaultMode: 0600
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;apiVersion: batch/v1&lt;/code&gt;: Kubernetes의 batch/v1 API를 사용한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kind: Job&lt;/code&gt;: Job의 작업으로 명시한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nvidia.com/gpu: '1'&lt;/code&gt;: GPU를 사용한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;htl-als-pvc&lt;/code&gt;: 해당 볼륨에는 전처리 데이터와 학습한 모델을 공유한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;매일 모델을 학습하고 Precision, MAP 평가를 진행하여 모델 성능을 평가한다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;100%|██████████| 35/35 [03:58&amp;lt;00:00,  6.83s/it]  
success to model training  
100%|██████████| 922977/922977 [00:37&amp;lt;00:00, 24404.81it/s]  
100%|██████████| 922977/922977 [00:37&amp;lt;00:00, 24619.43it/s]  
Precision@1000: 0.697069056276447  
MAP@1000: 0.1334731097421332  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;서빙 레이어에서는 개인적인 목표로 배치로 추론하기보다는 실시간으로 모델 추론을 진행하기를 원해 API 개발이 필요했다. 모델 서빙은 &lt;a href="https://docs.bentoml.org/en/latest/concepts/bento.html"&gt;BentoML&lt;/a&gt;을 사용하여 진행한다. BentoML은 모델 관리, 모델 배포, 모델 서빙을 한 번에 진행할 수 있는 머신러닝 라이브러리이다. 학습과 평가가 완료된 모델을 HDFS로부터 읽어 모델 빌드부터 서빙까지 자동으로 이루어진다.&lt;/p&gt;

&lt;p&gt;지금까지 설명한 모델 학습부터 서비스 적용 파이프라인까지의 과정을 도식화하면 다음과 같다. 단, 다른 쇼핑 아이템 추천과 달리 호텔의 경우 사용자가 요청한 숙박 조건(숙박일, 인원 수, 지역)에 따라서 추천해야 하므로, Spring Boot으로 구현한 서버를 두고 숙박 조건에 대한 처리를 거친 후 서비스에 제공한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/26.png" alt="" /&gt;&lt;/p&gt;

&lt;h2 id="ab"&gt;A/B 테스트 평가&lt;/h2&gt;

&lt;p&gt;오픈 예정인 &lt;a href="https://travel4u.naver.com"&gt;For you&lt;/a&gt;에 연관 상품 추천 모델을 적용하기 전에 호텔 서비스에 노출되는 개인화 추천 알고리즘과 A/B 테스트를 진행했다. 실험 기간은 2주 정도로, V0은 기존 추천 모델, V1은 협업 필터링 모델이다. 평가 지표로는 CTR을 사용했다. 전체 트래픽의 30%가 참여했으며, 5:5 비율로 V0, V1을 노출했다.&lt;/p&gt;

&lt;table role="table"&gt;  
&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;일자&lt;/th&gt;  
&lt;th&gt;V0&lt;/th&gt;  
&lt;th&gt;V1&lt;/th&gt;  
&lt;th&gt;증감률(%)&lt;/th&gt;  
&lt;/tr&gt;  
&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-15&lt;/td&gt;  
&lt;td&gt;3.18&lt;/td&gt;  
&lt;td&gt;3.59&lt;/td&gt;  
&lt;td&gt;13&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-16&lt;/td&gt;  
&lt;td&gt;3.06&lt;/td&gt;  
&lt;td&gt;3.61&lt;/td&gt;  
&lt;td&gt;18&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-17&lt;/td&gt;  
&lt;td&gt;3.06&lt;/td&gt;  
&lt;td&gt;3.57&lt;/td&gt;  
&lt;td&gt;17&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-18&lt;/td&gt;  
&lt;td&gt;2.97&lt;/td&gt;  
&lt;td&gt;3.71&lt;/td&gt;  
&lt;td&gt;25&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-19&lt;/td&gt;  
&lt;td&gt;3.21&lt;/td&gt;  
&lt;td&gt;3.87&lt;/td&gt;  
&lt;td&gt;21&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-20&lt;/td&gt;  
&lt;td&gt;3.06&lt;/td&gt;  
&lt;td&gt;3.69&lt;/td&gt;  
&lt;td&gt;21&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-21&lt;/td&gt;  
&lt;td&gt;2.98&lt;/td&gt;  
&lt;td&gt;3.45&lt;/td&gt;  
&lt;td&gt;16&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-22&lt;/td&gt;  
&lt;td&gt;3.10&lt;/td&gt;  
&lt;td&gt;3.69&lt;/td&gt;  
&lt;td&gt;19&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-23&lt;/td&gt;  
&lt;td&gt;3.00&lt;/td&gt;  
&lt;td&gt;3.45&lt;/td&gt;  
&lt;td&gt;15&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-24&lt;/td&gt;  
&lt;td&gt;2.90&lt;/td&gt;  
&lt;td&gt;3.59&lt;/td&gt;  
&lt;td&gt;24&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-25&lt;/td&gt;  
&lt;td&gt;3.11&lt;/td&gt;  
&lt;td&gt;3.31&lt;/td&gt;  
&lt;td&gt;6&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-26&lt;/td&gt;  
&lt;td&gt;3.02&lt;/td&gt;  
&lt;td&gt;3.80&lt;/td&gt;  
&lt;td&gt;26&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-27&lt;/td&gt;  
&lt;td&gt;3.34&lt;/td&gt;  
&lt;td&gt;3.61&lt;/td&gt;  
&lt;td&gt;8&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-28&lt;/td&gt;  
&lt;td&gt;3.00&lt;/td&gt;  
&lt;td&gt;3.67&lt;/td&gt;  
&lt;td&gt;22&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;2023-08-29&lt;/td&gt;  
&lt;td&gt;2.92&lt;/td&gt;  
&lt;td&gt;3.39&lt;/td&gt;  
&lt;td&gt;16&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;일평균&lt;/td&gt;  
&lt;td&gt;3.1&lt;/td&gt;  
&lt;td&gt;3.6&lt;/td&gt;  
&lt;td&gt;18&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;p&gt;실험 기간에 V1이 좀 더 나은 CTR을 보여줬으며 일 평균 약 18% 증가한 결과를 얻었다.&lt;/p&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;p&gt;추천 시스템 알고리즘에 대중화되어 있는 협업 필터링에서 행렬 분해(ALS)를 사용해서 실제 서비스에 적용하는 과정을 살펴 보았다. 성능이나 정말 서비스에 적용해도 문제가 없을지에 대해 다소 걱정이 있었지만, 목표했던 결과에 도달하여 서비스를 오픈할 수 있었다. 운영하는 서비스에 추천 시스템을 도입하실 분들께 조금이나마 도움이 되었으면 좋겠다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Awesome Terraform Overview HCL Deep Dive &amp; Terraform Expansion</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/9139321" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/9139321</id>
    <updated>2023-11-27T18:05:14Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(7월)에서 발표되었던 세션을 공개합니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/ZKFB5EmqiEU?si=5to4uTaP83MiabOd" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Up &amp;amp; Running Terraform&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Position of Terraform in IaC&lt;/li&gt;
&lt;li&gt;Basic Concept of Terraform&lt;/li&gt;
&lt;li&gt;Key Workflow of Terraform&lt;/li&gt;
&lt;li&gt;Key Commands of Terraform(init/plan/apply/import)&lt;/li&gt;
&lt;li&gt;Terraform Extra Keywords(backend/output)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;HCL(Hashicorp Configuration Language) Deep Dive&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Overview of HCL(Hashicorp Configuration Language)&lt;/li&gt;
&lt;li&gt;Terraform Elements &amp;amp; Expressions&lt;/li&gt;
&lt;li&gt;Terraform Functions&lt;/li&gt;
&lt;li&gt;Execute External Program with Terraform&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Expansion of Using Terraform&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Terraform IaC&lt;/li&gt;
&lt;li&gt;Terraform Graph&lt;/li&gt;
&lt;li&gt;Terraform Doc&lt;/li&gt;
&lt;li&gt;Terraform Modules&lt;/li&gt;
&lt;li&gt;Using Terragrunt&lt;/li&gt;
&lt;li&gt;Development of Terraform Provider&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 1년에 3번씩 열리고 있는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY 2023의 일부 세션을 7회에 걸쳐 공개할 예정으로 그 여섯 번째 세션 영상을 공개합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Terraform을 활용한 네이버 클라우드 플랫폼 IaC(Infrastructure as Code) 적용하기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/3612055" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/3612055</id>
    <updated>2023-11-27T18:01:13Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(4월)에서 발표되었던 세션을 공개합니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/CzeGryjIono?si=ujpolFGE9M44XnnL" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;NAVER Cloud Platform Service Overview&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Cloud Platform &amp;amp; Service Overview&lt;/li&gt;
&lt;li&gt;Cloud Service Map Overview&lt;/li&gt;
&lt;li&gt;SaaS solution on NAVER Cloud Platform&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Overview &amp;amp; Concept of Terraform&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Position of Terraform in IaC&lt;/li&gt;
&lt;li&gt;Basic Concept of Terraform&lt;/li&gt;
&lt;li&gt;Key Workflow of Terraform&lt;/li&gt;
&lt;li&gt;Key Commands of Terraform(init/plan/apply/import)&lt;/li&gt;
&lt;li&gt;Terraform Extra Keywords(backend/output)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Implementation of NAVER Cloud Platform IaC(with NCP Console)&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Terraform Installation&lt;/li&gt;
&lt;li&gt;Cheat Sheet of Ncloud VPC&lt;/li&gt;
&lt;li&gt;Ncloud VPC with Terraform
&lt;ul&gt;&lt;li&gt;Terraform Provider 설정&lt;/li&gt;
&lt;li&gt;VPC, Subnet 생성&lt;/li&gt;
&lt;li&gt;NAT Gateway, Route Table 생성&lt;/li&gt;
&lt;li&gt;Route Table Association, Route Rule 설정&lt;/li&gt;
&lt;li&gt;terraform plan, terraform apply&lt;/li&gt;
&lt;li&gt;NCP Console 리소스 생성 결과&lt;/li&gt;
&lt;li&gt;terraform state list&lt;/li&gt;
&lt;li&gt;Ncloud VPC Server 생성&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Terraform Variables&lt;/li&gt;
&lt;li&gt;Terraform Functions&lt;/li&gt;
&lt;li&gt;Ncloud NKS(Ncloud Kubernetes Service) with Terraform
&lt;ul&gt;&lt;li&gt;Terraform NKS Provider, Variables&lt;/li&gt;
&lt;li&gt;Terraform 실행을 통한 NKS Cluster 생성&lt;/li&gt;
&lt;li&gt;Nginx Image 설치 및 실행&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 1년에 3번씩 열리고 있는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY 2023의 일부 세션을 7회에 걸쳐 공개할 예정으로 그 다섯 번째 세션 영상을 공개합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>App Crash? 0.1초 만에 분석해 드릴게요, 고품질 고성능 Crash 분석 시스템 NCrashlytics</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/3461887" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/3461887</id>
    <updated>2023-11-20T17:50:23Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(10월)에서 발표되었던 세션을 공개합니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/RupdskqplU8?si=GxrV3rdmPAk5TG0T" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;NCrashlytics란 무엇인가?
&lt;ul&gt;&lt;li&gt;Crash, SymbolFile, Symbolication은 무엇인가?&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;App Crash 도메인 설명&lt;/li&gt;
&lt;li&gt;Old Symbolicator의 문제점
&lt;ul&gt;&lt;li&gt;Old Symbolicator의 기능, 성능적 한계 설명&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;New Symbolicator의 알고리즘
&lt;ul&gt;&lt;li&gt;Symbol Map File 이라는 핵심 알고리즘 설명&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;SymbolFile CLI 소개
&lt;ul&gt;&lt;li&gt;SymbolFile upload를 CLI로 해야 하는 이유 공유&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;New Symbolicator 서버 아키텍처
&lt;ul&gt;&lt;li&gt;저비용 고효율 서버 아키텍처 구조 공개&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Old, New Symbolicator 비교
&lt;ul&gt;&lt;li&gt;품질&lt;/li&gt;
&lt;li&gt;성능&lt;/li&gt;
&lt;li&gt;리소스 사용&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;추후 방향성 소개
&lt;ul&gt;&lt;li&gt;오픈소스화 관련 내용 소개&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 1년에 3번씩 열리고 있는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 마지막으로 진행된 NAVER ENGINEERING DAY 2023의 일부 세션을 7주에 걸쳐 공개할 예정으로 그 네 번째 세션 영상을 공개합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>데이터 품질 이슈로 발생하는 data downtime을 줄이자</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/5766317" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/5766317</id>
    <updated>2023-12-12T12:55:40Z</updated>
    <content type="html">&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/PgGgbKU9cs4?si=WkZbJPovONag-bQQ" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;데이터를 다루는 분이라면 공감할 이야기를 해보려 합니다. 다음과 같은 &lt;strong&gt;데이터 품질 이슈로 인해 원인을 파악하고 데이터를 재처리한 경험이 있지 않으신가요?&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;데이터 중복&lt;/li&gt;
&lt;li&gt;특정 칼럼의 NULL 분포 증가&lt;/li&gt;
&lt;li&gt;미리 정의한 문자열 값이 아닌 전혀 다른 값이 들어옴&lt;/li&gt;
&lt;li&gt;숫자 칼럼의 분포가 이상하거나 기대한 특정 범위를 벗어난 값이 들어옴&lt;/li&gt;
&lt;li&gt;그 밖의 여러 가지 데이터 품질 이슈&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이러한 &lt;strong&gt;데이터 품질 이슈를 빠르게 파악하고, data downtime을 줄이기 위해&lt;/strong&gt; 고민했던 내용과 새로운 기술을 적용한 경험을 공유합니다.&lt;/p&gt;

&lt;h2 id="datadowntime"&gt;data downtime&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;data downtime&lt;/strong&gt;이라는 용어가 생소할 수 있는데, 풀어서 설명하자면 다음과 같이 말할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;데이터 누락, 데이터 오류를 통틀어 '부정확한 데이터'가 존재하는 기간&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;data downtime이 길어지는 이유를 알아보고, data downtime이 길어지면 어떤 문제가 생기는지, 그리고 데이터 품질과 어떤 관계가 있는지 설명하겠다.&lt;/p&gt;

&lt;h3 id="datadowntime"&gt;data downtime이 길어지는 이유&lt;/h3&gt;

&lt;p&gt;데이터 엔지니어로 일을 하다 보면, 하나의 창구가 아니라 CS, 메신저, 메일 등의 다양한 경로로 데이터 품질 이슈에 대한 확인 요청을 많이 받는다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/04.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;그간의 경험으로는 실제로는 데이터에는 문제가 없었던 경우가 많았는데(평소의 추이와 다르면 한 번 더 확인을 하고자 연락이 오는 경우가 대부분이다), 그러다 보니 단건의 요청은 우선 순위가 밀리고 다수의 비슷한 문의가 쌓였을 때 데이터를 확인하게 된다.&lt;/p&gt;

&lt;p&gt;다수의 문의가 쌓였을 때 데이터를 확인하면 &lt;strong&gt;기대하지 않은 데이터&lt;/strong&gt;가 들어옴을 &lt;strong&gt;뒤늦게&lt;/strong&gt; 확인하게 된다(기대하지 않은 데이터란 위에서 언급한 데이터 품질 이슈를 내포한다).&lt;/p&gt;

&lt;p&gt;우리는 왜 &lt;strong&gt;데이터를 들여다보기 전까지 데이터 품질 문제를 확인할 수 없을까?&lt;/strong&gt; 이유는 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/05.png" alt="" /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data Lake에 들어오는 다양한 데이터 소스를 처리하는 데이터 파이프라인은 정상 동작&lt;/li&gt;
&lt;li&gt;데이터에 대한 품질 지표가 없으니 문의에 의존하고 직접 데이터를 확인해야 함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;정상 동작한 데이터 파이프라인 내부에는 &lt;strong&gt;기대하지 않은 데이터&lt;/strong&gt;가 흐르고, 해당 데이터로 만들어진 대시보드의 지표는 당연히 &lt;strong&gt;기대하지 않은 지표&lt;/strong&gt;가 된다. 즉, GIGO(Garbage In, Garbage Out)라는 표현과 같은 현상이다.&lt;/p&gt;

&lt;p&gt;하지만 데이터 품질 이슈는 잠재하고 있고 다양한 데이터 소스의 품질을 한곳에서 관리하지 않으니, 문제가 생길 때마다 담당자가 데이터를 하나 하나 확인하는 일이 반복된다. 물론, 빈번하게 발생하는 품질 이슈는 팀 내에서 필요에 따라 모니터링을 하지만 이것도 단점이 더 많은 구조였다(뒤에서 설명하겠다).&lt;/p&gt;

&lt;h3 id="datadowntimecost"&gt;data downtime과 cost의 상관관계&lt;/h3&gt;

&lt;p&gt;데이터 이슈가 생겼고, 이를 담당자가 알게되어 해결하는 시간까지를 data downtime이라고 볼 수 있다. &lt;strong&gt;이 기간이 늘어남에 따라&lt;/strong&gt; 문제가 생긴 기간의 데이터를 처리하는 리소스와 대시보드 사용자들에게 문제가 있었음을 알리는 커뮤니케이션 등의 &lt;strong&gt;비용이 비례해서 늘어난다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/06.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;그래서 이 글에서는 &lt;strong&gt;데이터가 이상함을 빨리 인지하고, data downtime을 줄이는 것&lt;/strong&gt;을 목표로 한다.&lt;/p&gt;

&lt;h2 id=""&gt;데이터 품질&lt;/h2&gt;

&lt;p&gt;데이터 품질(data quality)의 정의란 무엇일까? 나는 다음과 같이 한 줄로 정의했다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;데이터 품질이 좋다는 것은 '기대하지 않은 데이터가 없음'을 의미한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=""&gt;규칙&lt;/h3&gt;

&lt;p&gt;'기대하지 않는다'라는 설명이 조금 명확하지 않을 수 있다. 데이터 품질을 이야기할 때 나오는 6가지 규칙에 대해 조금 더 자세히 설명하겠다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/0a710dbd-8a01-17ba-818b-b7c81b9c2c2e.png" alt="" /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;정확성(accuracy): 데이터의 값이 정확한지 보장한다. 데이터가 정확하지 않다면, 데이터 기반 의사 결정에 대한 신뢰를 잃을 수 있다.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;checkpoint
&lt;ul&gt;&lt;li&gt;신뢰할 수 있는 다른 데이터와 교차 검증&lt;/li&gt;
&lt;li&gt;정기적으로 데이터를 검사&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;일관성(consistency): 데이터가 일관된 추세와 행동을 나타내고 있는지 확인한다.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;checkpoint
&lt;ul&gt;&lt;li&gt;데이터 입력 및 형식에 대한 엄격한 지침을 적용하는 데이터 표준화&lt;/li&gt;
&lt;li&gt;자동화된 데이터 검증 및 오류 보고&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;완전성(completeness): 모든 데이터가 존재하는지 확인한다.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;checkpoint
&lt;ul&gt;&lt;li&gt;누락된 데이터가 있는지 검사&lt;/li&gt;
&lt;li&gt;null 값의 비율 분석&lt;/li&gt;
&lt;li&gt;전체 레코드 카운팅&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;적시성(timeliness): 최신 데이터가 반영됨을 보장한다.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;checkpoint
&lt;ul&gt;&lt;li&gt;타임스탬프 분석&lt;/li&gt;
&lt;li&gt;실시간 데이터 모니터링&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;타당성(validity): 데이터 포맷이 비즈니스 요구 사항을 만족하는지 확인한다.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;checkpoint
&lt;ul&gt;&lt;li&gt;데이터 유형 확인&lt;/li&gt;
&lt;li&gt;수치형 칼럼의 경우 범위를 확인&lt;/li&gt;
&lt;li&gt;특정 패턴이 일치하는지 확인(예: 이메일 형식, 전화번호 형식 등)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;유일성(uniqueness): 데이터가 유일함을 확인한다.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;checkpoint
&lt;ul&gt;&lt;li&gt;모든 레코드가 중복이 없는지 확인&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이를 정리하면, 다음과 같은 3가지 작업이 필요하다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/08.png" alt="image" /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;데이터 표준 정의: 데이터에 대한 표준을 정의하려면, 우선 데이터를 잘 이해하고 특성(NULL 비율, 수치형 데이터 범위, 패턴 등)을 정리하는 것이 도움이 될 수 있다.&lt;/li&gt;
&lt;li&gt;데이터 검증 자동화: 데이터 표준을 기반으로 데이터 검증을 자동화한다.&lt;/li&gt;
&lt;li&gt;오류 보고: 자동화한 검증이 실패했다면, 어떤 정의에서 실패했는지 오류를 보고해야 한다. 실제 문제가 되는 데이터를 포함한 보고라면 문제를 파악하기 훨씬 좋을 것이다. 해당 보고에 신속하게 대응하면 data downtime을 줄일 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=""&gt;데이터 품질 도구 비교&lt;/h2&gt;

&lt;p&gt;위와 같은 일을 도와주는 데이터 품질 도구가 이미 많이 나와 있다. 그 중에서 고민했던 2가지의 오픈소스에 대해 간단하게 언급하고, 최종적으로 어떤 도구를 선택했는지 말하려고 한다.&lt;/p&gt;

&lt;h3 id=""&gt;현재 모니터링 방식&lt;/h3&gt;

&lt;p&gt;현재 팀 내에서 데이터 품질 관련 지표를 모니터링하는 방식은 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/09.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;필요에 따라 spot으로 관리되며, 주로 grafana와 zeppelin notebook을 통해 데이터를 확인하고, lambda를 통해 특정 임계점이 넘으면 메신저와 메일로 알람을 받도록 구성되어 있다.&lt;/p&gt;

&lt;p&gt;이런 방식에는 다음과 같은 문제가 있다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;zeppelin notebook과 lambda는 코드 관리가 쉽지 않다. 공통화가 어렵고, 어떤 지표를 모니터링하는지 스펙을 정리하기도 쉽지 않다.&lt;/li&gt;
&lt;li&gt;모니터링하지 않는 데이터가 많다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;만약 새로운 모니터링 방식을 만들어 본다면 다음과 같은 형태가 될 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/10.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이미 잘 구축된 데이터 품질 관련 오픈소스가 존재하므로 그 중에서 우리는 &lt;strong&gt;deequ&lt;/strong&gt;와 &lt;strong&gt;great expectations&lt;/strong&gt;를 검토해보았다.&lt;/p&gt;

&lt;h3 id="deequ"&gt;deequ&lt;/h3&gt;

&lt;p&gt;먼저 아마존에서 공개한 deequ를 살펴보겠다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/11.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이 글에서는 간단하게 특징만 정리하겠다. 자세한 내용은 &lt;a href="https://github.com/awslabs/deequ"&gt;deequ&lt;/a&gt;와 &lt;a href="https://aws.amazon.com/ko/blogs/big-data/test-data-quality-at-scale-with-deequ/"&gt;Test data quality at scale with Deequ&lt;/a&gt;를 참고하는 것을 권장한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Apache Spark 위에 구현된 라이브러리 형태&lt;/li&gt;
&lt;li&gt;언어는 Scala를 지원하며, Python 사용자를 위한 pydeequ를 제공&lt;/li&gt;
&lt;li&gt;기능
&lt;ul&gt;&lt;li&gt;Constraint(제약 조건): 데이터 표준화를 위한 데이터 제약 조건&lt;/li&gt;
&lt;li&gt;Data Profiling: 칼럼 단위의 데이터 프로파일링을 지원&lt;/li&gt;
&lt;li&gt;Automatic suggestion of constraints: 자동으로 데이터 프로파일링을 하여 제약 조건을 제안&lt;/li&gt;
&lt;li&gt;Anomaly Detection: 데이터 이상 탐지 룰 지원&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="greatexpectations"&gt;great expectations&lt;/h3&gt;

&lt;p&gt;great expectations를 살펴보겠다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/12.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;여기에서는 간단하게 특징만 정리하고 뒤에서 조금 더 자세히 설명하겠다. 궁금하다면 &lt;a href="https://greatexpectations.io/"&gt;great expectations&lt;/a&gt;를 참고하는 것을 권장한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Python 기반 도구&lt;/li&gt;
&lt;li&gt;데이터 테스트, 문서화, 프로파일링을 지원&lt;/li&gt;
&lt;li&gt;기능
&lt;ul&gt;&lt;li&gt;Expectations: 데이터 표준화를 위한 기대하는 조건&lt;/li&gt;
&lt;li&gt;Automated Data Profiling: 자동 데이터 프로파일링하여 표준화 제안&lt;/li&gt;
&lt;li&gt;Data Validation: Expectation 기반으로 데이터 검증&lt;/li&gt;
&lt;li&gt;Data Docs: 데이터 문서화 및 데이터 품질 리포트 제공&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="deequgreatexpectations"&gt;deequ와 great expectations 비교&lt;/h3&gt;

&lt;p&gt;2가지를 비교하기 위해 표로 정리해 보았다. 개인적인 의견이 들어갔으니 참고만 하고 직접 테스트 후에 선택하는 것을 추천한다.&lt;/p&gt;

&lt;table&gt;  
    &lt;tr&gt;
        &lt;th&gt;&amp;nbsp;&lt;/th&gt;
        &lt;th&gt;deequ&lt;/th&gt;
        &lt;th&gt;great expectations&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;기반&lt;/td&gt;
        &lt;td&gt;Spark 라이브러리&lt;/td&gt;
        &lt;td&gt;Python 패키지&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;언어&lt;/td&gt;
        &lt;td&gt;Scala, Python(pydeequ)&lt;/td&gt;
        &lt;td&gt;Python&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;데이터 소스&lt;/td&gt;
        &lt;td&gt;Spark에서 접근할 수 있는 모든 소스&lt;/td&gt;
        &lt;td&gt;파일 시스템, SQL 데이터베이스, 인메모리(pandas, Spark)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;문서화, 커뮤니티&lt;/td&gt;
        &lt;td&gt;상대적으로 미약함&lt;/td&gt;
        &lt;td&gt;상대적으로 활발함&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;러닝 커브&lt;/td&gt;
        &lt;td&gt;Spark를 알아야 함&lt;/td&gt;
        &lt;td&gt;습득할 새로운 용어 또는 개념이 많음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;데이터 품질 규칙&lt;/td&gt;
        &lt;td&gt;상대적으로 적음&lt;/td&gt;
        &lt;td&gt;상대적으로 많고, 활발하게 기여가 이루어짐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;integration&lt;/td&gt;
        &lt;td&gt;AWS&lt;/td&gt;
        &lt;td&gt;AWS, Airflow, DataHub 등의 데이터 엔지니어링 도구&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;h3 id="greatexpectations"&gt;최종 선택: great expectations&lt;/h3&gt;

&lt;p&gt;우리는 great expectations를 선택했다. 이유는 다음과 같이 정리할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/13.png" alt="" /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;초기 학습이 어렵지만, 그만큼 &lt;strong&gt;문서화나 커뮤니티가 활발&lt;/strong&gt;하다.&lt;/li&gt;
&lt;li&gt;한 번 구축하면, 다양한 데이터 소스에 대해 &lt;strong&gt;확장&lt;/strong&gt;하기 용이하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spark 경험이 없는&lt;/strong&gt; 팀원도 접근하기 좋다.
&lt;ul&gt;&lt;li&gt;특히 대부분의 API가 Jupyter Notebook을 지원하기 때문에 데이터 엔지니어링뿐만 아니라 데이터 과학, 데이터 분석 등에도 좋은 선택지라 생각한다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;AWS 스택 외에도 &lt;strong&gt;다양한 도구와의 integration&lt;/strong&gt;이 매력적이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Docs&lt;/strong&gt;가 다른 추가 개발 없이 자동 생성되고, 가독성이 좋다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="greatexpectationsworkflow"&gt;great expectations의 workflow&lt;/h2&gt;

&lt;p&gt;great expectations의 workflow에 대해 간단하게 설명하겠다. &lt;a href="https://docs.greatexpectations.io/docs/tutorials/quickstart/"&gt;Quickstart&lt;/a&gt;와 함께 보면 조금 더 이해가 수월할 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/14.png" alt="" /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;설치 &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;pip install great_expectations&lt;/code&gt; 명령으로 설치한다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;데이터 컨텍스트 생성 &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;great_expectations init&lt;/code&gt; 명령으로 프로젝트를 초기화한다.&lt;/li&gt;
&lt;li&gt;데이터 컨텍스트는 great expectations의 프로젝트 설정 및 메타데이터를 관리하고, Python API 진입점을 제공한다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;데이터 소스 연결 &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;great expectations는 다양한 데이터 소스와 연결하는 커넥터와 같은 역할을 제공한다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;기대 조건(Expectation) 정의 &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;데이터 표준화를 위한 데이터 기대 조건을 명시한다.&lt;/li&gt;
&lt;li&gt;Profiler를 사용하여 데이터 프로파일링을 통해 자동으로 조건을 생성할 수 있다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;데이터 검증 &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;정의한 기대 조건을 통해 데이터를 검증한다.&lt;/li&gt;
&lt;li&gt;검증 결과로 JSON 형식의 검증 결과와 HTML로 작성된 Data Docs가 생성된다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=""&gt;적용기&lt;/h2&gt;

&lt;p&gt;지금부터는 팀 내에 great expectations을 도입하는 과정을 이야기해보려 한다.&lt;/p&gt;

&lt;h3 id=""&gt;아키텍처&lt;/h3&gt;

&lt;p&gt;great expectations을 도입하기로 하면서, 개발을 위해 스케치했던 내용을 다시 그려보았다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/15.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이미 팀 내에 구축된 환경을 적극 활용하기로 했는데, 정리하면 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;데이터 검증 자동화는 팀 내에서 사용하고 있는 &lt;strong&gt;Airflow&lt;/strong&gt; 활용&lt;/li&gt;
&lt;li&gt;다른 팀원도 쉽게 사용할 수 있도록 인 2가지 Airflow Custom Operator를 개발
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;GXAutoProfilingOperator&lt;/strong&gt;: 자동 데이터 프로파일링 및 Expectation 제안&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GXCheckpointOperator&lt;/strong&gt;: 데이터 검증&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;자주 생성되는 메타데이터(검증 결과, Data Docs)는 &lt;strong&gt;MinIO(S3)&lt;/strong&gt;에 저장&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Expectation&lt;/strong&gt;은 버전 관리도 필요하고 코드 리뷰도 필요하니 &lt;strong&gt;git&lt;/strong&gt;으로 관리&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;앞에서 스케치한 내용을 다음과 같은 구조로 구현했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/16.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;팀 내의 데이터는 대부분 HDFS에 저장되어 있고, ETL을 Spark로 처리하기 때문에 다음과 같은 방향으로 구현했다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;데이터 소스는 &lt;code&gt;pyspark&lt;/code&gt;를 사용(컴퓨팅 리소스로 Spark를 사용)&lt;/li&gt;
&lt;li&gt;런타임에 HDFS 상의 데이터를 읽어 Spark 데이터프레임 형태로 데이터 검증에 활용&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;프로젝트 구조&lt;/h3&gt;

&lt;p&gt;우리는 airflow-dags라는 프로젝트에서 workflow를 관리하고 있다. 해당 프로젝트에 great expectations를 위해 몇 가지를 추가했다. 실제 프로젝트 구조는 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/17.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;프로젝트에 추가된 부분은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;dag 정의
&lt;ul&gt;&lt;li&gt;checkpoint example dag: 참고용 dag&lt;/li&gt;
&lt;li&gt;auto profiling dag: 해당 dag을 이용하여 원하는 데이터를 프로파일링하고 제안된 Expectation을 받음&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Expectation Suite
&lt;ul&gt;&lt;li&gt;정의된 각 데이터의 Expectation 모음을 관리&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Custom Expectation
&lt;ul&gt;&lt;li&gt;custom으로 작성한 Expectation 규칙&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.greatexpectations.io/docs/guides/expectations/custom_expectations_lp/"&gt;Create and manage Custom Expectations&lt;/a&gt;를 참고하여 개발&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Airflow Custom Operator
&lt;ul&gt;&lt;li&gt;custom operator 개발&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="airflowcustomoperator"&gt;Airflow Custom Operator&lt;/h3&gt;

&lt;p&gt;2가지 Airflow Custom Operator에 대해 더 자세히 설명하겠다.&lt;/p&gt;

&lt;h4 id="gxautoprofilingoperator"&gt;GXAutoProfilingOperator: 데이터 프로파일링&lt;/h4&gt;

&lt;p&gt;GXAutoProfilingOperator는 데이터에 대한 Auto Profiling을 제공한다(1회성 작업). 아직 데이터에 대한 이해도가 부족하거나, 데이터에 대한 Expectation 생성 작업을 시작할 때 도움이 될 수 있다.&lt;/p&gt;

&lt;p&gt;실행은 Airflow UI에서 이미 생성된 ge-user-profiling-expectation-suite dag의 trigger config만 변경해서 사용하도록 가이드했다. DAG conf Parameters는 기본적으로 내부에서 호출한 &lt;a href="https://docs.greatexpectations.io/docs/reference/api/profile/user_configurable_profiler/userconfigurableprofiler_class/"&gt;UserConfigurableProfilier API&lt;/a&gt;를 따르며, 필요한 파라미터를 추가했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/18.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;프로파일링 작업이 끝나면 자동으로 제안된 Expectation이 입력한 메일 주소로 발송되며, Expectation은 JSON 형식으로 생성됨을 확인할 수 있다. 담당자는 해당 Expectation을 기반으로 검토 및 수정하여 실제 적용할 수 있도록 설계했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/19.png" alt="" /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;{
  "data_asset_type": null,
  "expectation_suite_name": "mapping.channel",
  "expectations": [
    {
      "expectation_type": "expect_column_values_to_be_unique",
      "kwargs": {
        "column": "request_id"
      },
      "meta": {}
    },
    {
      "expectation_type": "expect_column_values_to_be_in_type_list",
      "kwargs": {
        "column": "request_id",
        "type_list": [
          "StringType"
        ]
      },
      "meta": {}
    }
  ],
  "ge_cloud_id": null,
  "meta": {
    "great_expectations_version": "0.15.41"
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id="gxcheckpointoperator"&gt;GXCheckpointOperator: 데이터 검증&lt;/h4&gt;

&lt;p&gt;GXCheckpointOperator는 검증할 데이터와 Expectation을 입력으로 받아 자동으로 데이터를 검증한다.&lt;/p&gt;

&lt;p&gt;다음과 같이 &lt;code&gt;GXCheckpointOperator&lt;/code&gt;를 이용하여 Task를 생성한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-python"&gt;checkpoint_run = GXCheckpointOperator(  
        task_id='checkpoint_run',
        hadoop_user_name='hadoop_user_name',
        spark_queue=queue,
        hdfs_path=path,
        hdfs_type='parquet',
        expectation_suite_name='mapping.channel',
        spark_conf={
            "spark.driver.memory": "2G",
            "spark.executor.memory": "2G",
            "spark.executor.instances": "80"
        },
        email='seulkee.park@navercorp.com'
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Checkpoint 실패 시에 Data path와 Data Docs를 메신저로 보내며, Data Docs에서 실패한 Expectation과 데이터를 살펴보고 빠르게 문제를 파악할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/20.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;적용 사례&lt;/h3&gt;

&lt;p&gt;팀 내의 중요도가 높은 데이터부터 적용하기 시작했으며, 기존에 문제가 되었던 다음과 같은 데이터 품질 이슈를 커버할 수 있게 되었다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;특정 필드가 NULL로 채워져서 오는 문제&lt;/li&gt;
&lt;li&gt;특정 필드를 채우는 외부 API 장애 현상으로 NULL 비율이 높아지는 문제&lt;/li&gt;
&lt;li&gt;업스트림 소스에서 스키마가 밀리면서 생긴 문제(밀린 스키마가 전체 string 타입이라 파이프라인이 정상 동작했던 이슈)&lt;/li&gt;
&lt;li&gt;정의되지 않은 값이 섞여서 들어옴으로써 지표에 혼란을 줄 수 있는 문제&lt;/li&gt;
&lt;li&gt;특정 타입의 데이터가 일부 2배로 들어오는 문제&lt;/li&gt;
&lt;li&gt;상관 관계가 있는 2개의 칼럼이 전혀 다른 값으로 들어오는 문제&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;p&gt;데이터 품질 이슈는 현재 데이터를 다루고 있는 조직이라면 누구나 공감할 수 있는 부분이라고 생각한다. 필요성은 이전부터 느꼈지만 실제로 도입하기까지 시간이 걸렸다. 앞으로도 데이터 품질의 중요성은 계속 늘어날 것이므로 빠르게 데이터 품질 관련 도구를 도입하고 발전시키는 과정이 필요하다고 생각이 든다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/21-1.png" alt="image" /&gt;&lt;/p&gt;

&lt;p&gt;우리는 데이터 품질을 시발점으로 &lt;a href="https://www.montecarlodata.com/blog-what-is-data-observability/"&gt;Data Observablity&lt;/a&gt;를 위한 다른 추가 과제도 진행 중이다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data Catalog를 통해 새로 입수되거나 생성되는 데이터는 자동 Expectation 제안&lt;/li&gt;
&lt;li&gt;Data Lineage를 통해 데이터 품질 오류가 생기면, 다운스트림 소스를 입수하고 있는 컨슈머에게 자동으로 리포트&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글이 데이터를 다루고 있는 이에게 조금의 도움이 되길 바란다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Kotlin으로 Cli를 만든다고?</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/2236952" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/2236952</id>
    <updated>2023-11-13T15:24:32Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(10월)에서 발표되었던 세션을 공개합니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/oFqfyjuLt88?si=LwjoMbCX3-LrM5Eq" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;배경&lt;/li&gt;
&lt;li&gt;Kotlin으로 CLI를?&lt;/li&gt;
&lt;li&gt;GraalVM&lt;/li&gt;
&lt;li&gt;사용법&lt;/li&gt;
&lt;li&gt;주의사항&lt;/li&gt;
&lt;li&gt;빌드 &amp;amp; 배포&lt;/li&gt;
&lt;li&gt;헬퍼 Library 소개&lt;/li&gt;
&lt;li&gt;샘플 코드&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 1년에 3번씩 열리고 있는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 마지막으로 진행된 NAVER ENGINEERING DAY 2023의 일부 세션을 7주에 걸쳐 공개할 예정으로 그 세 번째 세션 영상을 공개합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Fixture Monkey 1.0.0 정식 버전 릴리즈</title>
    <link rel="alternate" href="https://d2.naver.com/news/2459981" />
    <category term="news" />
    <id>https://d2.naver.com/news/2459981</id>
    <updated>2023-11-10T17:39:53Z</updated>
    <content type="html">&lt;p&gt;&lt;img src="/content/images/2023/11/-------2.png" alt="" /&gt;
&lt;a href="https://naver.github.io/fixture-monkey/"&gt;&gt;&gt; Fixture Monkey 홈페이지(링크)&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="fixturemonkey"&gt;Fixture Monkey 소개&lt;/h3&gt;

&lt;p&gt;2023년 11월 10일 네이버의 오픈소스 픽스쳐 몽키가 1.0.0 정식 버전을 릴리즈합니다. 픽스쳐 몽키는 코틀린, 자바에서 테스트 객체를 자동으로 생성하는 라이브러리로 2021년 10월부터 2년간 사용자 여러분의 피드백을 받으며 꾸준히 성장해왔습니다. 그 결과, 다양한 환경에서 사용할 수 있는 안정적인 라이브러리로 거듭났고 아래의 5가지 주요 기능을 선보이게 되었습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;유연한 객체 생성 방법: 테스트마다 다른 생성 방법으로 객체를 생성할 수 있습니다.&lt;/li&gt;
&lt;li&gt;인터페이스 익명 객체 생성: 인터페이스 익명 객체를 생성하는 방법을 객체 생성과 동일한 일관성 으로 표현할 수 있습니다.&lt;/li&gt;
&lt;li&gt;타입 안전한 표현식을 통한 값 제어: IDE 도움을 받아 리팩토링에서 안전하게 거의 모든 객체 내부 값 을 제어합니다.&lt;/li&gt;
&lt;li&gt;다양한 엔진 지원: jqwik, kotest-property, 그 외 사용자 정의 엔진을 사용해 객체를 구성하는 코틀 린, 자바 기본 타입을 생성할 수 있습니다.&lt;/li&gt;
&lt;li&gt;코틀린과 자바 호환: 코틀린, 자바를 모두 완벽하게 호환합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;사용 예시와 기능 소개&lt;/h3&gt;

&lt;p&gt;더욱 구체적인 사용 예시와 함께 주요 기능을 소개합니다. 코틀린, 자바가 동일하게 동작하는 예제는 이해의 편의와 가독성을 높이기 위해 코틀린으로 작성했습니다.&lt;/p&gt;

&lt;h5 id=""&gt;유연한 객체 생성 방법&lt;/h5&gt;

&lt;blockquote&gt;
  &lt;p&gt;픽스쳐 몽키를 사용하면 동일한 형태로 생성자 혹은 팩토리 메서드를 사용해 객체를 생성할 수 있습니다. 동일한 형태를 가지므로 테스트를 읽을 때 객체 생성 방식이 달라 발생하는 인지적 부하를 줄일 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/------.png" alt="" /&gt;&lt;/p&gt;

&lt;h5 id=""&gt;인터페이스 익명 객체 생성&lt;/h5&gt;

&lt;blockquote&gt;
  &lt;p&gt;인터페이스의 익명 객체를 생성 할 수 있습니다. 익명 객체는 다른 타입과 동일하게 필드를 제어할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/-----------.png" alt="" /&gt;&lt;/p&gt;

&lt;h5 id=""&gt;타입 안전한 표현식을 통한 값 제어&lt;/h5&gt;

&lt;blockquote&gt;
  &lt;p&gt;코틀린, 자바 모두 타입 안전한 표현식을 통한 값 제어를 제공합니다. 안전한 타입의 중첩된 객체, 컬렉션, 배열을 동시에 지원합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/--------.png" alt="" /&gt;&lt;/p&gt;

&lt;h5 id=""&gt;다양한 엔진 지원&lt;/h5&gt;

&lt;blockquote&gt;
  &lt;p&gt;플러그인을 추가하면 기본으로 제공하고 있는 jqwik, kotest-property 엔진을 사용할 수 있습니다. 그외 사용자 정의 엔진도 추가할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/-------1.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id="fixturemonkey"&gt;Fixture Monkey 팀 인사말&lt;/h4&gt;

&lt;p&gt;픽스쳐 몽키는 JVM 테스트 생태계를 개선하고자하는 프로젝트로 테스트를 더 가독성 있고 쉽게 작성할 수 있도록 노력하고 있으며, 동시에 안전한 테스트 작성을 지원하는 것을 지향하고 있습니다.&lt;/p&gt;

&lt;p&gt;정식 버전 릴리즈를 통해 이제 첫 걸음을 내딛었지만 지금까지 꾸준히 관심을 가지고 사용해주시고, 피드백을 주신 모든 분들께 진심으로 감사드립니다. 앞으로도 많은 관심과 피드백 부탁드리겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/naver/fixture-monkey"&gt;&gt;&gt; Fixture Monkey GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://medium.com/naver-platform-labs"&gt;&gt;&gt; NAVER Platform Labs Medium&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Local key-value 스토리지가 고민일땐 RocksDB 어때?</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/5053838" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/5053838</id>
    <updated>2023-11-07T09:06:09Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(10월)에서 발표되었던 세션을 공개합니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/NsKvCCMuJdY?si=v82MeIV6-3JSaud8" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;KV 스토리지&lt;/li&gt;
&lt;li&gt;RocksDB&lt;/li&gt;
&lt;li&gt;LSM Tree&lt;/li&gt;
&lt;li&gt;RocksDB Features&lt;/li&gt;
&lt;li&gt;주의사항&lt;/li&gt;
&lt;li&gt;마치며&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;강의 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;RocksDB가 무엇인지 궁금하신 분들&lt;/li&gt;
&lt;li&gt;로컬 key-value 스토리지 선택에 고민이신 분들&lt;/li&gt;
&lt;li&gt;LSM Tree가 무엇인지 궁금하신 분들&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 1년에 3번씩 열리고 있는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 마지막으로 진행된 NAVER ENGINEERING DAY 2023의 일부 세션을 7주에 걸쳐 공개할 예정으로 그 두 번째 세션 영상을 공개합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>FE News 11월 소식</title>
    <link rel="alternate" href="https://d2.naver.com/news/9680203" />
    <category term="news" />
    <id>https://d2.naver.com/news/9680203</id>
    <updated>2023-11-01T15:36:55Z</updated>
    <content type="html">&lt;p&gt;&lt;img src="/content/images/2023/11/-----------2023-07-06------4-16-49-1.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id="11"&gt;&lt;strong&gt;[11월 주요내용]&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src="/content/images/2023/11/-----------2023-11-01------3-34-26.png" alt="" /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The State of Vite&lt;/li&gt;
&lt;li&gt;The State of WebAssembly 2023&lt;/li&gt;
&lt;li&gt;The Saga of the Closure Compiler, and Why TypeScript Won&lt;/li&gt;
&lt;li&gt;HTTP/3 Performance for JS Developers&lt;/li&gt;
&lt;li&gt;The Negative Impact of Mobile-First Web Design on Desktop&lt;/li&gt;
&lt;li&gt;The Future of CSS: Easy Light-Dark Mode Color Switching with light-dark()
&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="fenews11httpsgithubcomnaverfenewsblobmasterissues202311md"&gt;&lt;strong&gt;&lt;a href="https://github.com/naver/fe-news/blob/master/issues/2023-11.md"&gt;&gt;&gt; FE News 11월 보러가기&lt;/a&gt;&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="fenewsbr"&gt;&lt;strong&gt;◎ FE News란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;네이버 FE 엔지니어들이 엄선한 양질의 FE 및 주요한 기술 소식들을 큐레이션해 공유하는 것을 목표로 하며, 이를 통해 국내 개발자들에게 지식 공유에 대한 가치 인식과 성장에 도움을 주고자 하는 기술소식 공유 프로젝트 입니다.&lt;/p&gt;
  
  &lt;p&gt;매월 첫째 주 수요일, 월 1회 발행 되고 있으니 많은 관심 부탁드립니다.&lt;br/&gt;
  ▷ &lt;a href="https://fenews.substack.com/embed"&gt;구독하기&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>AI 경량화: 더 빠르고 저렴한 AI 서비스</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/4608596" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/4608596</id>
    <updated>2023-10-31T11:18:55Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(10월)에서 발표되었던 세션을 공개합니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/NVNCPGWe5Ss?si=mcD3ArhgjFFLIpO4" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;AI 경량화 삽질기 (feat. LaRva)
&lt;ul&gt;&lt;li&gt;Quantization과 삽질기&lt;/li&gt;
&lt;li&gt;Pruning과 삽질기&lt;/li&gt;
&lt;li&gt;Low-Rank와 삽질기&lt;/li&gt;
&lt;li&gt;Knowledge Distillation과 삽질기&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;AI 경량화 Benefits &amp;amp; Risks
&lt;ul&gt;&lt;li&gt;전력 소모 단위에서의 AI 경량화&lt;/li&gt;
&lt;li&gt;각종 논문에서의 AI 경량화 안정성 반증&lt;/li&gt;
&lt;li&gt;AI 경량화에서 얻을 수 있는 Benefits&lt;/li&gt;
&lt;li&gt;AI 경량화를 할 때 대비해야 하는 Risks&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 1년에 3번씩 열리고 있는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 마지막으로 진행된 NAVER ENGINEERING DAY 2023의 일부 세션을 7주에 걸쳐 공개할 예정으로 그 첫 번째 세션 영상을 공개합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>NAVER ENGINEERING DAY 2023 살펴보기</title>
    <link rel="alternate" href="https://d2.naver.com/news/2884147" />
    <category term="news" />
    <id>https://d2.naver.com/news/2884147</id>
    <updated>2023-10-24T17:33:06Z</updated>
    <content type="html">&lt;p&gt;&lt;img src="/content/images/2023/10/0a710ba9-87a1-1b45-8188-9389f42d7924--1--1.gif" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. &lt;br /&gt;
그중 1년에 3번, 한 해에 200 여개의 세션이 발표되는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;/p&gt;

&lt;p&gt;2016년부터 시작되어 어느덧 8년 차에 접어들고 있는 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다.&lt;/p&gt;

&lt;h4 id="100"&gt;100여 개의 기술 세션과 부스&lt;/h4&gt;

&lt;p&gt;지난주 올해의 마지막 NAVER ENGINEERING DAY가 열렸습니다. &lt;br/&gt;
주니어 개발자를 위한 세션부터 한층 심화된 기술 내용을 다루는 세션까지 수준도 다양하고 기술 분야 또한 다양한 107개의 세션이 온라인, 오프라인으로 진행되었습니다.&lt;/p&gt;

&lt;p&gt;오랜만에 오프라인으로 기술 부스도 운영되어 각 조직의 기술 홍보를 통해 다른 분들의 의견도 듣고, 평소 궁금했던 기술 이야기도 나눌 수 있는 시간을 가졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/-----------2023-10-24------5-06-54.png" alt="" /&gt;
&lt;span class="caption"&gt;&amp;lt;10월 ENGINEERING DAY 세션과 부스 모습&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id=""&gt;세션을 공개합니다!&lt;/h4&gt;

&lt;p&gt;ENGINEERING DAY는 사내 행사로 발표 세션은 외부로 공개하지 않았지만, 지난 회부터 일부 세션을 공개하고 있습니다. &lt;br /&gt;
이번에도 공개 가능한 세션 일부를 7주에 걸쳐 공개할 예정인데요,
UI 개발부터 배포 시스템, App crash 분석 등 알찬 주제를 선보일 예정입니다.&lt;/p&gt;

&lt;p&gt;다음 주부터 매주 1편씩 영상이 공개될 예정이니 많은 관심과 시청 부탁드립니다.&lt;br&gt;
지난 세션영상과 더 많은 기술영상은 아래 채널에서 살펴 보실 수 있습니다.&lt;/p&gt;

&lt;p&gt;D2 유튜브 채널 : &lt;a href="https://www.youtube.com/@naver_d2"&gt;https://www.youtube.com/@naver_d2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Kafka에서 파티션 증가 없이 동시 처리량을 늘리는 방법 - Parallel Consumer</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/7181840" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/7181840</id>
    <updated>2023-10-30T14:42:36Z</updated>
    <content type="html">&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/4rOiH7OAqog?si=hbMLeCBtoDmlcC7g" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Kafka를 사용하면서 메시지 동시 처리량을 늘릴 수 있는 가장 쉬운 방법 중 하나는 파티션을 증가시키는 것입니다. 다만 파티션 수는 한번 늘어나면 줄일 수 없기에 신중해야 합니다.&lt;/p&gt;

&lt;p&gt;Log&amp;amp;Metric 조직에서는 Kafka를 활용하여 사내 로그 관리 시스템을 운영하고 있습니다. 방대한 양의 로그를 빠르게 처리하려다 보니 파티션 수가 굉장히 늘어나 있었으며 많은 파티션 수로 인한 사이드 이펙트도 존재했습니다. 파티션을 늘리지 않고도 동시 처리량을 늘리기 위해 고민하던 중 Parallel Consumer라는 라이브러리를 알게 되었으며 이후에 Parallel Consumer를 사용하여 적은 파티션으로 높은 동시 처리량 수준을 만족시킬 수 있었습니다.&lt;/p&gt;

&lt;p&gt;이 글에서는 Parallel Consumer가 무엇인지, 어떻게 동작하는지 그리고 내부 구조는 어떤지 간략하게 공유해 보겠습니다. Kafka Client나 Producer에 대한 자세한 설명은 &lt;a href="https://d2.naver.com/helloworld/6560422"&gt;KafkaProducer Client Internals&lt;/a&gt;, &lt;a href="https://d2.naver.com/helloworld/0974525"&gt;KafkaConsumer Client Internals&lt;/a&gt; 등을 참고 바랍니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#그냥-파티션-늘리면-안-돼"&gt;그냥 파티션 늘리면 안 돼?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#parallel-consumer란-무엇인가"&gt;Parallel Consumer란 무엇인가&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="#파티션-단위-vs-메시지-단위"&gt;파티션 단위 vs 메시지 단위&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#메시지-단위-병렬성이-어떻게-가능한가"&gt;메시지 단위 병렬성이 어떻게 가능한가&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#parallel-consumer의-순서-보장-방식"&gt;Parallel Consumer의 순서 보장 방식&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="#partition"&gt;Partition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#key"&gt;Key&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#unordered"&gt;Unordered&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#parallel-consumer의-내부-구조"&gt;Parallel Consumer의 내부 구조&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="#아키텍처"&gt;아키텍처&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#순서-보장-방식-구현"&gt;순서 보장 방식 구현&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#batchsize-delta"&gt;batchSize, delta&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#커밋"&gt;커밋&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#오류로-인한-메시지-중복-처리-방지"&gt;오류로 인한 메시지 중복 처리 방지&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#우아한-종료"&gt;우아한 종료&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#성능-비교"&gt;성능 비교&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#마치며"&gt;마치며&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=""&gt;그냥 파티션 늘리면 안 돼?&lt;/h2&gt;

&lt;p&gt;기존 Kafka Consumer의 병렬 처리 단위는 &lt;strong&gt;파티션&lt;/strong&gt;이다. 보통 파티션별 단일 컨슈머 스레드가 할당되는 구조이기 때문에 동시 처리량을 늘리기 위해서는 파티션 수 또한 늘려야 한다. 파티션을 늘리면 동시 처리량은 늘겠지만 다음과 같은 단점이 존재한다.&lt;/p&gt;

&lt;h4 id="1"&gt;1. 브로커 파일 시스템 리소스 사용량 증가&lt;/h4&gt;

&lt;p&gt;Kafka 브로커는 파티션별로 데이터를 저장하는데 이때 단순 데이터 정보(&lt;code&gt;.log&lt;/code&gt; 파일)뿐만 아니라 메타 정보(&lt;code&gt;.index&lt;/code&gt;, &lt;code&gt;.timeindex&lt;/code&gt;, &lt;code&gt;.snapshot&lt;/code&gt; 파일)도 함께 저장한다. 따라서 파티션이 많아질수록 많아지는 파일에 대한 파일 오픈 비용, 디스크 사용량 비용 등이 추가로 필요해진다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/kafka-broker-data.png" alt="kafka-broker-data.png" /&gt;&lt;/p&gt;

&lt;h4 id="2"&gt;2. 장애에 더 취약한 구조&lt;/h4&gt;

&lt;p&gt;단일 브로커에 파티션 리더가 더 많이 배치되기 때문에 브로커 노드 장애 혹은 재시작으로 영향받는 범위가 더 넓다.&lt;/p&gt;

&lt;h4 id="3"&gt;3. 복제 비용 증가&lt;/h4&gt;

&lt;p&gt;파티션 단위로 설정된 replicas 수만큼 복제가 이루어지기 때문에 복제로 인한 디스크 사용량, latency가 증가한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;파티션 수가 적은 환경에서는 어쩌면 큰 문제가 아닐 수 있지만, 과도하게 늘어나 있는 환경에서는 문제가 될 수 있다.&lt;/p&gt;

&lt;h2 id="parallelconsumer"&gt;Parallel Consumer란 무엇인가&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://github.com/confluentinc/parallel-consumer"&gt;Parallel Consumer&lt;/a&gt;는 Confluent Inc.에서 만든 오픈소스다(Apache 2.0 License). Parallel Consumer의 README를 살펴보면 이 라이브러리의 탄생 의도가 보인다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-motivation.png" alt="parallel-consumer-motivation.png" /&gt;&lt;/p&gt;

&lt;p&gt;간단히 말하자면 Parallel Consumer란 단일 파티션에 여러 컨슈머 스레드를 사용하여 &lt;strong&gt;파티션을 늘리지 않고 동시 처리량을 증가시키기 위해&lt;/strong&gt; 만들어진 라이브러리이다.&lt;/p&gt;

&lt;h3 id="vs"&gt;파티션 단위 vs 메시지 단위&lt;/h3&gt;

&lt;p&gt;Parallel Consumer를 사용하면 병렬 처리 단위를 파티션이 아닌 &lt;strong&gt;개별 Kafka 메시지&lt;/strong&gt; 또는 유사한 단위로 지정이 가능하다. 이해하기 쉽게 그림으로 비교해보면 다음과 같다. 첫 번째 그림은 일반 Kafka Consumer를 사용한 예시다. 파티션 단위로 병렬성을 달성해서 3개 메시지를 병렬로 처리하는 것을 볼 수 있다. 두 번째 그림은 Parallel Consumer를 사용한 예시다. 파티션이 한 개임에도 불구하고 복수의 스레드를 사용하여 첫 번째 그림과 동일하게 3개 메시지를 동시에 처리하는 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/kafka-vanilla-consumer-parallelism.png" alt="kafka-vanilla-consumer-parallelism.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-parallelism-1.png" alt="parallel-consumer-parallelism.png" /&gt;&lt;/p&gt;

&lt;p&gt;즉, &lt;strong&gt;파티션 수를 늘리지 않고도 동시 처리량을 늘릴 수 있다는 이점&lt;/strong&gt;이 Parallel Consumer와 일반 Kafka Consumer의 차이이다.&lt;/p&gt;

&lt;h3 id=""&gt;메시지 단위 병렬성이 어떻게 가능한가&lt;/h3&gt;

&lt;p&gt;기존 Kafka에서는 파티션별로 마지막으로 처리한 오프셋을 관리하고 있고 브로커의 오프셋 정보는 컨슈머가 메시지를 처리한 후 커밋을 하면서 갱신된다. 일반적으로는 한 번에 한 개의 메시지를 처리하며 auto 커밋 방식을 많이 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/kafka-vanilla-consumer.png" alt="kafka-vanilla-consumer.png" /&gt;&lt;/p&gt;

&lt;p&gt;한 번에 한 개씩 처리하지 않고 여러 개의 메시지를 처리한 후 마지막 오프셋을 커밋할 수도 있다. 이때 커밋은 수동으로 직접 수행해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/kafka-vanilla-batch-consumer.png" alt="kafka-vanilla-batch-consumer.png" /&gt;&lt;/p&gt;

&lt;p&gt;여기서 메시지 처리는 실제 Kafka Consumer가 하는 것이 아니기 때문에 사용자가 이를 병렬로 수행하면 성능이 더 올라갈 수 있다. 이 경우도 마찬가지로 처리 후 마지막 오프셋을 커밋한다. 마찬가지로 커밋은 수동으로 수행해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/kafka-vanilla-batch-consumer-multithread.png" alt="kafka-vanilla-batch-consumer-multithread.png" /&gt;&lt;/p&gt;

&lt;p&gt;Parallel Consumer는 여기서 더 나아가서 오프셋 갱신을 비동기로 수행한다. 처리 결과를 임시로 저장해두고 주기적으로 오프셋을 커밋한다. 이렇게 하면 오프셋 커밋으로 인한 병목 없이 연이어서 처리할 수 있다. 아래의 그림은 11번 오프셋에 해당하는 메시지 처리 후 11번 오프셋을 저장하고 있다가 메시지 처리와 비동기로 커밋하는 과정을 보여준다. 커밋을 할 때 12, 13, 14번 오프셋에 해당하는 메시지를 동시에 처리하고 있는 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-offset-async.png" alt="parallel-consumer-offset-async.png" /&gt;&lt;/p&gt;

&lt;p&gt;메시지 처리를 병렬로 수행하면 어떤 오프셋을 처리해야 할지 모호할 수 있다. 예를 들어 한 파티션에서 12~14번 오프셋에 해당하는 3개의 메시지를 가져갔지만 병렬 처리로 인해 13번 오프셋을 처리하기 전에 14번 오프셋을 처리할 수 있다. Parallel Consumer는 누적하여 이전 오프셋들에 대한 처리를 완료한 가장 마지막 오프셋을 커밋한다. 다음 그림은 누적하여 12번 오프셋까지 처리를 완료한 상황을 보여준다. 14번 오프셋을 처리했지만 13번 오프셋을 아직 미처리 했기에 12번 오프셋을 커밋한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-last-processed-omit.png" alt="parallel-consumer-last-processed-omit.png" /&gt;&lt;/p&gt;

&lt;p&gt;만약 13번 오프셋도 처리한 상황이라면 누적하여 14번 오프셋까지 처리 완료 했기에 14번 오프셋을 커밋할 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-last-processed-normal.png" alt="parallel-consumer-last-processed-normal.png" /&gt;&lt;/p&gt;

&lt;h2 id="parallelconsumer"&gt;Parallel Consumer의 순서 보장 방식&lt;/h2&gt;

&lt;p&gt;지금까지 Parallel Consumer가 병렬성을 높이는 방법을 알아보았다. 메시지 병렬 처리 및 비동기 오프셋 관리를 통해 성능을 높일 수 있다. 하지만 메시지 간에 순서가 중요한 경우가 있다. 예를 들어 상품 주문에 대한 이벤트를 처리하는 경우 주문 요청 이벤트를 처리하기 전에 취소 요청 이벤트를 처리하면 문제가 될 수 있다. Parallel Consumer는 이를 위해 Partition, Key, Unordered 세 가지의 순서 보장 방식을 제공한다. Partition, Key, Unordered순으로 순서 보장 관련 제약이 느슨해지며 성능이 향상된다.&lt;/p&gt;

&lt;h3 id="partition"&gt;Partition&lt;/h3&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-partition-ordering.png" alt="parallel-consumer-partition-ordering.png" /&gt;&lt;/p&gt;

&lt;p&gt;Partition 방식은 말 그대로 Kafka 파티션 단위로 순서 보장을 하는 것으로 원래 방식과 큰 차이는 없다. 이 방법은 서버 한 대로 여러 Kafka Consumer를 손쉽게 띄울 수 있어서 보다 적은 리소스로 처리할 수 있다는 점 외에는 큰 장점은 없다.&lt;/p&gt;

&lt;h3 id="key"&gt;Key&lt;/h3&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-key-ordering.png" alt="parallel-consumer-key-ordering.png" /&gt;&lt;/p&gt;

&lt;p&gt;Kafka 메시지에는 어떤 파티션으로 들어가야 한다는 힌트를 제공하는 Key가 있다. Parallel Consumer는 Key 단위의 순서 보장 방식이 있으며 이는 동일 Key 기준으로 메시지를 순차적으로 처리한다. 앞선 Partition 방식에서는 파티션 단위로만 병렬 처리가 가능한 반면에 Key 방식의 경우 동일 파티션 내에도 Key가 다르면 메시지가 병렬로 처리될 수 있다.&lt;/p&gt;

&lt;h3 id="unordered"&gt;Unordered&lt;/h3&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-unordered.png" alt="parallel-consumer-unordered.png" /&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 Unordered 방식은 순서를 아예 보장하지 않는 방식이며 앞서 들어온 메시지의 완료 결과를 기다리지 않는다. 즉, 메시지 단위로 병렬 처리하는 방식이다. 특별한 제약이 없기 때문에 세 방식 중 성능이 가장 뛰어나다.&lt;/p&gt;

&lt;h2 id="parallelconsumer"&gt;Parallel Consumer의 내부 구조&lt;/h2&gt;

&lt;p&gt;사용하는 라이브러리의 코드를 보며 내부 구현을 살펴보는 것은 해당 라이브러리를 목적에 맞게 더 잘 사용하고 추후 이슈 발생 시 원인 파악 및 대응에 큰 도움을 준다. Log&amp;amp;Metric 조직 내에서는 Parallel Consumer 코드를 면밀히 분석했으며 도중에 일부 버그를 찾아 기여하기도 했다. Parallel Consumer가 병렬성을 어떻게 달성하는지, 순서 보장은 어떻게 하는지 알아보았으니, 이제 내부 동작을 직접 확인해 보자. 관련 내용은 현재 이 글을 작성하는 시점에서 최신 버전인 0.5.2.7을 기반으로 작성했다.&lt;/p&gt;

&lt;h3 id=""&gt;아키텍처&lt;/h3&gt;

&lt;p&gt;Parallel Consumer에는 Broker Poller Thread와 Controller Thread라는 2개의 중요한 스레드와 실제 사용자 코드를 처리하는 Worker Thread Pool, 그리고 오프셋 저장소인 Work State Manager가 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-model.png" alt="parallel-consumer-model.png" /&gt;&lt;/p&gt;

&lt;p&gt;Broker Poller Thread는 실제 Kafka Broker와 통신하는 스레드로, 메시지를 가져와서 Mailbox에 저장한다. Controller Thread는 실제 메인 로직으로, Mailbox에서 메시지를 가져와서 Worker Thread에 전달하는 작업 및 메시지 커밋을 담당한다. Worker Thread Pool은 실제 사용자가 등록한 작업을 하는 스레드로, Controller Thread가 전달한 메시지를 처리한다. Work State Manager는 처리한 오프셋 및 순서 보장을 고려하여 다음에 처리될 메시지를 관리한다. 여기서 Mailbox는 Broker Poller Thread가 Controller Thread에게 polling한 Kafka 메시지를 전달하기 위한 매개체이다.&lt;/p&gt;

&lt;p&gt;실제 코드를 간략히 살펴보자. 실제 코드를 살펴볼 때는 사용자가 직접 호출할 수 있는 메서드부터 보는 것이 좋다. 실제 사용자는 &lt;code&gt;ParallelEoSStreamProcessor#poll&lt;/code&gt;을 주로 호출한다. 해당 메서드를 들어가 보면 &lt;code&gt;wrappedUserFunc&lt;/code&gt;라는 것을 만들어서 &lt;code&gt;AbstractParallelEoSStreamProcessor#supervisorLoop&lt;/code&gt;를 호출한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/ParallelEoSStreamProcessor-poll.png" alt="ParallelEoSStreamProcessor-poll.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;AbstractParallelEoSStreamProcessor#supervisorLoop&lt;/code&gt;는 Parallel Consumer 내부 구현의 핵심 메서드로, Broker, Control Loop 호출 등 거의 모든 작업을 트리거한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-supervisorloop.png" alt="AbstractParallelEoSStreamProcessor-supervisorloop.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;AbstractParallelEoSStreamProcessor#supervisorLoop&lt;/code&gt; 위쪽에서 &lt;code&gt;BrokerPollSystem#start&lt;/code&gt;를 호출하는 것을 볼 수 있다. 이는 앞서 설명한 Broker Poller Thread에 해당하는 부분으로, 코드를 타고 들어가면 &lt;code&gt;pc-broker-poll&lt;/code&gt;이라는 이름으로 스레드를 생성하는 것을 확인할 수 있다. &lt;code&gt;handlePoll&lt;/code&gt; 메서드에서 Mailbox에 저장한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/BrokerPollSystem-start.png" alt="BrokerPollSystem-start.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/BrokerPollSystem-controlloop.png" alt="BrokerPollSystem-controlloop.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;AbstractParallelEoSStreamProcessor#supervisorLoop&lt;/code&gt; 아래쪽에서는 &lt;code&gt;controlTask&lt;/code&gt;라는 함수를 만든 후 &lt;code&gt;ExecutorService&lt;/code&gt;에 넘기는 것을 볼 수 있다. 여기가 바로 Controller Thread를 생성하는 부분이다. 앞서 설명했듯이 Controller Thread는 Mailbox에서 메시지를 읽은 후 Worker Thread에 분배한다. 코드를 타고 들어가면 &lt;code&gt;AbstractParallelEoSStreamProcessor#submitWorkToPoolInner&lt;/code&gt; 메서드를 호출하여 &lt;code&gt;workerThreadPool&lt;/code&gt;에 submit한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-submitWorkToPoolInner.png" alt="AbstractParallelEoSStreamProcessor-submitWorkToPoolInner.png" /&gt;&lt;/p&gt;

&lt;p&gt;Worker Thread Pool은 AbstractParallelEoSStreamProcessor의 필드에 있는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-workerThreadPool.png" alt="AbstractParallelEoSStreamProcessor-workerThreadPool.png" /&gt;&lt;/p&gt;

&lt;p&gt;여기서 Control Thread가 Mailbox에서 가져오는 부분을 타고 들어가면 &lt;code&gt;AbstractParallelEoSStreamProcessor#processWorkCompleteMailbox&lt;/code&gt;에 도달한다. 이 메서드에서 &lt;code&gt;WorkManager#registerWork&lt;/code&gt;를 호출하여 Mailbox에서 메시지를 가져와서 &lt;code&gt;WorkManager&lt;/code&gt;에 등록한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-processWorkCompleteMailBox.png" alt="AbstractParallelEoSStreamProcessor-processWorkCompleteMailBox.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;WorkManager&lt;/code&gt;에 등록한 메시지를 &lt;code&gt;AbstractParallelEoSStreamProcessor#retrieveAndDistributeNewWork&lt;/code&gt;에서 &lt;code&gt;WorkManager#getWorkIfAvailable&lt;/code&gt;를 호출하여 가져온다. &lt;code&gt;WorkManager&lt;/code&gt;는 순서 보장을 고려하여 메시지를 반환한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-retrieveAndDistributeNewWork.png" alt="AbstractParallelEoSStreamProcessor-retrieveAndDistributeNewWork.png" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;순서 보장 방식 구현&lt;/h3&gt;

&lt;p&gt;위에서 언급한 순서 보장 방식을(Partition, Key, Unordered) Parallel Consumer는 어떤 식으로 구현하는지 살펴보겠다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-shard.png" alt="parallel-consumer-shard.png" /&gt;&lt;/p&gt;

&lt;p&gt;Parallel Consumer는 Kafka 메시지를 shard 단위로 분배하며, 각 shard별로 작업이 병렬 수행된다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-shard-partition-key.png" alt="parallel-consumer-shard-partition-key.png" /&gt;&lt;/p&gt;

&lt;p&gt;Key, Partition별로 shard가 생기고 shard 내에서 작업은 순서대로 처리되기 때문에, 단일 shard 내에서 메시지 처리 순서는 보장된다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-shard-unordered.png" alt="parallel-consumer-shard-unordered.png" /&gt;&lt;/p&gt;

&lt;p&gt;재밌는 것은 Unordered일 경우 Partition 개수만큼 shard가 생기지만 Partition shard 내의 메시지가 동시에 소비될 수 있다는 점이다.&lt;/p&gt;

&lt;p&gt;즉, shard 내의 메시지를 1개씩 순서대로 처리하면 Key, Partition 방식의 순서가 보장되고, shard 내의 메시지를 동시에 여러 건을 처리하면 Unordered 방식이 구현된다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/processing-shard.png" alt="processing-shard.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ProcessingShard&lt;/code&gt;는 단일 shard를 지칭하는데 entries를 통해 작업 메시지를, key를 통해 shardkey를 관리한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/shard-manager.png" alt="shard-manager.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ShardManager&lt;/code&gt;는 모든 shard 정보를 관리하며, 각 shard별로 메시지를 가져와 WorkPool에 넘겨준다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/get-work-from-shard.png" alt="get-work-from-shard.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ProcessingShard#getWorkIfAvailable&lt;/code&gt;는 shard별로 처리할 task를 가져오는 메서드이다. 이때 &lt;code&gt;ProcessingShard#getWorkIfAvailable&lt;/code&gt;를 보면 순서 보장이 필요한 경우(Key, Partition) shard별로 1건의 메시지만 가져오고, 순서 보장이 필요 없는 경우(Unordered) 병렬로 수행할 수 있는 최대의 메시지, 즉 batchSize만큼 가져온다.&lt;/p&gt;

&lt;h3 id="batchsizedelta"&gt;batchSize, delta&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;batchSize&lt;/code&gt;는 단일 Worker Thread에서 한 번에 처리할 Kafka 메시지 개수, 즉 단일 스레드 chunk를 의미한다. &lt;code&gt;delta&lt;/code&gt;는 전체 Worker Thread Pool에서 한 번에 처리할 Kafka 메시지 개수를 의미한다. 정리하면, 전체 shard로부터 &lt;code&gt;delta&lt;/code&gt;만큼 task를 가져와서 각 Worker Thread에 &lt;code&gt;batchSize&lt;/code&gt;만큼 task를 전달한다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;delta&lt;/code&gt;를 구하는 기본 공식은 &lt;code&gt;workerThreadPoolSize * 2 * batchSize * batchSize&lt;/code&gt;이다. &lt;code&gt;batchSize&lt;/code&gt;의 기본 값은 &lt;code&gt;1&lt;/code&gt;이므로, 기본 값을 사용한다는 가정 하에  &lt;code&gt;workerThreadPoolSize * 2&lt;/code&gt;라고 봐도 무방하다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;batchSize&lt;/code&gt;와 &lt;code&gt;delta&lt;/code&gt;는 &lt;code&gt;ParallelConsumerOptions&lt;/code&gt;으로 쉽게 수정 가능하다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/batch-size-delta.png" alt="batch-size-delta.png" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;커밋&lt;/h3&gt;

&lt;p&gt;다음으로 먼저 커밋을 어디서 하는지 알아보자. 커밋은 Controller Thread에서 수행한다. &lt;code&gt;AbstractParallelEoSStreamProcessor#controlLoop&lt;/code&gt; 위쪽을 보면 &lt;code&gt;commitOffsetsThatAreReady&lt;/code&gt;라는 메서드를 호출한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-controlloop-upper.png" alt="AbstractParallelEoSStreamProcessor-controlloop-upper.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;AbstractParallelEoSStreamProcessor#commitOffsetsThatAreReady&lt;/code&gt; 내부를 보면 commiter에게 &lt;code&gt;OffsetCommitter#retrieveOffsetsAndCommit&lt;/code&gt;를 호출한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-commitOffsetsThatAreReady.png" alt="AbstractParallelEoSStreamProcessor-commitOffsetsThatAreReady.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;OffsetCommitter&lt;/code&gt;는 &lt;code&gt;AbstractParallelEoSStreamProcessor&lt;/code&gt;의 필드에 있으며 생성자에서 옵션에 따라 어떤 &lt;code&gt;OffsetCommitter&lt;/code&gt;를 쓸지 결정한다. &lt;code&gt;OffsetCommitter&lt;/code&gt; 구현체는 앞서 설명한 Work State Manager에서 최신 오프셋을 가져와서 커밋한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-commiter.png" alt="AbstractParallelEoSStreamProcessor-commiter.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-constructor.png" alt="AbstractParallelEoSStreamProcessor-constructor.png" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;오류로 인한 메시지 중복 처리 방지&lt;/h3&gt;

&lt;p&gt;예를 들어 한 파티션에서 4, 5, 6, 7번 오프셋을 처리 중 4, 6, 7번 오프셋은 성공했지만 5번 오프셋은 처리하지 못한 경우 &lt;strong&gt;4번 오프셋까지 완료했다고 커밋한다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-offset-commit-server-down-before.png" alt="parallel-consumer-offset-commit-server-down-before.png" /&gt;&lt;/p&gt;

&lt;p&gt;이때 장애로 서버가 재시작되면, 마지막으로 커밋한 오프셋을 4번으로 인식하고 5, 6, 7번 오프셋에 해당하는 메시지를 처리하려 할 것이다. 그런데 6, 7번 오프셋에 해당하는 메시지는 이미 처리했으므로 중복하여 재처리할 필요가 없다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-offset-commit-server-down-after.png" alt="parallel-consumer-offset-commit-server-down-after.png" /&gt;&lt;/p&gt;

&lt;p&gt;Parallel Consumer에서는 이런 상황을 방지하기 위해 완료되지 않은 오프셋들을 오프셋 메타데이터에 기록한다. 이를 &lt;code&gt;incompleteOffsets&lt;/code&gt;이라고 부른다. 여기서는 5번 오프셋이 메타데이터에 기록될 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-offset-commit-server-down-metadata-before.png" alt="parallel-consumer-offset-commit-server-down-metadata-before.png" /&gt;&lt;/p&gt;

&lt;p&gt;Parallel Consumer는 메시지를 처리하기 전에 오프셋 메타데이터에 있는 &lt;code&gt;incompleteOffsets&lt;/code&gt; 정보를 확인하여 현재 메시지를 처리할지 여부를 판단한다. 여기서 &lt;code&gt;incompleteOffsets&lt;/code&gt;에는 5번 오프셋만 있으니 6번, 7번은 건너뛰고 5번 오프셋에 대해서만 처리한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-offset-commit-server-down-metadata-after.png" alt="parallel-consumer-offset-commit-server-down-metadata-after.png" /&gt;&lt;/p&gt;

&lt;p&gt;이제 구현을 살펴보자. 앞서 커밋을 할 때 &lt;code&gt;AbstractOffsetCommitter#retrieveOffsetsAndCommit&lt;/code&gt;을 호출한다고 했다. 이 안에서는 &lt;code&gt;WorkManager#collectCommitDataForDirtyPartitions&lt;/code&gt;를 호출한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractOffsetCommitter-retrieveOffsetsAndCommit.png" alt="AbstractOffsetCommitter-retrieveOffsetsAndCommit.png" /&gt;&lt;/p&gt;

&lt;p&gt;이를 따라가 보면 &lt;code&gt;PartitionState#createOffsetAndMetadata&lt;/code&gt;에 도달한다. 여기서 커밋할 오프셋과 메타데이터를 만들어 주는 것을 확인할 수 있다. 여기서 &lt;code&gt;PartitionState#tryToEncodeOffsets&lt;/code&gt;를 호출한다. &lt;code&gt;PartitionState#tryToEncodeOffsets&lt;/code&gt;에서 성공한 것 중 가장 큰 오프셋과, 실패한 오프셋 리스트를 인코딩하여 반환한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/PartitionState-createOffsetAndMetadata.png" alt="PartitionState-createOffsetAndMetadata.png" /&gt;&lt;/p&gt;

&lt;p&gt;앞서 저장한 메타데이터를 사용해서 &lt;code&gt;PartitionState#isRecordPreviouslyCompleted&lt;/code&gt;에서 &lt;code&gt;incompleteOffsets&lt;/code&gt;만 처리하게 필터링한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/PartitionState-isRecordPreviouslyCompleted.png" alt="PartitionState-isRecordPreviouslyCompleted.png" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;우아한 종료&lt;/h3&gt;

&lt;p&gt;마지막으로, 종료 시 어떤 일이 벌어지는지 알아보자. Parallel Consumer에는 &lt;code&gt;DrainingMode&lt;/code&gt;라는 것이 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/drainingmode.png" alt="drainingmode.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;DrainingMode.DRAIN&lt;/code&gt;, &lt;code&gt;DrainingMode.DONT_DRAIN&lt;/code&gt; 두 가지 방식이 있다. &lt;code&gt;DrainingMode.DRAIN&lt;/code&gt;은 queue에 존재하는 메시지까지 다 처리 후 종료하고 &lt;code&gt;DrainingMode.DONT_DRAIN&lt;/code&gt;은 queue에 들어간 메시지를 버린다. 두 방식 모두 종료 시 누적해서 마지막으로 처리한 오프셋에 대한 커밋은 한다.&lt;/p&gt;

&lt;p&gt;실제 어떻게 사용되는지 코드를 살펴보자. &lt;code&gt;AbstractParallelEoSStreamProcessor&lt;/code&gt;는 &lt;code&gt;java.io.Closeable&lt;/code&gt;를 구현하여 &lt;code&gt;close&lt;/code&gt; 메서드를 제공한다. &lt;code&gt;close&lt;/code&gt; 메서드를 타고 들어가면 &lt;code&gt;closeDontDrainFirst&lt;/code&gt;라는 메서드가 보인다. 이 메서드에서는 &lt;code&gt;DrainingMode&lt;/code&gt;라는 것을 &lt;code&gt;close&lt;/code&gt; 메서드에 넘긴다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-close.png" alt="AbstractParallelEoSStreamProcessor-close.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-closeDontDrainFirst.png" alt="AbstractParallelEoSStreamProcessor-closeDontDrainFirst.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;close&lt;/code&gt; 메서드를 타고 들어가면 &lt;code&gt;DrainingMode&lt;/code&gt;에 따라 다르게 분기하는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-close-drainmode.png" alt="AbstractParallelEoSStreamProcessor-close-drainmode.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;DrainingMode.DONT_DRAIN&lt;/code&gt;은 &lt;code&gt;shutdownTimeout&lt;/code&gt;에 &lt;code&gt;GRACE_PERIOD_FOR_OVERALL_SHUTDOWN&lt;/code&gt;만큼을 추가하여 기다린다. &lt;code&gt;DrainingMode.DRAIN&lt;/code&gt;의 경우 &lt;code&gt;drainTimeout&lt;/code&gt;만큼 추가로 기다린다. 각 분기에서 &lt;code&gt;transitionToDraining&lt;/code&gt;, &lt;code&gt;transitionToClosing&lt;/code&gt;를 호출하는데 이는 내부 state를 각각 &lt;code&gt;DRAINING&lt;/code&gt;이나 &lt;code&gt;CLOSING&lt;/code&gt;으로 바꾼다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-transitionToDraining.png" alt="AbstractParallelEoSStreamProcessor-transitionToDraining.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-transitionToClosing.png" alt="AbstractParallelEoSStreamProcessor-transitionToClosing.png" /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 상태를 바꾸고 &lt;code&gt;AbstractParallelEoSStreamProcessor#waitForClose&lt;/code&gt;를 호출한다. &lt;code&gt;AbstractParallelEoSStreamProcessor#waitForClose&lt;/code&gt; 내부를 보면 &lt;code&gt;controlThreadFuture.get()&lt;/code&gt;을 호출하는 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-waitForClose.png" alt="AbstractParallelEoSStreamProcessor-waitForClose.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;controlThreadFuture&lt;/code&gt;는 앞서 설명한 Controller Thread를 생성할 때 결과를 미리 Future로 바인딩해놓은 변수이다. Controller Thread는 state가 &lt;code&gt;CLOSED&lt;/code&gt;가 아니면 계속 도는데 state를 바꿔서 이를 종료하고 결과를 &lt;code&gt;controlThreadFuture&lt;/code&gt;에 받아서 종료를 확인한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-supervisorloop-down.png" alt="AbstractParallelEoSStreamProcessor-supervisorloop-down.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;AbstractParallelEoSStreamProcessor#controlLoop&lt;/code&gt; 메서드 내부에서 앞서 설정한 state에 따라 &lt;code&gt;AbstractParallelEoSStreamProcessor#drain&lt;/code&gt; 이나 &lt;code&gt;AbstractParallelEoSStreamProcessor#doClose&lt;/code&gt;를 호출하는 것을 볼 수 있다. &lt;code&gt;AbstractParallelEoSStreamProcessor#drain&lt;/code&gt; &lt;code&gt;AbstractParallelEoSStreamProcessor#doClose&lt;/code&gt; 내부에서 오프셋 커밋, 잔여 queue 처리 등의 작업을 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/AbstractParallelEoSStreamProcessor-controlloop-drain.png" alt="AbstractParallelEoSStreamProcessor-controlloop-drain.png" /&gt;&lt;/p&gt;

&lt;h2 id=""&gt;성능 비교&lt;/h2&gt;

&lt;p&gt;지금까지 Parallel Consumer가 어떻게 높은 병렬성을 달성하는지, 어떤 방식으로 순서를 보장하는지 알아보았다. 실제 성능이 어느 정도 차이날지 궁금하여 실제 동작하는 시스템을 일부 변경하여 성능 테스트를 진행해보았다.&lt;/p&gt;

&lt;p&gt;테스트 Topic에 8개의 파티션을 생성 후 8개 Kafka Consumer를 띄운 것과 2개의 파티션을 생성하여 Parallel Consumer의 순서 보장 방식별로 각각 2개의 컨슈머를 띄운 것으로 테스트했다. 각 컨슈머는 4코어 16메모리로 수행했다. Key의 경우 0~99 사이의 임의의 값을 할당했다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/parallel-consumer-performance-test.png" alt="parallel-consumer-performance-test.png" /&gt;&lt;/p&gt;

&lt;p&gt;성능 테스트 결과 Parallel Consumer Unordered, Key 방식이 8개의 Kafka Consumer를 띄운 것보다 오히려 빠르게 처리하는 것을 확인할 수 있었다. Unordered 방식과 Key 방식이 거의 유사한 결과가 나온 이유는 Key를 0~99 사의의 다양한 값으로 균등하게 퍼트렸기 때문으로 보인다. Key 개수는 결국 shard 개수와 비례하기 때문에 많은 Key가 균등하게 분배만 된다면 Unordered와 유사한 수치의 성능을 낼 수 있다.&lt;/p&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;p&gt;파티션을 늘리는 것이 항상 나쁜 것은 아니다. 트래픽도 적고 현재 파티션 수도 많지 않다는 가정 하에 단순히 파티션 1~2개 정도 더 늘리는 것으로 충분히 해결 가능한 상황도 있을 것이다. 단일 Kafka 메시지 처리 속도를 쉽게 향상시킬 수 있다면 먼저 그 부분을 개선하는 것이 좋다.&lt;/p&gt;

&lt;p&gt;단일 Kafka 메시지 처리 속도를 단기간에 향상시키기 어려운 상황에서 이미 파티션이 과도하게 늘어나 있어 파티션을 더 늘리기 부담스럽다면 Parallel Consumer는 좋은 선택지가 될 수 있다.&lt;/p&gt;

&lt;p&gt;다만 &lt;strong&gt;Partition&lt;/strong&gt; 순서 보장 방식은 기존 방식과 큰 차이가 없어 메리트가 없기 때문에 &lt;em&gt;*Key나 Unordered 순서 보장 방식을 사용할 수 있는 환경에서 사용하는 것을 권장한다. *&lt;/em&gt; 또한 Parallel Consumer가 트랜잭션 기능도 지원하지만 메시지가 정확히 1번만 전달되어야 하는 강한 제약 조건이 있는 환경에서는 권장하지 않는다. 오히려 디버깅에 어려움을 겪는 상황이 발생할 수 있다.&lt;/p&gt;

&lt;p&gt;참고로 Log&amp;amp;Metric 조직 내에서는 평균 하루 5억 건 이상의 메시지를 처리하는 Kafka Consumer 컴포넌트에서 &lt;strong&gt;Unordered&lt;/strong&gt; 방식으로 Parallel Consumer를 문제 없이 잘 활용하고 있다.&lt;/p&gt;

&lt;p&gt;Parallel Consumer는 이 글 작성 시점 기준 0.5.2.7이 최신 버전이다. 아직 메이저 버전이 나오지 않았기 때문에 추후 버전에서 변경이 많아질 수 있다. 하지만 큰 구조나 개념은 달라지지 않을 것이다. 이 글이 Parallel Consumer가 무엇인지, 어떤 상황에서 사용해야 하는지 이해하는 데 도움이 되었으면 좋겠다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>AOP in TypeScript</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/3010710" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/3010710</id>
    <updated>2023-10-17T18:42:00Z</updated>
    <content type="html">&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/IRp0iMGTSbQ?si=FMUuVMz5bvdg4Q-4" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;AOP(aspect-oriented programming)의 개념은 Spring을 비롯한 강력한 프레임워크의 존재로 인해 개발자들 사이에 널리 퍼져있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2023/09/0u1byw3c.png" alt="image" /&gt;&lt;/p&gt;

&lt;p&gt;그러나 여전히 애플리케이션 코드에 적용하는 경우는 많지 않습니다. 개발자에게 AOP를 도입하자고 한다면 아래와 같은 불만(단점)이 으레 나옵니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;코드를 작성하고 이해하는 데 시간이 더 걸린다.&lt;/li&gt;
&lt;li&gt;호출 관계나 생명 주기(life cycle)가 직접적으로 보이지 않아 디버깅이 어렵다.&lt;/li&gt;
&lt;li&gt;굳이 왜 해야 하는지 모르겠다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그래서 AOP는 프레임워크를 적극적으로 사용하는 대규모 애플리케이션에나 적합한 방법론으로 받아들여지고 있습니다. 하지만 Spring처럼 잘 만들어진 프레임워크를 보면 AOP를 도입하는 이유를 알 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;비즈니스 로직에 온전히 집중할 수 있으며 인터페이스와 로직을 통일할 수 있다.&lt;/li&gt;
&lt;li&gt;비즈니스 로직만 있으므로 테스트 및 모킹하기도 쉽다.&lt;/li&gt;
&lt;li&gt;프레임워크의 동작을 모르더라도 로직을 작성하는 데 문제가 없다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, 애플리케이션이라 하더라도 그 규모가 크고 공통된 인터페이스를 가진 부분이 많으며, 프로젝트 참여 인원이 커서 실력 및 이해도의 편차가 심할 경우 AOP는 상당한 강점이 될 수 있습니다. 시니어 개발자는 프레임워크를 작성하고 비즈니스 코드의 형식을 통일하며, 주니어 개발자는 상대적으로 쉬운 스펙의 구현 및 테스트에 집중하다 경험이 쌓인 후 프레임워크의 코드도 분석하며 자연스럽게 시니어로 성장을 기대할 수 있습니다.&lt;/p&gt;

&lt;h2 id="aopinjavascript"&gt;AOP in JavaScript&lt;/h2&gt;

&lt;p&gt;JavaScript도 Node.js의 등장과 함께 빠르게 발전하면서 복합 프레임워크의 수요가 발생했고 AOP를 위한 도구도 &lt;a href="https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Global_Objects/Proxy"&gt;&lt;code&gt;Proxy&lt;/code&gt;&lt;/a&gt;부터 표준에 추가되기 시작했다. 이후 메타 프로그래밍을 위해 &lt;a href="https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Global_Objects/Reflect"&gt;&lt;code&gt;Reflect&lt;/code&gt;&lt;/a&gt; 객체도 추가되었으며 현재는 &lt;a href="https://github.com/tc39/proposal-decorators"&gt;&lt;code&gt;Decorator&lt;/code&gt;&lt;/a&gt; 명세를 추가함으로써 완전한 선언형 AOP을 위한 표준을 준비하고 있다.&lt;/p&gt;

&lt;p&gt;앞서 백엔드 프레임워크인 nest.js 등에서도 발빠르게 데코레이터를 도입했다. 사실 NodeJS 백엔드 애플리케이션이 직접 데코레이터와 프레임워크를 작성할 필요가 있을 정도로 커졌다면 그렇게 하기보다는 MSA를 도입하여 애플리케이션 자체를 분할하는 것이 최근의 정석이다.&lt;/p&gt;

&lt;p&gt;프런트엔드 애플리케이션 역시 시간이 지남에 따라 규모가 커져 AOP 프레임워크의 필요성이 부각되고 있다. 이 글에서는 백엔드와 프런트엔드를 모두 고려하겠다.&lt;/p&gt;

&lt;p&gt;데코레이터 명세는 Stage 3에서 형태가 크게 변했다. ClassMethodDecorator를 기준으로 인터페이스 형태를 비교해보면 다음과 같다.&lt;/p&gt;

&lt;h3 id="stage2"&gt;Stage 2 명세&lt;/h3&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;declare type MethodDecorator = &amp;lt;T&amp;gt;(target: Object, propertyKey: string | symbol, descriptor: TypedPropertyDescriptor&amp;lt;T&amp;gt;) =&amp;gt; TypedPropertyDescriptor&amp;lt;T&amp;gt; | void;  
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export function Log(_target: Object, name: string | symbol, descriptor: PropertyDescriptor) {  
    const origin = descriptor.value;

    descriptor.value = function (...args: any[]) {
        const returned = origin.call(this, ...args);

        console.info(`${name} returned: ${JSON.stringify(returned)}`);
        return returned;
    };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stage 2 명세는 &lt;code&gt;PropertyDescriptor&lt;/code&gt;가 인자로 제공되었기에 &lt;code&gt;descriptor.value&lt;/code&gt;를 조작하는 방식으로 함수를 래핑했다. 그러나 TC39 포럼은 &lt;code&gt;PropertyDescriptor&lt;/code&gt;가 메타 프로그래밍 도구로서 확장하는 데 한계가 있다고 보고 명시적인 도구는 &lt;code&gt;Reflect&lt;/code&gt; 객체로, 데코레이터 명세로는 &lt;code&gt;DecoratorContext&lt;/code&gt;를 제공하는 방향으로 수정했다.&lt;/p&gt;

&lt;h3 id="stage3"&gt;Stage 3 명세&lt;/h3&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;type ClassMethodDecorator = (value: Function, context: {  
  kind: "method";
  name: string | symbol;
  access: { get(): unknown };
  static: boolean;
  private: boolean;
  addInitializer(initializer: () =&amp;gt; void): void;
}) =&amp;gt; Function | void;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stage 3에서는 &lt;code&gt;DecoratorContext&lt;/code&gt; 객체가 &lt;code&gt;kind&lt;/code&gt;, &lt;code&gt;name&lt;/code&gt; 및 modifier 정보도 전달하며 확장 가능한 구조로 설계되었다. 실제로 이후 &lt;code&gt;metadata&lt;/code&gt; 필드가 추가되어 기존에 &lt;code&gt;symbol&lt;/code&gt;을 통해 구현하던 메타데이터 버킷을 표준 명세로 정의했다. 또한 반환하는 함수로 기존 함수를 대체하도록 하여 위의 &lt;code&gt;@Log&lt;/code&gt; 데코레이터는 아래와 같이 구현할 수 있게 되었다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export type DecoratableFunction = (...args: any[]) =&amp;gt; any;

export function Log(func: DecoratableFunction, context?: ClassMethodDecoratorContext): void | DecoratableFunction {  
    return function (this: object, ...args: any[]): any {

        const originReturn = func.call(this, ...args);

        console.info(`${String(context?.name)} returned : ${JSON.stringify(originReturn)}`);

        return originReturn;
    };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id="typescript"&gt;TypeScript의 데코레이터&lt;/h2&gt;

&lt;p&gt;TypeScript는 5.0 버전부터 Stage 3 데코레이터 명세를 지원하며, &lt;code&gt;experimentalDecorators&lt;/code&gt; 플래그를 켜야 데코레이터를 지원했던 4.x 버전과는 달리 기본적으로 Stage 3 데코레이터 명세를 지원하고 &lt;code&gt;experimentalDecorators&lt;/code&gt; 플래그를 켜면 Stage 2 명세를 지원한다. 5.2 버전부터는 메타데이터 컨텍스트 명세를 지원하기 시작했으며 현재(23년 9월) 기준 5.2 정식 버전을 제공하고 있다. 이 글에서는 Stage 3 데코레이터와 메타데이터 컨텍스트를 활용하여 선언적 AOP 프레임워크를 작성하는 간단한 예를 소개하겠다.&lt;/p&gt;

&lt;p&gt;애플리케이션의 기능은 웹소켓 메시지 송수신기를 통해 특정 메시지를 수신하는 클래스를 작성하며, 프레임워크는 receiver 클래스가 웹소켓 구현부의 코드나 별도의 인스턴스화 없이 클래스 선언만으로 메시지 수신이 가능한 형태를 구현하는 것이다.&lt;/p&gt;

&lt;p&gt;최종 비즈니스 코드의 형태는 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;// JoinedMessageHandle.ts

@MessageReceiver
export class JoinedMessageHandle{  
    @Recv('JOINED')
    public onJoined(msg:JoinedMessage):void{
        console.info(`event: ${msg.event}`);
        console.info(`txid: ${msg.txid}`);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Spring에서 &lt;code&gt;@Bean&lt;/code&gt;을 선언하는 것과 유사하게 클래스 확장, 핸들러 함수 또는 별도의 매니페스트 없이 데코레이터 선언만으로 웹소켓 메시지 처리 클래스에 대한 IoC를 구현하도록 하겠다.&lt;/p&gt;

&lt;h3 id="log"&gt;@Log 데코레이터&lt;/h3&gt;

&lt;p&gt;먼저 메서드 실행 시 인자와 결과값을 로깅하는 간단한 형태의 데코레이터부터 만들어 보자. 이러한 데코레이터는 어떠한 애플리케이션에서도 필요할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export type DecoratableFunction = (...args: any[]) =&amp;gt; any;

export function Log(func: DecoratableFunction, context?: ClassMethodDecoratorContext): void | DecoratableFunction {  
    return function (this: object, ...args: any[]): any {
        if (args.length) {
            console.info(`${String(context?.name)} parameters`);
            console.info(JSON.stringify(args));
        }

        const originReturn = func.call(this, ...args);

        console.info(`${String(context?.name)} returned : ${JSON.stringify(originReturn)}`);

        return originReturn;
    };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;테스트 코드는 다음과 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;import { Log } from './@Log';

describe('@Log decorator', () =&amp;gt; {  
    it('@Log to log parameter and return value', () =&amp;gt; {
        class Foo {
            @Log
            public foo1(): number {
                return 1;
            }

            @Log
            public foo2(a: number, b: number): number {
                return a + b;
            }
        }

        const myFoo = new Foo();

        myFoo.foo1();
        myFoo.foo2(2, 3);
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;@Log decorator
foo1 returned : 1  
foo2 parameters  
[2,3]
foo2 returned : 5  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;특정 메서드는 디버깅 상황에서만 로그를 남기고 싶은 경우도 있다. 이는 데코레이터에 인자를 주입하여 구현할 수 있다. 데코레이터에 인자를 주입하려면 데코레이터 함수의 형태도 달라져야 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export const enum Env {  
    DEV = 'development',
    PRODUCTION = 'production',
}
export function Log(env?: Env): ClassMethodDecorator {  
    return function (func: DecoratableFunction, context?: ClassMethodDecoratorContext): void | DecoratableFunction {
        return function (this: object, ...args: any[]): any {
            if (!env || process.env.NODE_ENV === env) {
                if (args.length) {
                    console.info(`${String(context?.name)} parameters`);
                    console.info(JSON.stringify(args));
                }
            }
            const originReturn = func.call(this, ...args);

            if (!env || process.env.NODE_ENV === env) {
                console.info(`${String(context?.name)} returned : ${JSON.stringify(originReturn)}`);
            }

            return originReturn;
        };
    };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;@Log(Env.DEV)
public foo2(a: number, b: number): number {  
    return a + b;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;foo2()&lt;/code&gt;는 &lt;code&gt;development&lt;/code&gt; 환경에서만 로깅한다.&lt;/p&gt;

&lt;h3 id="send"&gt;@Send 데코레이터&lt;/h3&gt;

&lt;p&gt;이번에는 조금 복잡한 형태의 데코레이터를 작성해보자. 웹소켓을 통해 메시지를 전송하는 애플리케이션이 있다면 보통 웹소켓 기능을 구현한 클래스를 아래와 같이 작성할 것이다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export interface Message {  
    event: string;
    txid: string;
}

export interface JoinMessage extends Message {  
    event: 'JOIN';
    userId: string;
}

export class MessageTranceiver {  
        private _connected = false;
    private _ws: WebSocket;

    public static instance = new MessageTranceiver();

    private constructor() { }

        public async connect(): Promise&amp;lt;void&amp;gt; {
        if (this._connected) {
            return;
        }

        return new Promise&amp;lt;void&amp;gt;((res) =&amp;gt; {
            this._ws = new WebSocket(DEFAULT_WS_URL);
            this._ws.addEventListener('open', () =&amp;gt; {
                this._connected = true;
                res();
            });
        });
    }

    public send(msg: Message): void {
        this._ws.send(JSON.stringify(msg));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export class JoinMessageHandler {  
    public constructor(private _userId: string) {}

    public join(): JoinMessage {
        const txid = v4();
        const joinMessage = {
            event: 'JOIN',
            txid,
            userId: this._userId,
        } as JoinMessage;

        MessageTranceiver.instance.send(joinMessage);

        return joinMessage;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이를 &lt;code&gt;@Send&lt;/code&gt; 데코레이터를 통해 결과를 항상 웹소켓으로 전송하도록 할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;type DecorateTargetFunction = (...args: any[]) =&amp;gt; any;

export function Send(_target: DecorateTargetFunction): DecorateTargetFunction {  
    return function (...args: any[]): any {
        const origin = _target(...args);

        if (typeof origin.then === 'function') {
            origin.then((result: any) =&amp;gt; {
                MessageTranceiver.instance.send(result as Message);
            });
        } else {
            MessageTranceiver.instance.send(origin as Message);
        }

        return origin;
    };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;import { expect } from 'chai';  
import { Server } from 'mock-socket';

describe('@Send', () =&amp;gt; {  
    let fakeServer: Server;

    before(() =&amp;gt; {
        fakeServer = new Server(DEFAULT_WS_URL);
    });
    after(() =&amp;gt; {
        fakeServer.stop();
    });

    it('@Send method will send returned message', (done) =&amp;gt; {
        const randomTxid = v4();
        const randomUserId = v4();

        fakeServer.on('connection', (socket) =&amp;gt; {
            socket.on('message', (data) =&amp;gt; {
                const { event, txid, userId } = JSON.parse(data as string) as JoinMessage;

                expect(event).to.be.eq('JOIN');
                expect(txid).to.be.eq(randomTxid);
                expect(userId).to.be.eq(randomUserId);
                done();
            });
        });

        MessageTranceiver.instance.connect().then(() =&amp;gt; {
            class JoinMessageHandler {
                @Send
                public join(): JoinMessage {
                    return {
                        event: 'JOIN',
                        txid: randomTxid,
                        userId: randomUserId,
                    };
                }
            }

            const handler = new JoinMessageHandler();

            handler.join();
        });
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="recv"&gt;@Recv 데코레이터&lt;/h3&gt;

&lt;p&gt;웹소켓으로 전달된 데이터를 파싱하여 특정 메시지인 경우 수신하는 &lt;code&gt;@Recv&lt;/code&gt; 데코레이터를 만들어 보자. &lt;code&gt;@Send&lt;/code&gt;는 함수를 단순 래핑하여 &lt;code&gt;MessageTransceiver.send()&lt;/code&gt;만 호출하면 되므로 &lt;code&gt;@Log&lt;/code&gt;와 구현 형태에 큰 차이는 없다. 반대로 특정 메시지를 수신하기 위한 &lt;code&gt;@Recv&lt;/code&gt;는 클래스 인스턴스를 &lt;code&gt;MessageTranceiver&lt;/code&gt;에 listener로 등록해야 하므로 함수를 래핑하는 것만으로는 불가능하다.&lt;/p&gt;

&lt;p&gt;먼저 &lt;code&gt;MessageTransceiver.addListener&lt;/code&gt; 메서드를 구현한다. 세부적인 코드는 이 글의 주제와 연관성이 적어 생략하겠다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export class MessageTranceiver {

        ...

    public addListener(event: string, listener: (msg: Message) =&amp;gt; any);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;상기했듯 메타데이터 데코레이터는 서명이 변경되어 PropertyDescriptor는 이용할 수 없게 되었다. 대신 &lt;code&gt;context.addInitializer()&lt;/code&gt; API가 추가되어 클래스 생성자 호출 후 인스턴스에 작업을 추가할 수 있다. &lt;code&gt;initializer&lt;/code&gt;는 메서드 데코레이터가 추가될 때마다 호출되기 때문에 중복 호출 시 적절한 처리를 해야 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export function Recv(type: string) {  
    return function (_target: DecorateTargetFunction, context: ClassMemberDecoratorContext): void {
        context.addInitializer(function () {
            MessageTranceiver.instance.addListener(type, (...args: any[]) =&amp;gt; {
                _target.call(this, ...args);
            });
        });
    };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;@Recv&lt;/code&gt;는 수신할 이벤트 타입을 입력받아야 하므로 &lt;code&gt;@Send&lt;/code&gt;와는 달리 &lt;code&gt;@Recv(event:string)&lt;/code&gt;의 서명을 가지도록 구현한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;// @Recv.spec.ts
import { Server } from 'mock-socket';

describe('@Recv decorator', () =&amp;gt; {  
    let fakeServer: Server;

    before(() =&amp;gt; {
        fakeServer = new Server(DEFAULT_WS_URL);
    });

    after(() =&amp;gt; {
        fakeServer?.stop();
    });

    it('@Recv to listen message', (done) =&amp;gt; {

        class Foo {
            @Recv('JOINED')
            public onJoined(msg: JoinedMessage) {
                const { event, userId } = msg;

                expect(event).to.be.eq('JOINED');
                expect(userId).to.be.a('string');
                expect(userId.length).to.be.gte(1);
                done();
            }
        }

        fakeServer.on('connection', (socket) =&amp;gt; {
            socket.send(
                JSON.stringify({
                    event: 'JOINED',
                    txid: v4(),
                    userId: v4(),
                } as JoinedMessage)
            );
        });

        MessageTranceiver.instance.connect();
        const myFoo = new Foo();
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위와 같이 &lt;code&gt;@Recv&lt;/code&gt;를 사용하면 인스턴스를 만드는 것만으로도 웹소켓 메시지를 수신할 수 있게 된다.&lt;/p&gt;

&lt;h3 id=""&gt;메시지 프레임워크&lt;/h3&gt;

&lt;p&gt;마지막으로는 메타데이터를 사용해 클래스 데코레이터를 선언한 모듈을 프레임워크에서 인스턴스를 관리하도록 비즈니스 코드에서 완전한 관점 분리를 구현해보자.&lt;/p&gt;

&lt;p&gt;위에서 메시지 송수신 로직은 관점 분리했으나 테스트 코드에서 보이듯이 여전히 클래스의 인스턴스화는 직접 호출해야 한다. 즉, 비즈니스 로직 어딘가에 receiver 클래스 인스턴스를 관리하는 부분이 있어야 한다.&lt;/p&gt;

&lt;p&gt;선언형 프레임워크에는 클래스 인스턴스의 생성 및 생명 주기에 대한 IoC 기능이 있다. 이를 위해 비즈니스 로직 코드에서 작성한 클래스를 프레임워크에서 인스턴스화하려면 클래스 모듈에 대한 암시적 접근이 가능해야 한다. 현재 JavaScript 및 Node.js 런타임은 이러한 모듈 접근법을 제공하고 있지 않으므로 백엔드, 프런트엔드에서 각각 서드파티 툴을 이용해 선언형 클래스 프레임워크를 구현해 보도록 하겠다.&lt;/p&gt;

&lt;p&gt;우선 receiver 클래스의 인스턴스를 프레임워크 수준에서 직접 관리할 것이므로 &lt;code&gt;@Recv&lt;/code&gt; 데코레이터의 initializer를 제거하고 메서드의 &lt;code&gt;name&lt;/code&gt;만을 &lt;code&gt;context.metadata&lt;/code&gt;에 저장한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export const RECEIVER_SYMBOL = Symbol.for('Symbol.MessageReceiver');

export function Recv(type: string) {  
    return function (_target: DecorateTargetFunction, context: ClassMemberDecoratorContext): void {
        const receiverMap = (context.metadata[RECEIVER_SYMBOL] ??= {}) as Record&amp;lt;string, PropertyKey[]&amp;gt;;

        const rcvs: PropertyKey[] = (receiverMap[type] ??= []);

        if (!rcvs.includes(context.name)) {
            rcvs.push(context.name);
        }
    };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;@MessageReceiver&lt;/code&gt; 데코레이터를 선언한 클래스는 receiver 함수를 가지고 있음을 표시한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;export const MESSAGE_RECEIVER_SYMBOL = Symbol.for('Symbol.MessageReceiver');

export function MessageReceiver(cls: new (...args: any[]) =&amp;gt; void, context: ClassDecoratorContext) {  
    context.metadata[MESSAGE_RECEIVER_SYMBOL] = true;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;MessageFramework&lt;/code&gt;에서는 임의의 모듈을 로드하여 &lt;code&gt;@MessageReceiver&lt;/code&gt; 데코레이터가 선언된 클래스를 추출하고 인스턴스화한다.&lt;/p&gt;

&lt;p&gt;백엔드에서는 &lt;code&gt;glob&lt;/code&gt;을 통해 클래스 모듈을 암시적으로 로드하여 클래스 데코레이터를 실행한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;import { glob } from 'glob';  
import { MessageTranceiver } from '../modules/MessageTranceiver';  
import { MESSAGE_RECEIVER_SYMBOL } from '../reflect/@MessageReceiver';  
import { RECEIVER_SYMBOL } from '../reflect/@Recv';

export class MessageFramework {  
    public static instance = new MessageFramework();

    public async initialize() {
        const paths = await glob('**/*.js', {
            ignore: ['node_modules/**', '**/*.spec.*', 'transpiled/framework/MessageFramework.test.js'],
        });

        const cwd = process.cwd();
        const promises = paths.map(async (modulePath) =&amp;gt; {
            const exports = await import(`${cwd}/${modulePath}`);

            return new Promise&amp;lt;void&amp;gt;((res) =&amp;gt; {
                Object.values(exports).forEach((ClassCtor: any) =&amp;gt; {
                    if (!ClassCtor[Symbol.metadata]?.[MESSAGE_RECEIVER_SYMBOL]) {
                        return;
                    }

                    const instance = new ClassCtor();

                    const receiversMap = (ClassCtor[Symbol.metadata][RECEIVER_SYMBOL] ??= {}) as Record&amp;lt;
                        string,
                        PropertyKey[]
                    &amp;gt;;

                    Object.entries(receiversMap).forEach(([event, methodNames]: [string, PropertyKey[]]) =&amp;gt; {
                        methodNames.forEach((method) =&amp;gt; {
                            MessageTranceiver.instance.addListener(event, instance[method].bind(instance));
                        });
                    });
                });

                res();
            });
        });

        return Promise.all(promises);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;테스트 코드 내에서 클래스를 선언하면 위의 암시적 접근이 불가능하므로 MessageReceiver 클래스는 별도 모듈에 작성한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;// JoinedMessageHandle.ts

@MessageReceiver
export class JoinedMessageHandle{  
    @Recv('JOINED')
    public onJoined(msg:JoinedMessage):void{
        console.info(`event: ${msg.event}`);
        console.info(`txid: ${msg.txid}`);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;MessageFramework&lt;/code&gt;의 테스트 코드는 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;// MessageFramework.test.js

(async () =&amp;gt; {
    const server = new Server(DEFAULT_WS_URL);

    server.on('connection', (socket) =&amp;gt; {
        socket.send(
            JSON.stringify({
                event: 'JOINED',
                txid: v4(),
            } as JoinedMessage)
        );
    });

    await MessageFramework.instance.initialize();
    await MessageTranceiver.instance.connect();
    server.stop();
})();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;실행 결과는 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;event: JOINED  
txid: 8d75b275-b86a-4d3a-aa8a-09a50b564089  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;비즈니스 로직 코드에서 &lt;code&gt;JoinedMessageHandle&lt;/code&gt;를 인스턴스화하지 않더라도 receiver 함수가 동작함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;프런트엔드에서는 &lt;code&gt;glob&lt;/code&gt;을 통한 파일 접근 대신 웹팩의 &lt;code&gt;require.context&lt;/code&gt;를 통해 미리 번들링된 모듈을 런타임에 로드한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;import { MessageTranceiver } from '../modules/MessageTranceiver';  
import { MESSAGE_RECEIVER_SYMBOL } from '../reflect/@MessageReceiver';  
import { RECEIVER_SYMBOL } from '../reflect/@Recv';

export class MessageFramework {  
    public static instance = new MessageFramework();

    public async initialize() {
        const context = (require as any).context('../', true, /^(?!.*\.spec\.ts$).*\.ts$/);

        const promises = context.keys().map((mod: string) =&amp;gt; {
            if (mod.endsWith('test.ts')) {
                return Promise.resolve();
            }

            const exports = context(mod);

            return new Promise&amp;lt;void&amp;gt;((res) =&amp;gt; {
                Object.values(exports).forEach((ClassCtor: any) =&amp;gt; {
                    if (!ClassCtor[Symbol.metadata]?.[MESSAGE_RECEIVER_SYMBOL]) {
                        return;
                    }

                    const instance = new ClassCtor();

                    const receiversMap = (ClassCtor[Symbol.metadata][RECEIVER_SYMBOL] ??= {}) as Record&amp;lt;
                        string,
                        PropertyKey[]
                    &amp;gt;;

                    Object.entries(receiversMap).forEach(([event, methodNames]: [string, PropertyKey[]]) =&amp;gt; {
                        methodNames.forEach((method) =&amp;gt; {
                            MessageTranceiver.instance.addListener(event, instance[method].bind(instance));
                        });
                    });
                });

                res();
            });
        });

        return Promise.all(promises);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;테스트 코드 및 실행 결과는 백엔드의 경우와 같다.&lt;/p&gt;

&lt;p&gt;이로써 비즈니스 로직 개발자는 클래스 데코레이터를 선언하는 것만으로 인스턴스 생명 주기를 고려할 필요 없이 선언적인 형태로 웹소켓 메시지 receiver 클래스를 작성할 수 있게 되었다.&lt;/p&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;p&gt;메타데이터 컨텍스트 덕분에 데코레이터를 통한 메타데이터 처리 방법을 통일할 수 있게 되면서 TypeScript에서 엔터프라이즈급 프레임워크를 위한 AOP 방법론도 체계화될 것으로 기대된다. 필자의 팀에서도 AOP를 프로덕션 애플리케이션에 적극적으로 활용하고 있으며 추후 복잡한 애플리케이션을 AOP 프레임워크를 통해 체계화한 결과물을 발표할 수 있도록 준비 중이다.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>FE News 10월 소식</title>
    <link rel="alternate" href="https://d2.naver.com/news/8498532" />
    <category term="news" />
    <id>https://d2.naver.com/news/8498532</id>
    <updated>2023-10-05T19:18:48Z</updated>
    <content type="html">&lt;p&gt;&lt;img src="/content/images/2023/09/-----------2023-07-06------4-16-49-1.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id="10"&gt;&lt;strong&gt;[10월 주요내용]&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src="/content/images/2023/10/-----------2023-10-05------7-11-17.png" alt="" /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bun 1.0 릴리스. 진짜 Node.js 보다 빠를까?&lt;/li&gt;
&lt;li&gt;타입스크립트 다큐멘터리: TypeScript의 비하인드 스토리&lt;/li&gt;
&lt;li&gt;탈 타입스크립트? Turbo와 Svelte 개발에는 타입스크립트를 사용하지 않는다는데, 우리도 타입스크립트를 벗어날 때인가?&lt;/li&gt;
&lt;li&gt;2023.09를 끝으로 Node 16 LTS 지원 종료&lt;/li&gt;
&lt;li&gt;Astro 3.0&lt;/li&gt;
&lt;li&gt;Introducing runes&lt;/li&gt;
&lt;li&gt;Laws Of UX
&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="fenews10httpsgithubcomnaverfenewsblobmasterissues202310md"&gt;&lt;strong&gt;&lt;a href="https://github.com/naver/fe-news/blob/master/issues/2023-10.md"&gt;&gt;&gt; FE News 10월 보러가기&lt;/a&gt;&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;h5 id="fenewsbr"&gt;&lt;strong&gt;◎ FE News란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;네이버 FE 엔지니어들이 엄선한 양질의 FE 및 주요한 기술 소식들을 큐레이션해 공유하는 것을 목표로 하며, 이를 통해 국내 개발자들에게 지식 공유에 대한 가치 인식과 성장에 도움을 주고자 하는 기술소식 공유 프로젝트 입니다.&lt;/p&gt;
  
  &lt;p&gt;매월 첫째 주 수요일, 월 1회 발행 되고 있으니 많은 관심 부탁드립니다.&lt;br/&gt;
  ▷ &lt;a href="https://fenews.substack.com/embed"&gt;구독하기&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://forms.gle/hsYv2kwJjHTx2SaSA" target="_blank"&gt; &lt;img src="/content/images/2023/09/-----------2023-09-15------2-25-26.png" alt="" title="" /&gt;&lt;/a&gt;&lt;/p&gt;</content>
  </entry>
</feed>

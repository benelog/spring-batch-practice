<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>D2 Blog</title>
  <link rel="alternate" href="https://d2.naver.com" />
  <id>https://d2.naver.com/blog.atom</id>
  <icon>https://d2.naver.com/favicon.ico</icon>
  <updated>2025-08-13T02:07:36Z</updated>
  <entry>
    <title>[FE Ground] 'AI x Front-End: 코딩의 미래를 묻다' 밋업이 열립니다.</title>
    <link rel="alternate" href="https://d2.naver.com/news/6518915" />
    <category term="news" />
    <id>https://d2.naver.com/news/6518915</id>
    <updated>2025-08-13T11:07:21Z</updated>
    <content type="html">&lt;p&gt;안녕하세요! 네이버 프런트엔드 개발자 모임 &lt;a href="https://netil.github.io/slides/DAN24/"&gt;H26y&lt;/a&gt;입니다.&lt;/p&gt;

&lt;p&gt;매달 &lt;a href="https://github.com/naver/fe-news"&gt;FE News&lt;/a&gt;를 통해 찾아뵈었는데요, 
8월 29일(금), &lt;strong&gt;“[FE Ground] AI × Front-End: 코딩의 미래를 묻다.”&lt;/strong&gt;라는 주제로 첫 공개 개발자 밋업을 진행하게 되어 안내드립니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/08/88a2b32c-0ec6-4ba5-9ea1-e1f8362e0ea7_1812x1194.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;&lt;strong&gt;진행일시&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;일시: 8월 29(금), 19시 ~ 21시&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;건물 보안 지침 상 사전 입장이 불가하며, &lt;strong&gt;19시 부터 입장이 가능&lt;/strong&gt;합니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;장소&lt;/strong&gt;: &lt;a href="https://naver.me/x8tpI6kP"&gt;NAVER D2SF 강남&lt;/a&gt; (삼성화재 서초타워 18층)&lt;/li&gt;
&lt;li&gt;[참고] 간단히 저녁 식사 할 수 있는 샌드위치와 음료가 제공됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;&lt;strong&gt;세션안내&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;19:00 ~ 19:10 입장 &amp;amp; 오프닝&lt;/li&gt;
&lt;li&gt;19:10 ~ 19:25 AI 도구로 2배 속도 내는 프론트 개발팀 만들기 / 장기효&lt;/li&gt;
&lt;li&gt;19:25 ~ 19:45 우리가 알고 있는 프로그래밍의 종말: 현실적 AI / 박재성&lt;/li&gt;
&lt;li&gt;19:45 ~ 20:00 Code Wars: The Last Coder: AI가 코드를 쓰는 세상, 개발자의 역할은 어떻게 바뀌는가? / 차성원&lt;/li&gt;
&lt;li&gt;20:00 ~ 20:30 패널토론: AI × Front-End: 코딩의 미래는 어떻게 될까?
&lt;ul&gt;&lt;li&gt;AI 시대, 시니어와 주니어의 성장 경로는 어떻게 달라질까?&lt;/li&gt;
&lt;li&gt;AI 시대, 프론트엔드 개발자의 역할은 확장되고 있는가?&lt;/li&gt;
&lt;li&gt;프론트엔드 개발, AI 환경에 수혜자인가 희생자인가?&lt;/li&gt;
&lt;li&gt;AI 시대에 개발자는 몇명이나 살아남을 것인가?&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;20:30 ~ 21:00 네트워킹 및 행사 종료&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;&lt;strong&gt;신청방법&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;다음의 신청폼에 신청 정보를 입력해 주시면, 추첨을 통해 총 50분을 선정할 예정입니다. 
결과는 8월 21일(목), 19시 전까지 &lt;strong&gt;선정되신 분들께만 개별 메일을 통해&lt;/strong&gt; 안내 드릴 예정입니다.&lt;/p&gt;

&lt;p&gt;장소가 한정되어 있어 꼭 참석이 가능하신 경우에만 신청 부탁드립니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;참가 신청&lt;/strong&gt;: &lt;a href="https://naver.me/xHmnbSaz"&gt;https://naver.me/xHmnbSaz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;신청기간: 2025년 8월 20일(수), 19:00까지&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;&lt;strong&gt;사전안내&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;현장 등록은 불가하며, 사전 신청 및 참가 확정자만 입장 가능합니다.&lt;/li&gt;
&lt;li&gt;건물 보안 방침에 따라, 1층에서 신청자 확인 후 입장과 인솔을 통해 층 이동이 가능하며, 행사 시간동안 외부 출입과 다른 장소로 이동은 불가합니다.&lt;/li&gt;
&lt;li&gt;건물 주차는 지원되지 않습니다.&lt;/li&gt;
&lt;li&gt;건물 관리 방안에 따라 냉방 가동이 되지 않으며, 선풍기가 배치될 예정입니다. 사전 양해 부탁드립니다.&lt;/li&gt;
&lt;li&gt;세션 및 진행 시간은 사전 고지 없이 변경될 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;</content>
  </entry>
  <entry>
    <title>FE News 25년 8월</title>
    <link rel="alternate" href="https://d2.naver.com/news/3554080" />
    <category term="news" />
    <id>https://d2.naver.com/news/3554080</id>
    <updated>2025-08-07T11:03:54Z</updated>
    <content type="html">&lt;p&gt;&lt;img src=https://d2.naver.com/content/images/2023/07/-----------2023-07-06------4-16-49.png&gt;&lt;/p&gt;

&lt;h2 id=""&gt;주요소식&lt;/h2&gt;

&lt;p&gt;&lt;img src="/content/images/2025/08/-----------2025-08-07-------10-58-37.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;25년 8월 소식에서는 다음과 같은 유용한 정보들을 만나보실 수 있습니다.&lt;/p&gt;

&lt;h4 id=""&gt;링크 &amp;amp; 읽을거리&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JSNation 2025&lt;/strong&gt;: GitNation이 주최하는 JavaScript 컨퍼런스로, JavaScript관련된 다양한 주제의 세션들을 볼 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tech-Verse 2025&lt;/strong&gt;: 라인야후애서 주최한 최신 기술 트렌드와 개발 방법론을 공유하는 개발자 중심의 컨퍼런스다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI Design Guide&lt;/strong&gt;: AI와 디자인의 결합으로 가능한 새로운 워크플로와 방법론을 소개하는 리소스 컬렉션으로, 프롬프트 작성법부터 디자인 자동화까지 실용적인 팁을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The New Code — Sean Grove, OpenAI&lt;/strong&gt;: AI 시대에 가장 가치 있는 기술은 코드 작성이 아닌 의도를 정확히 전달하는 것이라는 관점을 제시한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Can AI Replace Web Developers?&lt;/strong&gt;: "AI가 웹 개발자를 대체할 수 있을까?"라는 주제를 다룬 글이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ultimate Guide to Vibe Coding&lt;/strong&gt;: AI 시대의 새로운 코딩 접근 방식인 'Vibe Coding'에 대한 가이드를 제공한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;튜토리얼&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Claude Code 마스터하기&lt;/strong&gt;: 카카오의 황민호님이 작성한 Claude를 개발 환경에서 효과적으로 활용하는 방법에 대한 포괄적인 가이드를 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reactive State Manager With Proxies&lt;/strong&gt;: JavaScript의 Proxy 객체를 활용해 Reactive State Manager를 직접 구현하는 과정을 소개한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jsdate.wtf&lt;/strong&gt;: JavaScript의 Date 객체가 얼마나 혼란스럽고 예측하기 어려운지 보여주는 인터랙티브 웹사이트이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A Friendly Introduction to SVG&lt;/strong&gt;: SVG의 기본 개념부터 실용적인 활용법까지 친근하게 소개하는 포괄적인 가이드를 제공한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;코드와 도구&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;n8n - Flexible AI workflow automation for technical teams&lt;/strong&gt;: 프런트엔드 개발자들이 API 통합과 워크플로우 자동화를 위해 주목해야 할 오픈소스 워크플로우 자동화 플랫폼이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Code Canvas App&lt;/strong&gt;: VSCode 확장 프로그램으로, 코드 시각화와 구조화에 혁신적인 접근 방식을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Awesome Context Engineering&lt;/strong&gt;: AI 개발에 있어 중요성이 날로 커지고 있는 '컨텍스트 엔지니어링'에 관한 포괄적인 리소스 모음을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bruno - API Client&lt;/strong&gt;: Postman과 Insomnia의 대안으로 등장한 API 탐색과 테스트를 위한 오픈소스 IDE이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="fenews258httpsgithubcomnaverfenewsblobmasterissues202508md"&gt;&lt;a href="https://github.com/naver/fe-news/blob/master/issues/2025-08.md"&gt;&gt;&gt; FE News 25년 8월 소식 보러가기&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;◎ FE News란?&lt;/strong&gt;&lt;br/&gt;
  네이버 FE 엔지니어들이 엄선한 양질의 FE 및 주요한 기술 소식들을 큐레이션해 공유하는 것을 목표로 하며, 이를 통해 국내 개발자들에게 지식 공유에 대한 가치 인식과 성장에 도움을 주고자 하는 기술소식 공유 프로젝트 입니다.&lt;/p&gt;
  
  &lt;p&gt;매월 첫째 주 수요일, 월 1회 발행 되고 있으니 많은 관심 부탁드립니다.&lt;br/&gt;
  &lt;a href="https://fenews.substack.com/embed"&gt;▷ 구독하기&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>실시간 유효 광고 선정을 위한 Flink에서 Apache Paimon 도입기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/2766731" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/2766731</id>
    <updated>2025-07-31T15:46:53Z</updated>
    <content type="html">&lt;p&gt;저희 팀에서는 Apache Spark를 기반으로 배치 및 실시간 처리를 수행하는 AI 데이터 파이프라인을 구축하고 있습니다. 그 과정에서 Spark의 마이크로 배치 아키텍처보다 더 효율적이고 생산적으로 실시간 데이터를 수집하고 집계하는 방법을 고민해왔습니다.&lt;/p&gt;

&lt;p&gt;이 글에서는 Apache Flink와 Apache Paimon을 도입하여 빠르고 안정적인 데이터 처리 파이프라인을 개발한 경험을 공유하고, 그 과정에 사용한 기술과 유용한 팁을 소개합니다.&lt;/p&gt;

&lt;h2 id="advoostshopping"&gt;ADVoost Shopping에서 실시간으로 유효 광고를 선정하는 방법&lt;/h2&gt;

&lt;p&gt;먼저 ADVoost Shopping 과제에서 실시간으로 유효 광고를 선정하기 위해 구축한 파이프라인에서 유효 광고 애셋 그룹 선정 파이프라인, 상품 광고 매핑 업데이트 파이프라인, 로그 수집 및 집계 파이프라인을 소개하겠습니다.&lt;/p&gt;

&lt;h3 id="paimon"&gt;Paimon을 활용한 실시간 유효 광고 선정 아키텍처&lt;/h3&gt;

&lt;p&gt;AI Serving API가 광고를 빠르게 조회할 수 있도록, 실시간으로 유효 광고를 선정해 Feature Store에 적재하는 아키텍처입니다.&lt;/p&gt;

&lt;h4 id=""&gt;유효 광고 애셋 그룹 선정&lt;/h4&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/1-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;가장 먼저, 유효 광고 선정에 필요한 메타성 테이블을 구성하기 위해, 광고 정보 CDC 데이터를 Kafka로부터 consume해서 Flink를 사용해 Paimon에 적재합니다. 이 과정에서 특정 테이블에는 Paimon의 부분 업데이트(partial update) 기능을 사용해 필요한 칼럼만 업데이트합니다.&lt;/p&gt;

&lt;p&gt;이렇게 Paimon에 데이터를 적재함으로써 Paimon의 다양한 기능을 활용할 수 있습니다. 그 중 몇 가지를 꼽아보자면, 스냅샷이나 태그, 변경 로그를 이용해 타임 트래블이 가능하고, Kafka에서는 쉽게 구현하기 힘든 데이터 간 조인이나 집계, 데이터 분석도 가능합니다.&lt;/p&gt;

&lt;p&gt;그 다음으로, 다양한 광고 정보를 조인하여 애셋 그룹 기준으로 반정규화된 데이터를 생성합니다. Paimon으로 반정규화된 데이터를 생성하면 부가 기능을 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이어서, 반정규화 데이터로부터 유효 광고를 선정해 유효 애셋 그룹 데이터를 생성합니다. Paimon의 rowkind 재정의 기능을 활용하면, 단순 SQL로 실행한 Flink 스트리밍 작업에서 데이터를 실시간으로 추가/수정/삭제할 수 있습니다.&lt;/p&gt;

&lt;p&gt;마지막으로, 이렇게 선정한 유효 애셋 그룹 데이터를 AI Serving API가 광고를 조회하는 Feature Store에 업로드합니다. 앞에서 추가/수정/삭제한 데이터는 당연히 Feature Store에서도 추가/수정/삭제됩니다.&lt;/p&gt;

&lt;p&gt;추가로, 유효 광고를 선정할 때는 일별 캠페인 소진량 데이터가 필요합니다. Flink는 한 번 처리한 데이터를 다시 처리하려면 데이터를 재발행해야 하는데, 일별 캠페인 소진량은 매일 초기화가 필요한 데이터입니다. 일별 배치 작업으로 캠페인 소진량 데이터를 초기화하기 위해서, 일별 초기화 결과 테이블과 소진량 테이블을 스트리밍 조인했습니다. 그 결과, 일별 초기화가 반영된 캠페인 소진량을 실시간으로 활용할 수 있게 되었습니다.&lt;/p&gt;

&lt;h4 id=""&gt;상품 광고 매핑 정보 업데이트, 로그 수집과 집계&lt;/h4&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/2-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;상품 광고 매핑 정보 업데이트 파이프라인은 비교적 간단합니다. Kafka를 통해 상품과 연결된 애셋 그룹 매핑 정보를 CDC로 받아와서 Paimon에 추가/수정/삭제합니다. 이어서 Feature Store에도 동일한 스키마로 동기화해 상품과 애셋 그룹 매핑 Feature를 AI Serving API도 활용할 수 있도록 구축했습니다.&lt;/p&gt;

&lt;p&gt;그리고 로그 수집 및 집계 파이프라인도 비교적 간단합니다. 로그 데이터를 Kafka로부터 받아서 Paimon 테이블에 실시간으로 적재하고, 적재된 데이터를 활용해 Spark에서 배치로 집계하고, 집계 결과를 Hive와 Aerospike에 적재합니다. 집계 Feature도 Paimon으로 구축할 수 있지만, 이 작업에서는 기존에도 많이 사용하는 Hive를 그대로 활용했습니다.&lt;/p&gt;

&lt;h4 id="aiserving"&gt;집계 데이터 기반 유효 광고 AI Serving&lt;/h4&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/3-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;앞선 파이프라인에서 Feature Store에 업로드된 데이터를 AI Serving에서는 어떻게 처리하는지 간단히 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;먼저, 광고 서버로부터 상품 정보 목록을 전달받습니다.&lt;/p&gt;

&lt;p&gt;다음 단계에서 애셋 그룹 매핑 Feature를 조회합니다. 최대 상품 개수인 200에 최대 애셋 그룹 매핑 개수인 500을 곱하면 최대 만 개의 유효 애셋 그룹이 필요합니다.&lt;/p&gt;

&lt;p&gt;세 번째로, 유효 애셋 그룹 Feature를 조회합니다. 이 유효 애셋 그룹 Feature를 사용해서, 최대 만 개의 매핑된 유효 애셋 그룹 중에서 실제로 광고를 송출할 수 있는 유효한 애셋 그룹을 선정합니다.&lt;/p&gt;

&lt;p&gt;그리고 유효 애셋 그룹에 해당하는 집계 Feature를 조회합니다. 이 집계 Feature를 활용해서 AI 모델에서 추론해 모델 결과 값을 생성합니다.&lt;/p&gt;

&lt;p&gt;그 결과, 상품별 모델 결과 값을 기준으로 광고 성과가 가장 최적화된 애셋 그룹을 하나씩 반환해 광고 송출에 사용합니다.&lt;/p&gt;

&lt;h3 id="flinkpaimon"&gt;실시간 유효 광고 선정에 Flink + Paimon을 도입한 이유&lt;/h3&gt;

&lt;p&gt;Spark만 사용하는 방법으로도 파이프라인을 구축할 수 있었지만, 리소스를 효율적으로 사용하면서도 빠르고 안정적인 파이프라인을 구축하기 위해 Flink + Paimon 도입을 결정했습니다.&lt;/p&gt;

&lt;h4 id="flinkpaimon"&gt;Flink + Paimon 통합 사용성&lt;/h4&gt;

&lt;p&gt;Flink는 실시간 처리 기능과 성능이 우수하고 레퍼런스도 풍부하며, Paimon은 태생이 Flink Table Store로 시작된 프로젝트인 만큼 Flink와 통합했을 때 사용성이 좋습니다. 또한 여기에 따라오는 다음과 같은 장점이 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;실시간 집계&lt;/strong&gt;(aggregation), &lt;strong&gt;스키마 진화&lt;/strong&gt;(schema evolution), &lt;strong&gt;변경 로그&lt;/strong&gt;(changelog) 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;부분 업데이트&lt;/strong&gt; 기능 지원
&lt;ul&gt;&lt;li&gt;실시간 조인 실행 시 조인 키와 기본 키(primary key, 이하 PK)가 같으면 Flink에서 조인하는 대신 Paimon에 INSERT를 실행하는 것만으로 조인 처리 가능&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;타임 트래블&lt;/strong&gt; 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Merge on Write&lt;/strong&gt; 지원
&lt;ul&gt;&lt;li&gt;읽는 시점에 삭제 벡터(deletion vector)를 조합하여 읽기에 빠른 조회 가능&lt;/li&gt;
&lt;li&gt;쓰기 성능이 Merge on Read에 비해 느리지만, Copy on Write에 비해 빠름&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;테이블 자동 관리&lt;/strong&gt; 기능 지원
&lt;ul&gt;&lt;li&gt;자동 compaction, 자동 태깅, 자동 만료 파티션, 자동 만료 스냅샷 등의 기능을 지원해 별도의 테이블 관리 배치 작업이 불필요&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Flink에 신규 기능이 추가되면 가장 빠르게 지원
&lt;ul&gt;&lt;li&gt;예: Flink 2.0에 추가된 구체화된 테이블(materialized table)의 경우 Paimon만 지원함&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;실시간 처리 보장&lt;/h4&gt;

&lt;p&gt;Flink의 경우 Spark Streaming의 마이크로 배치와는 다르게 스트림 기반으로 처리할 수 있습니다. 여기에 Paimon의 consumer-id 기능을 사용하면 &lt;strong&gt;exactly-once&lt;/strong&gt; 처리도 보장됩니다.&lt;/p&gt;

&lt;p&gt;여기에 따라오는 부가적인 장점을 살펴보면 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;필요한 기간 동안 원본 테이블의 스냅샷이 스냅샷 만료로 없어지지 않도록 유지 가능&lt;/li&gt;
&lt;li&gt;해당 스냅샷으로부터 변경분만 또는 전체 읽기 가능&lt;/li&gt;
&lt;li&gt;Paimon 데이터를 읽는 작업 및 스트리밍 조인 처리 시 exactly-once 처리 가능&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;중간 데이터 활용 가능&lt;/h4&gt;

&lt;p&gt;실시간 처리를 위해 중간 Kafka를 추가하는 대신 Paimon으로 대체할 수 있습니다. 실시간 &lt;strong&gt;메시지 큐&lt;/strong&gt;와 유사한 형태로 사용할 수도 있으며, 중간 데이터를 디버깅하기 용이하고 데이터 분석이나 ML 개발 시에도 활용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;실제로 중요한 메타 데이터인 유효 광고 데이터는 확인이 빈번하게 필요했고, 타임 트래블 기능을 이용해 디버깅할 때 유용했습니다.&lt;/p&gt;

&lt;h4 id="flinkspark"&gt;Flink, Spark 지원&lt;/h4&gt;

&lt;p&gt;Paimon이 저희 팀에서 많이 사용하는 Flink와 Spark를 지원해 익숙하게 사용할 수 있었습니다. Paimon은 Flink의 스트리밍이나 (미니) 배치, Spark Streaming이나 Spark 배치에서 모두 처리 가능합니다.&lt;/p&gt;

&lt;h2 id="paimon"&gt;Paimon 살펴보기&lt;/h2&gt;

&lt;p&gt;Paimon은 Flink와의 깊은 통합과 LSM 트리 구조를 기반으로 실시간 트랜젝션 처리가 강화된 레이크하우스 포맷입니다. 로고는 돛새치(sailfish) 모양으로, 물(lake)에서 가장 빠른 물고기를 상징합니다. 실시간 처리 엔진인 Flink 프로젝트 내부에서 Hive/Iceberg/Hudi 사용성의 한계에 부딪치면서 Flink Table Store로 시작되어 현재는 Paimon으로 분리되었습니다. 유사한 프로젝트로 Apache Iceberg, Apache Hudi, Deltalake가 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/4-4.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;파일 구조&lt;/h3&gt;

&lt;p&gt;Paimon 데이터의 파일 트리 구조를 살펴보면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/5-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;가장 상위에 데이터베이스가 있고, 하위에 테이블, 그 하위에 버킷, 인덱스, 매니페스트, 스키마, 스냅샷 순서로 자리합니다.&lt;/p&gt;

&lt;p&gt;이 파일 트리는 다음 그림과 같이 Paimon 엔진에서 접근하고 처리합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/6-4.png" alt="" /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;스냅샷
&lt;ul&gt;&lt;li&gt;스키마, 매니페스트 목록 정보를 포함하는 파일입니다.&lt;/li&gt;
&lt;li&gt;스키마는 변경될 때마다 JSON 파일로 기록되고, 필드 정보와 파티션 키, PK, 테이블 옵션 정보를 포함합니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;매니페스트 목록(manifest-list)
&lt;ul&gt;&lt;li&gt;매니페스트 파일들의 메타 정보를 포함하는 Avro 형식의 파일입니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;매니페스트
&lt;ul&gt;&lt;li&gt;데이터 파일, 변경 로그, 테이블 인덱스 파일의 메타 정보를 포함하는 Avro 형식의 파일입니다.&lt;/li&gt;
&lt;li&gt;데이터 파일의 메타 정보에는 LSM 레벨이 포함됩니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;데이터 파일
&lt;ul&gt;&lt;li&gt;데이터 처리 구문을 실행했을 때 저장되는 레코드에 해당하는 데이터를 포함하는 파일입니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;변경 로그
&lt;ul&gt;&lt;li&gt;데이터베이스의 바이너리 로그와 유사하게, 데이터 파일의 변경 이력을 포함하는 파일입니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;테이블 인덱스
&lt;ul&gt;&lt;li&gt;PK와 일치하는 버킷에 해당하는 동적 버킷 인덱스와 삭제 벡터를 포함하는 파일입니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;삭제 벡터
&lt;ul&gt;&lt;li&gt;데이터 파일에서 삭제된 레코드의 위치를 포함하는 파일입니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="compaction"&gt;자동 compaction&lt;/h3&gt;

&lt;p&gt;Paimon의 compaction은 RocksDB의 &lt;a href="https://github.com/facebook/rocksdb/wiki/Universal-Compaction"&gt;Universal Compaction&lt;/a&gt;과 유사한 구조를 따릅니다. Universal Compaction은 유사한 크기의 SST 파일들이 모일 때까지 기다렸다가 병합하는 방식으로, 쓰기 성능을 확보하면서도 쿼리 성능을 유지하는 데 효과적입니다.&lt;/p&gt;

&lt;p&gt;Paimon은 내부적으로 LSM 트리 구조를 사용하며, &lt;strong&gt;SST 파일 수가 증가하면 쿼리 지연 시간이 증가하므로 이를 방지하기 위해 compaction을 실행&lt;/strong&gt;해야 합니다. LSM 트리에서 최신 데이터는 level-0 레벨에 위치하고, 오래된 데이터일수록 상위 레벨로 이동합니다. 여러 SST 파일이 누적되면 compaction으로 상위 레벨에 병합하고, 이 과정에서 불필요한 level-0 파일 수를 줄여 쿼리 성능을 유지합니다.&lt;/p&gt;

&lt;p&gt;compaction으로 해결할 수 있는 일들은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;level-0 파일 감소&lt;/li&gt;
&lt;li&gt;변경 로그 생성&lt;/li&gt;
&lt;li&gt;삭제 벡터 생성&lt;/li&gt;
&lt;li&gt;스냅샷, 태그, 파티션 만료&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;단, 한 테이블 내의 동일 파티션에서는 동시에 하나의 compaction 작업만 수행될 수 있으며, 작업이 동시에 실행되면 충돌이 발생할 수 있다는 점을 유의해야 합니다.&lt;/p&gt;

&lt;h4 id="compaction"&gt;compaction 전략&lt;/h4&gt;

&lt;p&gt;Paimon은 여러 가지 compaction 전략을 제공합니다.&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;전략&lt;/th&gt;  
&lt;th&gt;특징&lt;/th&gt;  
&lt;th&gt;주요 옵션&lt;/th&gt;  
&lt;/tr&gt;&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;Lookup Compaction&lt;/td&gt;  
&lt;td&gt;빠른 조회를 위해 매 compaction 트리거마다 level-0 파일을 강제로 더 높은 레벨로 compaction.&lt;br&gt; 다음 조건에서 수행.&lt;ul&gt;&lt;li&gt;changelog producer = 'lookup'&lt;/li&gt;&lt;li&gt;merge-engine = 'first-row'&lt;/li&gt;&lt;li&gt;Merge on Write mode&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;  
&lt;td&gt;lookup-compact, lookup-wait&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;Full Compaction&lt;/td&gt;  
&lt;td&gt;LSM에 변화가 너무 많으면 자동으로 수행.&lt;br&gt;full-compaction 옵션을 설정해 주기적으로 수행시킬 수도 있음.&lt;/td&gt;  
&lt;td&gt;full-compaction.delta-commits, compaction.optimization-interval&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;Asynchronous Compaction&lt;/td&gt;  
&lt;td&gt;쓰기 처리량 최대화를 위함.&lt;br&gt;옵션으로 설정 가능.&lt;/td&gt;  
&lt;td&gt;stop-trigger, lookup-wait, spill-threshold&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;Record-Level Expire&lt;/td&gt;  
&lt;td&gt;TTL에 가까운 기능이지만 제 시간에 만료를 보장하지 않음.&lt;/td&gt;  
&lt;td&gt;expire-time, time-field&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;h4 id="pkcompaction"&gt;PK 테이블 compaction 트리거&lt;/h4&gt;

&lt;p&gt;PK 테이블의 compaction은 기본적으로 다음의 조건에 따라 트리거됩니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;num-sorted-run.compaction-trigger
&lt;ul&gt;&lt;li&gt;compaction을 트리거하기 위한 최소 compaction 수&lt;/li&gt;
&lt;li&gt;기본값: 5&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;num-sorted-run.stop-trigger
&lt;ul&gt;&lt;li&gt;sorted run이 너무 많아지면 성능에 영향을 미칠 수 있으므로 이 값을 초과하면 쓰기 작업을 일시 중단&lt;/li&gt;
&lt;li&gt;기본값: &lt;code&gt;num-sorted-run.compaction-trigger&lt;/code&gt; + 3&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;sort-spill-threshold
&lt;ul&gt;&lt;li&gt;sort reader(SST file reader) 수가 이 값을 초과하면 시스템의 OOM을 방지하기 위해 디스크로 spill 유도&lt;/li&gt;
&lt;li&gt;시스템의 메모리 크기에 따라 설정 필요&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;테이블 종류&lt;/h3&gt;

&lt;p&gt;Paimon 테이블은 PK 테이블과 PK가 없는 테이블로 나눌 수 있습니다.&lt;/p&gt;

&lt;h4 id="pk"&gt;PK 테이블&lt;/h4&gt;

&lt;p&gt;UPSERT를 지원하는 PK 테이블로, 버킷 내 정렬이 보장됩니다.  각 버킷 내부는 LSM 구조이며 동적 버킷팅(dynamic bucketing)을 지원합니다.&lt;/p&gt;

&lt;p&gt;동적 버킷팅이란, 버킷 할당 및 수가 고정되어 있지 않고 데이터의 양에 따라 조절하는 버킷팅 방법을 말합니다. 정적 버킷팅과 달리 다음과 같은 옵션을 설정해 버킷당 레코드 수, 초기 버킷 수 등을 조절할 수 있습니다.&lt;/p&gt;

&lt;table&gt;  
&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;키&lt;/th&gt;  
&lt;th&gt;기본 값&lt;/th&gt;  
&lt;th&gt;타입&lt;/th&gt;  
&lt;th&gt;설명&lt;/th&gt;  
&lt;/tr&gt;&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;dynamic-bucket.assigner-parallelism&lt;/td&gt;  
&lt;td&gt;(없음)&lt;/td&gt;  
&lt;td&gt;Integer&lt;/td&gt;  
&lt;td&gt;동적 버킷 모드에서 assigner 연산자의 병렬 처리 수준. 초기화된 버킷 수와 관련이 있으며, 너무 작으면 assigner의 처리 속도가 부족할 수 있음.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;dynamic-bucket.initial-buckets&lt;/td&gt;  
&lt;td&gt;(없음)&lt;/td&gt;  
&lt;td&gt;Integer&lt;/td&gt;  
&lt;td&gt;동적 버킷 모드에서 assigner 연산자의 파티션별 초기 버킷 수.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;dynamic-bucket.target-row-num&lt;/td&gt;  
&lt;td&gt;2000000&lt;/td&gt;  
&lt;td&gt;Long&lt;/td&gt;  
&lt;td&gt;버킷이 -1일 때, PK 테이블에서 동적 버킷 모드로 동작하며, 이 옵션은 하나의 버킷에 대한 목표 행 수를 제어함.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;dynamic-partition-overwrite&lt;/td&gt;  
&lt;td&gt;true&lt;/td&gt;  
&lt;td&gt;Boolean&lt;/td&gt;  
&lt;td&gt;동적 파티션 칼럼이 있는 파티션 테이블을 덮어쓸 때 동적 파티션만 덮어쓸지 여부. 테이블에 파티션 키가 있는 경우에만 작동함.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;p&gt;다만, 동적 버킷팅을 관리하는 bucket assigner가 필요하기 때문에 하나의 쓰기 작업에서만 지원합니다. 따라서 이 기능을 사용할 때는 동시에 여러 개의 쓰기 작업은 불가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://paimon.apache.org/docs/1.0/primary-key-table/data-distribution/#normal-dynamic-bucket-mode"&gt;공식 문서&lt;/a&gt;에 따르면, 파티션이 없거나 PK가 모든 파티션에 있는 경우 UPDATE 비율이 낮은 테이블에 normal dynamic bucket 모드를 사용하면 상당한 성능 향상이 있다고 합니다. 일반적으로 성능 손실은 없지만 추가 메모리 소비가 발생할 수 있습니다(파티션당 1억 개의 레코드에 1GB 추가 메모리 필요).&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/8-6.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;PK 테이블은 총 세 가지 테이블 모드를 지원합니다.&lt;/p&gt;

&lt;h5 id="copyonwrite"&gt;Copy on Write&lt;/h5&gt;

&lt;p&gt;매 커밋마다 full compaction이 발생합니다. 따라서 쓰기 성능은 낮지만 읽기 성능은 좋습니다. 다음 옵션으로 설정할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;'full-compaction.delta-commits' = '1'  
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id="mergeonread"&gt;Merge on Read&lt;/h5&gt;

&lt;p&gt;compaction 없이 바로 쓰기를 하며, 읽기 시점에 PK 기준으로 병합을 수행합니다. 따라서 쓰기 성능은 좋지만 읽기 성능은 낮습니다.&lt;/p&gt;

&lt;p&gt;PK 칼럼 외 필터 푸시다운이 불가능하다는 단점이 있습니다.&lt;/p&gt;

&lt;h5 id="mergeonwrite"&gt;Merge on Write&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;Merge on Read와 Copy on Write의 절충안으로, 쓰기 시점에 삭제 벡터를 생성&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/9-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;삭제 벡터란, Paimon 테이블에 쓰기 작업을 수행할 때, LSM에 쓰면서 동시에 삭제된 행의 위치를 &lt;a href="https://github.com/apache/paimon/blob/release-1.0.1/paimon-core/src/main/java/org/apache/paimon/deletionvectors/BitmapDeletionVector.java"&gt;비트맵으로 저장&lt;/a&gt;하는 것을 말합니다. 이때 비트맵의 형식으로는 &lt;a href="https://github.com/RoaringBitmap/RoaringBitmap"&gt;RoaringBitmap&lt;/a&gt;을 사용합니다.&lt;/p&gt;

&lt;p&gt;삭제 벡터를 이용하면 읽기 시점에 별도의 병합 없이 비트맵 기반 필터링만 수행하므로 Merge on Read보다 좋은 읽기 성능을 보장합니다. 또한 필터 푸시다운도 가능하다는 장점이 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/10-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;예를 들어, PK 2번의 값이 새로운 필드로 UPDATE되면, 기존 레코드는 삭제 벡터에 의해 삭제 위치가 저장되고, 새로운 sorted run에 새로운 행이 기록됩니다. 읽기 시점에는 별도의 병합 없이 삭제 벡터 기반 필터링만 수행하고, compaction 시점에 삭제 벡터가 병합됩니다. 삭제 벡터는 compaction 과정에서 생성되기 때문에 compaction이 필수적으로 동작합니다.&lt;/p&gt;

&lt;p&gt;삭제 벡터 생성 비용이 발생하기 때문에 쓰기 성능은 Merge on Read에 비해 안 좋을 수 밖에 없지만, Copy on Write에 비해서는 성능이 좋습니다.&lt;/p&gt;

&lt;p&gt;삭제 벡터는 변경 로그 프로듀서가 none, input, lookup 모드일 때만 사용할 수 있으며 full-compaction 모드일 때는 사용할 수 없습니다. 또한, 병합 엔진이 first-row인 경우에도 삭제 벡터를 사용할 수 없습니다. 이는 first-row는 맨 처음 들어온 레코드만 가지고 있어 삭제가 발생하지 않기 때문입니다.(참고: &lt;a href="https://github.com/apache/paimon/blob/01a85d18e659da246a6eb2de7bce4db9c952c508/paimon-core/src/main/java/org/apache/paimon/schema/SchemaValidation.java#L488-L499"&gt;validateForDeletionVectors&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;다음 옵션으로 삭제 벡터를 활성화해 Merge on Write로 설정할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;‘deletion-vectors.enabled’ = ‘true’
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id="pkappendonly"&gt;PK가 없는 테이블(append-only)&lt;/h4&gt;

&lt;p&gt;PK가 없는 테이블은 단순히 파일을 append하기만 하므로, 불필요한 정렬을 수반하는 LSM 트리 구조를 사용하지 않습니다. 따라서 LSM 트리의 복잡한 병합 로직도 수행하지 않으며, 대신 &lt;a href="https://github.com/apache/paimon/blob/release-1.0.1/paimon-core/src/main/java/org/apache/paimon/AppendOnlyFileStore.java"&gt;AppendOnlyFileStore&lt;/a&gt;를 사용합니다.&lt;/p&gt;

&lt;p&gt;이러한 특성상, 로그성 데이터 적재에 적합합니다. PK 테이블에서 제공하는 동적 버킷팅은 지원하지 않습니다.&lt;/p&gt;

&lt;p&gt;PK 테이블에서 sorted run 파일을 병합하며 compaction을 수행한 것과 달리, PK가 없는 테이블은 &lt;code&gt;compaction.min.file-num&lt;/code&gt; 옵션으로 compaction 트리거를 설정합니다. 해당 옵션 값이 클수록 compaction 빈도는 낮아지지만 compaction 시 메모리 사용량이 늘어나고, 반대의 경우 compaction 빈도는 높아지지만 compaction 시 메모리 사용량이 줄어듭니다.&lt;/p&gt;

&lt;h3 id="httpspaimonapacheorgdocs10primarykeytablechangelogproducer"&gt;&lt;a href="https://paimon.apache.org/docs/1.0/primary-key-table/changelog-producer/"&gt;변경 로그 프로듀서&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;변경 로그 프로듀서란, 원본 테이블을 바라보는 다른 애플리케이션이 해당 원본 테이블의 실시간 변경 사항을 읽을 수 있도록 최신 변경 사항을 생성하는 기능입니다. 이는 compaction 성능을 상당히 낮추므로, 불필요한 경우에는 켜지 않는 것이 좋습니다.&lt;/p&gt;

&lt;p&gt;변경 로그는 보통 스냅샷보다 오래 보관합니다. 변경 로그가 스냅샷보다 보관 주기가 길면 decoupled 상태가 되는데, 이때는 스냅샷과는 별도로 retention이 관리되기 때문에 스냅샷이 삭제되어도 타임 트래블이 가능합니다.&lt;/p&gt;

&lt;p&gt;Paimon은 변경 로그를 생성하는 네 가지 전략을 지원합니다.&lt;/p&gt;

&lt;h4 id="none"&gt;none&lt;/h4&gt;

&lt;p&gt;변경 로그를 생성하지 않습니다. 이 경우 Flink가 기본적으로 제공하는 normalize 연산자가 각 키의 값을 state에 들고 계산하는데, 이는 비용이 매우 큽니다.&lt;/p&gt;

&lt;p&gt;따라서 변경 로그를 사용하지 않는다면 다음 옵션을 쿼리 힌트로 제공해 normalize 연산자를 강제로 제거하는 것이 좋습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;'scan.remove-normalize'='true'  
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id="input"&gt;input&lt;/h4&gt;

&lt;p&gt;입력 데이터가 완전한 변경 로그를 제공하는 경우입니다. 성능 영향이 가장 적습니다.&lt;/p&gt;

&lt;h4 id="lookup"&gt;lookup&lt;/h4&gt;

&lt;p&gt;lookup 모드는 input 모드가 완전한 변경 로그를 제공하지 않는 경우에 사용합니다.&lt;/p&gt;

&lt;p&gt;이는 &lt;a href="https://github.com/apache/paimon/blob/release-1.0.1/paimon-core/src/main/java/org/apache/paimon/mergetree/compact/LookupChangelogMergeFunctionWrapper.java"&gt;LookupChangelogMergeFunctionWrapper&lt;/a&gt;를 통해 수행됩니다. LSM의 구조를 생각해보면 그 원리를 쉽게 이해할 수 있는데요, level-0 파일이 compaction 대상일 때 아래의 조건에 따라 변경 로그를 발행합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;level-0 파일이 존재하지 않으면, 새로 유입된 레코드가 없기 때문에 변경 로그도 발행하지 않습니다.&lt;/li&gt;
&lt;li&gt;level-0 파일이 존재하고 level-x(x &gt; 0) 파일도 존재하면, level-x가 UPDATE_BEFORE 값이 되고, level-0가 UPDATE_AFTER 값이 됩니다. 이는 LSM의 구조상 가장 최신의 데이터일수록 레벨이 낮기 때문입니다.&lt;/li&gt;
&lt;li&gt;level-0 파일이 존재하지만 level-x(x &gt; 0) 파일이 없으면, 과거 값을 찾기 위해 상위 레벨에 연이어 lookup을 수행합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;lookup 모드는 lookup 수행 과정에서 성능 향상을 위해 메모리나 디스크에 캐시 작업을 수행하며, 다음의 옵션으로 조절할 수 있습니다.&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;옵션&lt;/th&gt;  
&lt;th&gt;기본 값&lt;/th&gt;  
&lt;th&gt;타입&lt;/th&gt;  
&lt;th&gt;설명&lt;/th&gt;  
&lt;/tr&gt;&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;lookup.cache-file-retention&lt;/td&gt;  
&lt;td&gt;1 h&lt;/td&gt;  
&lt;td&gt;Duration&lt;/td&gt;  
&lt;td&gt;lookup을 위한 캐시된 파일의 보관 시간. 파일이 만료된 후 접근이 필요하면 DFS에서 다시 읽어 로컬 디스크에 인덱스를 구축함.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;lookup.cache-max-disk-size&lt;/td&gt;  
&lt;td&gt;unlimited&lt;/td&gt;  
&lt;td&gt;MemorySize&lt;/td&gt;  
&lt;td&gt;lookup 캐시를 위한 최대 디스크 크기. 이 옵션을 사용하여 로컬 디스크 사용량을 제한할 수 있음.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;lookup.cache-max-memory-size&lt;/td&gt;  
&lt;td&gt;256 mb&lt;/td&gt;  
&lt;td&gt;MemorySize&lt;/td&gt;  
&lt;td&gt;lookup 캐시를 위한 최대 메모리 크기.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;h4 id="fullcompaction"&gt;full-compaction&lt;/h4&gt;

&lt;p&gt;주기적으로 full compaction 결과를 비교해 변경 로그를 생성합니다. full compaction이 주기적으로 발생하기 때문에 비용이 큽니다. 따라서 지연 시간이 길어도 되는 경우에만 사용합니다.&lt;/p&gt;

&lt;p&gt;full compaction은 &lt;a href="https://github.com/apache/paimon/blob/release-1.0.1/paimon-core/src/main/java/org/apache/paimon/mergetree/compact/FullChangelogMergeFunctionWrapper.java"&gt;FullChangelogMergeFunctionWrapper&lt;/a&gt;을 통해 수행되는데, LSM의 각 레벨별 파일에 대한 lookup 없이, 해당 키-값에 대한 최상위 레벨 파일과 현재 병합된 결과만을 비교하여 변경 로그를 생성합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;최상위 레벨의 키-값이 존재하지 않으면 INSERT&lt;/li&gt;
&lt;li&gt;최상위 레벨의 키-값과 병합된 파일 간 결과가 다르면 최상위 레벨의 키-값은 UPDATE_BEFORE, 병합된 파일의 키-값은 UPDATE_AFTER&lt;/li&gt;
&lt;li&gt;반대로 삭제된 경우는 DELETE&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="paimoniceberg"&gt;Paimon과 Iceberg 성능 및 변경 로그 기능 비교&lt;/h2&gt;

&lt;p&gt;먼저 Paimon과 Iceberg의 성능을 비교한 실험 조건에 대해 설명하겠습니다. 테스트 목적은 Flink 환경에서 두 포맷의 읽기/쓰기 성능을 측정하는 것이었습니다. 실험은 PK 테이블을 기준으로 진행했으며, 다음과 같은 옵션에 따라 성능 차이를 비교했고, 모든 실험 결과는 평균값입니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;쓰기 타입
&lt;ul&gt;&lt;li&gt;Flink에서 Iceberg로 데이터를 적재하는 로직은 항상 Merge on Read로 동작하므로 Iceberg는 Merge on Read로 테스트 진행&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;체크포인트 간격&lt;/li&gt;
&lt;li&gt;compaction 사용 여부&lt;/li&gt;
&lt;li&gt;변경 로그 유무&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;테스트 시나리오는 &lt;a href="https://github.com/apache/paimon/tree/master/paimon-benchmark/paimon-cluster-benchmark?spm=a2c65.11461447.0.0.3fc17b7cJ0UL35"&gt;Paimon Benchmark&lt;/a&gt;를 참고했습니다. 데이터는 총 5억 건의 행을 생성해 UPSERT 형태로 주입했으며, 키 범위는 0 ~ 99,999,999로 설정했습니다. 데이터 생성에는 Flink의 DataGen 커넥터를 사용했습니다. 테스트에 사용된 리소스는 parallelism 16, TaskManager당 4GB 메모리를 사용했습니다. 테스트 환경 및 DataGen을 활용한 더미 데이터 생성 방식은 다음과 같습니다.&lt;/p&gt;

&lt;h3 id=""&gt;테스트 환경&lt;/h3&gt;

&lt;h4 id=""&gt;각 라이브러리 버전&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Flink 버전: 1.20&lt;/li&gt;
&lt;li&gt;Paimon 버전: 1.0.1&lt;/li&gt;
&lt;li&gt;Iceberg 버전: 1.8.1&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="flink"&gt;Flink 리소스 설정&lt;/h4&gt;

&lt;pre&gt;&lt;code class="language-yaml"&gt; jobmanager.memory.process.size: 4g
  parallelism.default: 16
  taskmanager.memory.process.size: 4g
  taskmanager.numberOfTaskSlots: 1
  yarn.appmaster.vcores: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id="datagen"&gt;DataGen 생성 코드&lt;/h4&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE item_uv_pv_1d_source (  
                                      `item_id` BIGINT,
                                      `item_name` STRING,
                                      `item_click_uv_1d` BIGINT,
                                      `item_click_pv_1d` BIGINT,
                                      `item_like_uv_1d` BIGINT,
                                      `item_like_pv_1d` BIGINT,
                                      `item_cart_uv_1d` BIGINT,
                                      `item_cart_pv_1d` BIGINT,
                                      `item_share_uv_1d` BIGINT,
                                      `item_share_pv_1d` BIGINT
) WITH (
      'connector' = 'datagen',
      'rows-per-second' = '999999999',
      'number-of-rows' = '{{ number-of-rows }}',
      'fields.item_id.min' = '0',
      'fields.item_id.max' = '99999999',
      'fields.item_click_uv_1d.min' = '0',
      'fields.item_click_uv_1d.max' = '999999999',
      'fields.item_click_pv_1d.min' = '0',
      'fields.item_click_pv_1d.max' = '999999999',
      'fields.item_like_uv_1d.min' = '0',
      'fields.item_like_uv_1d.max' = '999999999',
      'fields.item_like_pv_1d.min' = '0',
      'fields.item_like_pv_1d.max' = '999999999',
      'fields.item_cart_uv_1d.min' = '0',
      'fields.item_cart_uv_1d.max' = '999999999',
      'fields.item_cart_pv_1d.min' = '0',
      'fields.item_cart_pv_1d.max' = '999999999',
      'fields.item_share_uv_1d.min' = '0',
      'fields.item_share_uv_1d.max' = '999999999',
      'fields.item_share_pv_1d.min' = '0',
      'fields.item_share_pv_1d.max' = '999999999'
      );
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="mergeonread"&gt;쓰기 성능 비교(Merge on Read 기준)&lt;/h3&gt;

&lt;p&gt;첫 번째 테스트에서는 Paimon과 Iceberg를 모두 Merge on Read 모드로 두고 쓰기 성능을 비교했습니다.&lt;/p&gt;

&lt;p&gt;Paimon과 Iceberg의 테이블 설정은 다음과 같습니다. Iceberg는 자동 compaction 기능을 공식적으로 지원하지 않기 때문에 이 테스트에서는 compaction을 제외하고 실험했습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Paimon(Merge on Read, 체크포인팅 30초/60초, compaction 사용, 변경 로그  없음)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;...
    PRIMARY KEY (`item_id`) NOT ENFORCED
    ) WITH (
          'target-file-size' = '256 mb',
          'file.format' = 'parquet',
          'bucket' = '16',
          'bucket-key' = 'item_id'
);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Paimon(Merge on Read, 체크포인팅 30초/60초, compaction 사용 안 함, 변경 로그 없음)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;...
    PRIMARY KEY (`item_id`) NOT ENFORCED
    ) WITH (
          'write-only' = 'true',
          'target-file-size' = '256 mb',
          'file.format' = 'parquet',
          'bucket' = '16',
          'bucket-key' = 'item_id'
);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Iceberg(Merge on Read, 체크포인팅 30초/60초, compaction 사용 안 함, 변경 로그 없음)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;...
    PRIMARY KEY (`item_id`) NOT ENFORCED
    )
    DISTRIBUTED BY HASH(item_id) INTO 16 BUCKETS
    WITH (
          'format-version' = '2',
          'write.format.default' = 'parquet',
          'write.target-file-size-bytes' = '268435456', -- 256MB
          'write.delete.mode'='merge-on-read',
          'write.update.mode'='merge-on-read',
          'write.merge.mode'='merge-on-read'
        );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;체크포인트 간격을 30초로 설정했을 때는 Iceberg가 가장 좋은 성능을 보여주었습니다. 다만 Iceberg와 Paimon의 성능 차이가 그리 크진 않았습니다. 특히 Paimon에서 compaction을 사용했을 때와 하지 않았을 때의 성능 차이 역시 거의 없었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/11-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;체크포인트 간격을 60초로 변경한 두 번째 실험에서는 Paimon은 이전과 유사한 성능을 유지한 반면, Iceberg는 약간의 성능 저하가 있었습니다. 이 테스트에서도 Paimon은 compaction 사용 여부에 따른 성능 변화가 크지 않았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/12-4.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id="paimon"&gt;Paimon 테이블 모드별 쓰기 성능 비교&lt;/h3&gt;

&lt;p&gt;두 번째 테스트에서는 Paimon의 테이블 모드에 따른 쓰기 성능을 비교했습니다.&lt;/p&gt;

&lt;p&gt;Iceberg는 Merge on Write나 실시간 변경 로그 기능을 아직 공식 지원하지 않기 때문에, Paimon만 테스트했습니다. 테스트에 사용된 변경 로그 프로듀서는 lookup 모드이며, Merge on Write는 compaction이 필수이므로 compaction을 사용한 상태로 측정했습니다.&lt;/p&gt;

&lt;p&gt;각 Paimon 테이블의 설정은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Paimon(Merge on Read, 체크포인팅 30초, compaction 사용, 변경 로그 있음)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;...
    PRIMARY KEY (`item_id`) NOT ENFORCED
    ) WITH (
          'changelog-producer' = 'lookup',
          'target-file-size' = '256 mb',
          'file.format' = 'parquet',
          'bucket' = '16',
          'bucket-key' = 'item_id'
);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Paimon(Merge on Write, 체크포인팅 30초, compaction 사용, 변경 로그 없음)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;...
    PRIMARY KEY (`item_id`) NOT ENFORCED
    ) WITH (
          'deletion-vectors.enabled' = 'true',
          'target-file-size' = '256 mb',
          'file.format' = 'parquet',
          'bucket' = '16',
          'bucket-key' = 'item_id'
);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Paimon(Merge on Write, 체크포인팅 30초, compaction 사용, 변경 로그 있음)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;...
    PRIMARY KEY (`item_id`) NOT ENFORCED
    ) WITH (
          'deletion-vectors.enabled' = 'true',
          'changelog-producer' = 'lookup',
          'target-file-size' = '256 mb',
          'file.format' = 'parquet',
          'bucket' = '16',
          'bucket-key' = 'item_id'
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Merge on Write는 Merge on Read보다 쓰기 비용이 더 큰 것으로 나타났습니다. 예를 들어, Merge on Read는 약 400초 미만의 수행 시간을 보인 반면, Merge on Write는 약 800초에 가까운 시간을 기록했습니다. 이는 삭제 벡터를 생성하는 데 추가 시간이 소요되기 때문입니다. 이는 뒤에서 설명할 읽기 성능과도 관련이 있으며, 읽기 성능 요건에 따라 적절한 모드 선택이 필요합니다.&lt;/p&gt;

&lt;p&gt;또한 변경 로그를 사용했을 때 Merge on Read과 Merge on Write 모두 가장 낮은 쓰기 성능을 보여주었습니다. lookup 모드는 level-0 파일을 매번 compaction하는 &lt;a href="https://paimon.apache.org/docs/master/primary-key-table/compaction/#lookup-compaction"&gt;lookup compaction&lt;/a&gt;이 발생하기 때문에 비용이 매우 높은 구조로, 꼭 필요한 경우에만 사용하는 것이 좋고, 가능하다면 input 모드를 사용하는 것이 효율적임을 확인했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/13-4.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;읽기 성능 비교&lt;/h3&gt;

&lt;p&gt;읽기 성능을 비교하기 위해서 Spark 환경에서 다음과 같은 연산에 대해 평균 수행 시간을 측정했습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ROW COUNT&lt;/li&gt;
&lt;li&gt;SELECT&lt;/li&gt;
&lt;li&gt;SUM&lt;/li&gt;
&lt;li&gt;FILTER&lt;/li&gt;
&lt;li&gt;GROUP BY&lt;/li&gt;
&lt;li&gt;ORDER BY&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Iceberg는 compaction 없이 Spark에서 시간 초과가 계속 발생하는 이슈로 인해 정확한 비교가 불가능하여 읽기 성능 비교에서는 제외했습니다.&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;작업 유형&lt;/th&gt;  
&lt;th&gt;Paimon&lt;br&gt;Merge on Read&lt;br&gt;(compaction 사용 안 함)&lt;/th&gt;  
&lt;th&gt;Paimon&lt;br&gt;Merge on Read&lt;br&gt;(compaction 사용)&lt;/th&gt;  
&lt;th&gt;Paimon&lt;br&gt;Merge on Write&lt;br&gt;(compaction 사용)&lt;/th&gt;  
&lt;/tr&gt;&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;ROW COUNT&lt;/td&gt;  
&lt;td&gt;33.39s&lt;/td&gt;  
&lt;td&gt;3.34s&lt;/td&gt;  
&lt;td&gt;&lt;b&gt;0.18s&lt;/b&gt;&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;SELECT&lt;/td&gt;  
&lt;td&gt;26.13s&lt;/td&gt;  
&lt;td&gt;3.03s&lt;/td&gt;  
&lt;td&gt;&lt;b&gt;0.08s&lt;/b&gt;&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;SUM&lt;/td&gt;  
&lt;td&gt;30.58s&lt;/td&gt;  
&lt;td&gt;4.35s&lt;/td&gt;  
&lt;td&gt;&lt;b&gt;3.46s&lt;/b&gt;&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;FILTER&lt;/td&gt;  
&lt;td&gt;29.39s&lt;/td&gt;  
&lt;td&gt;3.50s&lt;/td&gt;  
&lt;td&gt;&lt;b&gt;2.06s&lt;/b&gt;&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;GROUP BY&lt;/td&gt;  
&lt;td&gt;44.15s&lt;/td&gt;  
&lt;td&gt;9.77s&lt;/td&gt;  
&lt;td&gt;&lt;b&gt;4.27s&lt;/b&gt;&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;ORDER BY&lt;/td&gt;  
&lt;td&gt;111.96s&lt;/td&gt;  
&lt;td&gt;36.44s&lt;/td&gt;  
&lt;td&gt;&lt;b&gt;13.57s&lt;/b&gt;&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;p&gt;compaction을 사용하면 전반적으로 읽기 성능이 대폭 향상되는 것을 확인했습니다. 예를 들어, compaction을 사용하지 않고 Merge on Read로 데이터를 적재한 경우보다 compaction을 사용하고 Merge on Read로 실행했을 때 약 80%의 성능 향상이 있었습니다.&lt;/p&gt;

&lt;p&gt;또한 Merge on Write 모드에서는 Merge on Read 대비 50% 이상 향상된 성능을 보여주었습니다. 이는 Merge on Read 모드에서는 PK가 아닌 칼럼에 대해 filter-based data skipping이 불가능한 반면, Merge on Write 모드에서는 삭제 벡터를 통해 직접 필터링이 가능하기 때문입니다.&lt;/p&gt;

&lt;h3 id=""&gt;성능 및 변경 로그 기능 비교 결과&lt;/h3&gt;

&lt;p&gt;테스트 결과, 각 레이크하우스 포맷의 장점은 다음과 같았습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Paimon
&lt;ul&gt;&lt;li&gt;compaction과 같은 테이블 운영 작업이 자동화되어 있음&lt;/li&gt;
&lt;li&gt;동일 조건에서 Iceberg와 성능 차이가 크지 않음&lt;/li&gt;
&lt;li&gt;다양한 변경 로그 전략 제공&lt;/li&gt;
&lt;li&gt;쓰기 시점에 실시간 변경 로그 생성 가능(input/lookup/full-compaction 모드)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Iceberg
&lt;ul&gt;&lt;li&gt;compaction 시점을 수동으로 조절 가능해 상황 대응력이 높음&lt;/li&gt;
&lt;li&gt;현 시점 가장 많이 사용되는 테이블 포맷이며, 생태계가 크고 공식 문서 및 예시가 풍부함&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다만 Iceberg는 1.8.1 기준으로 &lt;a href="https://github.com/apache/iceberg/blob/1e944650fcd4718dc6a8bccc34946871bbe13726/core/src/main/java/org/apache/iceberg/BaseIncrementalChangelogScan.java#L36"&gt;읽기 시점에만 스냅샷 간 비교로 변경 로그를 제공&lt;/a&gt;합니다. 또한 &lt;a href="https://github.com/apache/iceberg/blob/1e944650fcd4718dc6a8bccc34946871bbe13726/core/src/main/java/org/apache/iceberg/BaseIncrementalChangelogScan.java#L110"&gt;스냅샷에 DELETE가 존재하면 해당 스냅샷을 기준으로 변경 로그를 생성할 수 없다는 제약&lt;/a&gt;이 있었으며, 이 점은 실시간 변경 로그가 필요한 환경에서는 단점으로 작용했습니다. 따라서 저희 팀에서는 실시간 변경 로그가 필수인 아키텍처 특성상 Paimon을 채택했습니다.&lt;/p&gt;

&lt;p&gt;Paimon도 옵션 설정에 따라 성능 차이가 크기 때문에 반드시 적절한 튜닝이 필요합니다.&lt;/p&gt;

&lt;h2 id="paimon"&gt;알아두면 쓸모 있는 Paimon 옵션&lt;/h2&gt;

&lt;h3 id="shufflesort"&gt;버킷 - shuffle &amp;amp; sort&lt;/h3&gt;

&lt;p&gt;Paimon의 성능 최적화에서 버킷 설정은 매우 중요한 요소입니다. 읽기/쓰기 성능은 물론 테이블 간 조인 시 shuffle 또는 sort 발생 여부에 영향을 미칩니다.&lt;/p&gt;

&lt;p&gt;결론부터 말하자면, &lt;strong&gt;버킷 키와 버킷 수가 모두 동일해야 조인 시 shuffle이 발생하지 않습니다&lt;/strong&gt;. 다만 append 모드 테이블의 경우 LSM 트리 구조를 사용하지 않기 때문에 조인 시 sort가 발생할 수 있습니다.&lt;/p&gt;

&lt;p&gt;트래픽에 따라 쓰기 성능도 고려해야 하므로 모든 테이블의 버킷 구성을 일치시키는 것은 현실적으로 어렵습니다. 따라서 사용 케이스에 따라 적절한 선택이 필요합니다.&lt;/p&gt;

&lt;p&gt;다음 코드는 위 내용을 확인하기 위한 테스트 코드로, &lt;a href="https://github.com/apache/paimon/blob/626e338c55340a3f494aeff6d9b345f971657f18/paimon-spark/paimon-spark-ut/src/test/scala/org/apache/paimon/spark/sql/BucketedTableQueryTest.scala"&gt;Paimon 테스트 코드&lt;/a&gt;를 참고해 작성했습니다. Spark에서 두 개의 append 모드 테이블을 조인하는 경우, 두 테이블의 버킷 키와 버킷 수가 동일하다면 shuffle은 발생하지 않고 sort만 발생하는 것을 확인합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-scala"&gt;  test("Query on a bucketed table - join - append mode table case") {
    assume(gteqSpark3_5)
    withTable("t1", "t2") {
      spark.sql(
        "CREATE TABLE t1 (id INT, c STRING) TBLPROPERTIES ('bucket-key' = 'id', 'bucket'='10')")
      spark.sql("INSERT INTO t1 VALUES (1, 'x1'), (2, 'x3'), (3, 'x3'), (4, 'x4'), (5, 'x5')")
      // one bucketed table and one bucketed table
      spark.sql(
        "CREATE TABLE t2 (id INT, c STRING) TBLPROPERTIES ('bucket-key' = 'id', 'bucket'='10')")
      spark.sql("INSERT INTO t2 VALUES (1, 'x1'), (2, 'x3'), (3, 'x3'), (4, 'x4'), (5, 'x5')")
      checkAnswerAndShuffleSorts("SELECT * FROM t1 JOIN t2 on t1.id = t2.id", 0, 2)
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;실제로 테스트를 실행하면 shuffle은 0회, sort는 2회 발생합니다.&lt;/p&gt;

&lt;p&gt;저희 팀에서는 실시간 로그 수집에 Paimon의 append 모드 테이블을 사용하고 있고, 해당 Paimon 테이블을 Spark에서 읽고 조인해서 사용하는 경우가 빈번하므로 버킷 설정을 최적화하여 사용하고 있습니다.&lt;/p&gt;

&lt;h3 id=""&gt;파일 프루닝 전략&lt;/h3&gt;

&lt;p&gt;Paimon은 파일 프루닝 최적화를 통해 불필요한 I/O를 줄일 수 있도록 다양한 전략을 지원합니다. Paimon에서 파일 프루닝은 다음 기준으로 동작합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;파티션 프루닝&lt;/li&gt;
&lt;li&gt;버킷 프루닝&lt;/li&gt;
&lt;li&gt;매니페스트 파일의 최소/최대 집계 값 기반 프루닝&lt;/li&gt;
&lt;li&gt;&lt;a href="https://paimon.apache.org/docs/1.0/append-table/query-performance/#data-skipping-by-file-index"&gt;블룸 필터&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다만 이 글에선 블룸 필터를 제외한 나머지 부분만 기술합니다.&lt;/p&gt;

&lt;h4 id=""&gt;파티션 프루닝&lt;/h4&gt;

&lt;p&gt;파티션 칼럼에 대한 필터 조건이 존재하면 해당 파티션에만 접근합니다. 예를 들어, 파티션이 ymd이고 필터 조건이 "2025-05-10"이면 해당 파티션의 데이터만 읽습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/14-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;다음과 같은 코드에서 파티션 칼럼을 필터링 조건에 넣으면 파티션 프루닝이 동작하여 테이블 파일을 건너뛰는 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-scala"&gt;## partition: ymd
## bucket: hm, impId, requestId
df = (  
    spark.read.table("`paimon`.`default`.`t_test_log`")
    .select("ymd", "hm", "requestId", "impId")
)

spark.conf.set("spark.sql.sources.v2.bucketing.enabled", "true")

(
    ## number of skipped table files: 2818
    ## number of resulted table files: 6502 ➡️ 파티션 프루닝만 동작
    df.where(f"ymd = '{ymd}'").distinct().count(),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=""&gt;버킷 프루닝&lt;/h4&gt;

&lt;p&gt;버킷 프루닝의 경우 모든 버킷 키가 필터 조건에 포함되어야만 프루닝이 활성화됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/15-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;예를 들어, 버킷 키가 hm, impId, requestId이면 세 개 모두가 조건에 포함되어야 버킷 프루닝이 동작합니다.&lt;/p&gt;

&lt;p&gt;다음과 같은 코드에서 필터 조건에 파티션과 버킷 칼럼을 모두 넣어 파티션과 버킷 프루닝이 동시에 동작했을 때 가장 많은 파일을 건너뛰는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-scala"&gt;## partition: ymd
## bucket: hm, impId, requestId
df = (  
    spark.read.table("`paimon`.`default`.`t_test_log`")
    .select("ymd", "hm", "requestId", "impId")
)

spark.conf.set("spark.sql.sources.v2.bucketing.enabled", "true")

(
    ## number of skipped table files: 5341
    ## number of resulted table files: 6474 ➡️ 파티션 프루닝은 동작하지만, 추가 프루닝이 거의 되지 않는다.(버킷 프루닝 동작하지 않음)
    df.where(f"ymd = '{ymd}' and impId = '{impId}'").distinct().count(),

    ## number of skipped table files: 8278
    ## number of resulted table files: 72 ➡️ 파티션 + 추가 프루닝 동작
    df.where(f"ymd = '{ymd}' and hm = '{hm}'").distinct().count(),

    ## number of skipped table files: 8278
    ## number of resulted table files: 72 ➡️ 파티션 + 추가 프루닝 동작
    df.where(f"ymd = '{ymd}' and hm = '{hm}' and impId = '{impId}'").distinct().count(),

    ## number of skipped table files: 8420
    ## number of resulted table files: 2 ➡️ 파티션 + 버킷 프루닝 동작
    df.where(f"ymd = '{ymd}' and hm = '{hm}' and impId = '{impId}' and requestId = '{requestId}'").distinct().count(),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id="httpspaimonapacheorgdocs10appendtablequeryperformance"&gt;&lt;a href="https://paimon.apache.org/docs/1.0/append-table/query-performance/"&gt;매니페스트 파일의 최소/최대 집계 값 기반 프루닝&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;일부 버킷 키에 대한 필터만 있더라도, 매니페스트 파일에 저장된 집계 값(최소/최대 등)을 기준으로 프루닝이 추가로 수행될 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/16-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;예를 들어 다음과 같은 코드에서 파티션 칼럼인 &lt;code&gt;ymd&lt;/code&gt;와 버킷 키 중 하나인 hm 필드만 필터 조건에 넣어도 72개의 파일 중 일부만 읽는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-scala"&gt;## partition: ymd
## bucket: hm, impId, requestId
df = (  
    spark.read.table("`paimon`.`default`.`t_test_log`")
    .select("ymd", "hm", "requestId", "impId")
)

spark.conf.set("spark.sql.sources.v2.bucketing.enabled", "true")

(
    ## number of skipped table files: 8278
    ## number of resulted table files: 72 ➡️ 파티션 + 추가 프루닝 동작
    df.where(f"ymd = '{ymd}' and hm = '{hm}'").distinct().count(),

    ## number of skipped table files: 8278
    ## number of resulted table files: 72 ➡️ 파티션 + 추가 프루닝 동작
    df.where(f"ymd = '{ymd}' and hm = '{hm}' and impId = '{impId}'").distinct().count(),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;파일 시스템 테이블을 확인해보면, &lt;strong&gt;min&lt;em&gt;hm보다 크거나 같고, max&lt;/em&gt;hm보다 작거나 같은&lt;/strong&gt; 파일이 정확히 72개 존재하는 것을 알 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-scala"&gt;get_hm = lambda s: [e.split("=")[1] for e in s[1:-1].split(", ") if e.split("=")[0] == "hm"][0]  
get_hm_udf = F.udf(get_hm, StringType())

df = spark.read.table("`paimon`.`default`.`t_test_log$files`")  
df.show(3)

df2 = (  
    df.select(
        "partition", "bucket",
        get_hm_udf("min_value_stats").alias("min_hm"),
        get_hm_udf("max_value_stats").alias("max_hm")
    )
    .where(f"partition = '[{ymd}]' and min_hm &amp;lt;= '{hm}' and max_hm &amp;gt;= '{hm}'")
)
df2.count()


+------------+------+--------------------+-----------+---------+-----+------------+------------------+-------+-------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+-----------+
|   partition|bucket|           file_path|file_format|schema_id|level|record_count|file_size_in_bytes|min_key|max_key|   null_value_counts|     min_value_stats|     max_value_stats|min_sequence_number|max_sequence_number|       creation_time|file_source|
+------------+------+--------------------+-----------+---------+-----+------------+------------------+-------+-------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+-----------+
|[2025-04-05]|     5|[hdfs://...|](hdfs://...)    parquet|        0|    0|     1607000|         256177358|   NULL|   NULL|{a=0, b...|{a=0, b...|{a=647937, ...|                  0|            1606999|2025-04-07 16:09:...|    COMPACT|
|[2025-04-05]|     5|[hdfs://...|](hdfs://...)    parquet|        0|    0|     1569000|         255413869|   NULL|   NULL|{a=0, b...|{a=0, b...|{a=654275, ...|            1607000|            3175999|2025-04-07 16:15:...|    COMPACT|
|[2025-04-05]|     5|[hdfs://...|](hdfs://...)    parquet|        0|    0|     1540000|         256047471|   NULL|   NULL|{a=0, b...|{a=0, b...|{a=660521, ...|            3176000|            4715999|2025-04-07 16:21:...|    COMPACT|
+------------+------+--------------------+-----------+---------+-----+------------+------------------+-------+-------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+-----------+
72  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이러한 점을 고려해 Paimon 테이블의 DDL을 작성하고 Paimon 테이블을 쿼리하면 읽기 성능을 크게 향상시킬 수 있습니다.&lt;/p&gt;

&lt;h3 id="httpspaimonapacheorgdocs10flinkexpirepartitionretention"&gt;&lt;a href="https://paimon.apache.org/docs/1.0/flink/expire-partition/"&gt;파티션 만료&lt;/a&gt;(retention 관리)&lt;/h3&gt;

&lt;p&gt;Hive 기반 운영 환경에서는 retention을 위해 배치 작업으로 삭제를 실행해야 했습니다. 하지만 Paimon은 자동 만료 파티션 기능을 제공합니다. 각 모드별 사용 방법 및 특징은 아래와 같습니다.&lt;/p&gt;

&lt;h4 id="valuestime"&gt;values-time 모드&lt;/h4&gt;

&lt;p&gt;파티션 칼럼을 기준으로 타임스탬프를 구성하고, 만료 시간이 경과하면 자동 삭제됩니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE IF NOT EXISTS `paimon`.`default`.`t_values_time`  
(
    ymd STRING,
    hm STRING,
    k STRING,
    v_a INT,
    PRIMARY KEY (`k`) NOT ENFORCED
)
COMMENT 't_partition_expire'  
PARTITIONED BY (`ymd`, `hm`)  
WITH (  
    'partition.expiration-strategy' = 'values-time'
    'partition.timestamp-pattern' = '$ymd $hm',
    'partition.timestamp-formatter' = 'yyyy-MM-dd HHmm',
    'partition.expiration-time' = '3 d',
    'partition.expiration-check-interval' = '1 d'
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id="updatetime"&gt;update-time 모드&lt;/h4&gt;

&lt;p&gt;가장 최근에 해당 파티션에 쓰기된 시점을 기준으로 만료 여부를 판단합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE IF NOT EXISTS `paimon`.`default`.`t_update_time`  
(
    ymd STRING,
    hm STRING,
    k STRING,
    v_a INT,
    PRIMARY KEY (`k`) NOT ENFORCED
)
COMMENT 't_partition_expire'  
PARTITIONED BY (`ymd`, `hm`)  
WITH (  
    'partition.expiration-strategy' = 'update-time'
    'partition.expiration-time' = '3 d',
    'partition.expiration-check-interval' = '1 d'
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;update-time 모드의 경우, backfill이나 다른 이유로 이전 파티션에 UPDATE가 발생해 원하는 시점에 파티션이 삭제되지 않을 수도 있으므로 저희 팀에서는 values-time 모드를 사용하고 있습니다.&lt;/p&gt;

&lt;h4 id=""&gt;파티션 만료는 언제, 어떻게 동작할까?&lt;/h4&gt;

&lt;p&gt;우선 파티션 만료 작업은 커밋 작업의 일부로 실행됩니다. 따라서 새로운 데이터가 들어와 커밋이 발생할 때 삭제할 파티션이 있는지 확인 후 후속 작업이 진행됩니다.&lt;/p&gt;

&lt;p&gt;전역 커밋 작업을 처리하는 Flink의 task manager에서 다음과 같이 파티션 만료 작업을 수행합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2025-06-25 21:57:06,690 INFO  org.apache.paimon.operation.PartitionExpire                  [] - Expire Partitions: [{ymd=2025-06-25, hm=1800}]  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;다만 이렇게 파티션 만료 작업을 수행하더라도, 작업이 수행된 직후는 데이터 파일이 아직 남아 있는 것을 확인할 수 있습니다. 이는 파티션 만료 작업은 논리적으로 파티션을 삭제하는 작업이고, 실제 데이터 삭제는 스냅샷이 삭제되는 시점에 진행되기 때문입니다.&lt;/p&gt;

&lt;p&gt;즉, 파티션 만료 작업 이후에 논리적으로 삭제된 파티션이 조회되지 않더라도, 스토리지 용량 확보를 위한 데이터 삭제는 스냅샷이 만료되는 시점까지는 기다려야 합니다.&lt;/p&gt;

&lt;p&gt;조금 더 자세히 살펴보겠습니다. Paimon 테이블에 커밋이 발생할 때, expire 동작은 &lt;a href="https://github.com/apache/paimon/blob/c07ec05d287f8db42f039e68afb9f1f12c76026e/paimon-core/src/main/java/org/apache/paimon/table/sink/TableCommitImpl.java#L332-L348"&gt;다음 코드&lt;/a&gt;와 같이 진행됩니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;    private void expire(long partitionExpireIdentifier) {
        // expire consumer first to avoid preventing snapshot expiration
        if (consumerExpireTime != null) {
            consumerManager.expire(LocalDateTime.now().minus(consumerExpireTime));
        }

        expireSnapshots();

        if (partitionExpire != null) {
            partitionExpire.expire(partitionExpireIdentifier);
        }

        if (tagAutoManager != null) {
            tagAutoManager.run();
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;만료 동작은 다음과 같은 순서로 이뤄집니다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;컨슈머 만료 확인  &lt;/li&gt;
&lt;li&gt;스냅샷 만료(여기서 물리적 삭제가 진행됩니다.)  &lt;/li&gt;
&lt;li&gt;파티션 만료(파티션에 대한 논리적 삭제가 진행됩니다.)  &lt;/li&gt;
&lt;li&gt;태그 만료&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;그림으로 정리하면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/17-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;먼저 &lt;a href="https://github.com/apache/paimon/blob/release-1.0.1/paimon-core/src/main/java/org/apache/paimon/table/ExpireSnapshotsImpl.java"&gt;스냅샷에 대한 물리적 삭제&lt;/a&gt;가 실행되고 나서 파티션 만료를 확인하고, 삭제할 파티션이 존재한다면 &lt;a href="https://github.com/apache/paimon/blob/c07ec05d287f8db42f039e68afb9f1f12c76026e/paimon-core/src/main/java/org/apache/paimon/operation/FileStoreCommitImpl.java#L527-L566"&gt;dropPartitions&lt;/a&gt;을 통해 OVERWRITE 커밋을 생성하며 파티션에 대한 논리적 삭제가 진행됩니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;    /** Type of changes in this snapshot. */
    public enum CommitKind {

        /** Changes flushed from the mem table. */
        APPEND,

        /** Changes by compacting existing data files. */
        COMPACT,

        /** Changes that clear up the whole partition and then add new records. */
        OVERWRITE,

        /** Collect statistics. */
        ANALYZE
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OVERWRITE 커밋이란 파티션 만료 시 발생하는 커밋인데요, 이해를 위해 실제 스냅샷 예시를 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;다음 스냅샷은 APPEND 커밋입니다. 이때는 deltaRecordCount가 증가하는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;{
  "version" : 3,
  "id" : 243,
  "schemaId" : 0,
  "baseManifestList" : "manifest-list-d18f3e24-aebf-4b93-8403-c9f706132a49-348",
  "deltaManifestList" : "manifest-list-d18f3e24-aebf-4b93-8403-c9f706132a49-349",
  "changelogManifestList" : null,
  "commitUser" : "a34c2fbe-8046-42ee-a4f6-ac740fc22132",
  "commitIdentifier" : 176,
  "commitKind" : "APPEND",
  "timeMillis" : 1750859955973,
  "logOffsets" : { },
  "totalRecordCount" : 475240,
  "deltaRecordCount" : 475240,
  "changelogRecordCount" : 0,
  "watermark" : -9223372036854775808
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;반면 OVERWRITE의 경우 deltaRecordCount가 감소하는 것을 확인할 수 있습니다. 이를 통해 파티션의 논리적 삭제를 확인할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;{
  "version" : 3,
  "id" : 257,
  "schemaId" : 0,
  "baseManifestList" : "manifest-list-64c333e3-c023-40fe-ab7c-194f4c187224-144",
  "deltaManifestList" : "manifest-list-64c333e3-c023-40fe-ab7c-194f4c187224-145",
  "changelogManifestList" : null,
  "commitUser" : "a34c2fbe-8046-42ee-a4f6-ac740fc22132",
  "commitIdentifier" : 185,
  "commitKind" : "OVERWRITE",
  "timeMillis" : 1750860296210,
  "logOffsets" : { },
  "totalRecordCount" : 0,
  "deltaRecordCount" : -563475,
  "changelogRecordCount" : 0,
  "watermark" : -9223372036854775808
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=""&gt;자동 태깅 기능&lt;/h3&gt;

&lt;p&gt;Paimon의 자동 태깅 기능은 이력 데이터를 쉽게 조회할 수 있도록 태그를 자동으로 생성하는 기능입니다. 이를 통해 특정 시점의 스냅샷을 읽을 수 있습니다.  &lt;/p&gt;

&lt;p&gt;Hive에서 메타 테이블을 daily dump로 관리하던 것을 대체할 수 있으며, Paimon은 LSM으로 구성되어 있기에 중복 데이터 적재 방지를 기대할 수 있습니다. LSM 구조상 여러 태그 사이에 상위 레벨의 대규모 파일을 공유함으로써 스토리지 효율성을 확보할 수 있기 때문입니다.&lt;/p&gt;

&lt;p&gt;자동 태그 생성 옵션 예는 다음과 같습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    -- Auto Tagging Option
    'tag.automatic-completion' = 'true',
    'tag.automatic-creation' = 'process-time',
    'tag.creation-period' = 'hourly',
    'tag.default-time-retained' = '2 hours'
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=""&gt;태그 생성 결과&lt;/h4&gt;

&lt;p&gt;태그는 스냅샷 기반으로 생성되며, 생성된 태그는 테이블 폴더 내에 &lt;code&gt;tag&lt;/code&gt; 폴더에서 관리됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/18-4.png" alt="스크린샷 2024-10-31 오후 5 44 19" /&gt;&lt;/p&gt;

&lt;p&gt;tag 폴더가 새로 생기고 설정된 주기마다 태그가 생성됩니다. &lt;a href="https://github.com/apache/paimon/blob/c07ec05d287f8db42f039e68afb9f1f12c76026e/paimon-core/src/main/java/org/apache/paimon/tag/TagPeriodHandler.java#L221-L231"&gt;태그의 생성 주기는 1.0.1 기준으로 hourly, two hours, daily만 설정 가능&lt;/a&gt;합니다. 시간 단위의 경우 태그 이름은 &lt;code&gt;2024-10-31 16&lt;/code&gt;와 같은 형식이며 하이픈(-) 유무만 설정할 수 있습니다.&lt;/p&gt;

&lt;h5 id="tag2024103116"&gt;tag-2024-10-31 16 파일&lt;/h5&gt;

&lt;p&gt;실제 태그 파일을 열어보면, 스냅샷 파일과 거의 동일한 형식이며 태그 정보만 추가된 형태임을 알 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;{
  "version" : 3,
  "id" : 6,
  "schemaId" : 0,
  "baseManifestList" : "manifest-list-9742e9bc-4159-4f6a-94e2-d5aa71267ad2-11",
  "deltaManifestList" : "manifest-list-9742e9bc-4159-4f6a-94e2-d5aa71267ad2-12",
  "changelogManifestList" : null,
  "indexManifest" : "index-manifest-d6db990a-ecf7-4fff-8ea4-471e74e2a25c-0",
  "commitUser" : "f7c2f94c-3f6b-443a-a924-fc9270814ecb",
  "commitIdentifier" : 6,
  "commitKind" : "APPEND",
  "timeMillis" : 1730361611361,
  "logOffsets" : { },
  "totalRecordCount" : 3,
  "deltaRecordCount" : 0,
  "changelogRecordCount" : 0,
  "watermark" : -9223372036854775808,
  "tagCreateTime" : [ 2024, 10, 31, 17, 0, 11, 362808000 ],
  "tagTimeRetained" : 7200.000000000
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id="snapshot6"&gt;snapshot-6 파일&lt;/h5&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;{
  "version" : 3,
  "id" : 6,
  "schemaId" : 0,
  "baseManifestList" : "manifest-list-9742e9bc-4159-4f6a-94e2-d5aa71267ad2-11",
  "deltaManifestList" : "manifest-list-9742e9bc-4159-4f6a-94e2-d5aa71267ad2-12",
  "changelogManifestList" : null,
  "indexManifest" : "index-manifest-d6db990a-ecf7-4fff-8ea4-471e74e2a25c-0",
  "commitUser" : "f7c2f94c-3f6b-443a-a924-fc9270814ecb",
  "commitIdentifier" : 6,
  "commitKind" : "APPEND",
  "timeMillis" : 1730361611361,
  "logOffsets" : { },
  "totalRecordCount" : 3,
  "deltaRecordCount" : 0,
  "changelogRecordCount" : 0,
  "watermark" : -9223372036854775808
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;정리해보면 태그는 그 시점의 스냅샷을 기록하는 형태이고 각 스냅샷은 매니페스트 파일로 관리되므로 같은 데이터에 대한 중복 저장 없이 효율적으로 관리할 수 있습니다.&lt;/p&gt;

&lt;h4 id=""&gt;태그 조회 방법&lt;/h4&gt;

&lt;p&gt;태그의 조회는 기본적으로 스냅샷 조회와 동일합니다. Flink의 경우 streaming 모드에선 특정 태그(스냅샷)에 대한 데이터 조회가 어렵고, 특정 태그(스냅샷)으로 부터의 증분을 읽는 것만 가능합니다. 특정 태그에 대한 데이터 조회를 위해선 batch 모드로 설정한 뒤 쿼리를 실행해야 합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;SET 'execution.runtime-mode' = 'batch';  
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;SELECT * FROM `paimon`.`default`.`t_tag_test` /*+ OPTIONS('scan.tag-name' = '2025-05-05 12') */;  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Spark에서 Paimon 테이블에 대한 태그(스냅샷) 조회 시 Flink와는 문법이 조금 다릅니다. 아래의 경우 Spark SQL을 통한 태그(스냅샷) 조회 방법입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;-- Spark SQL

-- Read latest snapshot
SELECT * FROM t;

-- Read Tag snapshot
SELECT * FROM t VERSION AS OF '2025-05-05';  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/19-5.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;Spark의 Dataframe API을 사용하는 경우의 예는 다음과 같습니다. Pyspark 기준으로 작성했습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-scala"&gt;df = spark.read.format("paimon").option("scan.tag-name", "2025-05-05").table("paimon.default.t_tag_test")

df  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;현재 생성된 태그의 목록을 확인하려면 Paimon의 &lt;a href="https://paimon.apache.org/docs/1.0/concepts/system-tables/#tags-table"&gt;시스템 테이블&lt;/a&gt;을 활용합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;-- Spark SQL

-- 태그 목록 조회
SELECT * FROM t$tags;  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/20-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이와 같이 Paimon은 태그(스냅샷)를 활용해 특정 시점의 스냅샷을 조회하는 타임 트래블 쿼리를 지원하기 때문에 디버깅이 매우 용이합니다.&lt;/p&gt;

&lt;h3 id="auditlog"&gt;감사 로그(audit log)를 활용한 변경분 조회&lt;/h3&gt;

&lt;p&gt;Paimon은 스냅샷 사이의 변경분을 조회할 수 있는 증분 쿼리 기능도 제공합니다. 두 스냅샷 사이의 변경분을 &lt;a href="https://paimon.apache.org/docs/1.0/concepts/system-tables/#audit-log-table"&gt;audit_log 시스템 테이블&lt;/a&gt;로 확인해 디버깅에 활용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/21-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;다음은 스냅샷 7777과 8888 사이에서 각 키의 변경 사항을 확인하는 예입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/22-4.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id="consumerid"&gt;consumer-id&lt;/h3&gt;

&lt;p&gt;Paimon은 스트리밍 환경에서 스냅샷 기반 오프셋을 관리하기 위해 consumer-id 옵션을 제공합니다. 이를 통해 exactly-once를 보장할 수 있습니다.&lt;/p&gt;

&lt;p&gt;consumer-id에 대한 상세 옵션은 아래와 같습니다.(1.0.1 기준)&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;키&lt;/th&gt;  
&lt;th&gt;기본 값&lt;/th&gt;  
&lt;th&gt;타입&lt;/th&gt;  
&lt;th&gt;설명&lt;/th&gt;  
&lt;/tr&gt;&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;consumer-id&lt;/td&gt;  
&lt;td&gt;(없음)&lt;/td&gt;  
&lt;td&gt;String&lt;/td&gt;  
&lt;td&gt;스토리지에서 컨슈머 오프셋을 기록하기 위한 컨슈머 ID.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;consumer.expiration-time&lt;/td&gt;  
&lt;td&gt;(없음)&lt;/td&gt;  
&lt;td&gt;Duration&lt;/td&gt;  
&lt;td&gt;컨슈머 파일의 만료 시간을 설정하는 옵션. 마지막 수정 후 이 시간을 초과하면 컨슈머 파일이 만료됨.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;consumer.ignore-progress&lt;/td&gt;  
&lt;td&gt;false&lt;/td&gt;  
&lt;td&gt;Boolean&lt;/td&gt;  
&lt;td&gt;새로 시작된 작업에서 컨슈머 진행 상황을 무시할지 여부.&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;consumer.mode&lt;/td&gt;  
&lt;td&gt;exactly-once&lt;/td&gt;  
&lt;td&gt;Enum&lt;/td&gt;  
&lt;td&gt;테이블의 컨슈머 일관성 모드를 지정.&lt;br&gt;가능한 값:&lt;ul&gt;&lt;li&gt;"exactly-once": reader가 스냅샷 단위로 데이터를 소비하며, 컨슈머에 기록된 snapshot-id가 모든 reader가 정확히 소비한 snapshot-id + 1임을 엄격히 보장.&lt;/li&gt;&lt;li&gt;"at-least-once": 각 reader가 서로 다른 속도로 스냅샷을 소비하며, 모든 reader 중 가장 느린 소비 진행 상황의 스냅샷이 컨슈머에 기록됨.&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;스트리밍 읽기 테이블에 반드시 &lt;code&gt;consumer.expiration-time&lt;/code&gt;을 명시해야 합니다. 이는 consumer-id를 사용할 땐 컨슈머에서 바라보고 있는 스냅샷이 삭제되지 않도록 보장하고 있기 때문입니다.&lt;/p&gt;

&lt;p&gt;따라서 &lt;code&gt;consumer.expiration-time&lt;/code&gt;이 명시되지 않으면 스냅샷이 삭제되지 않고 계속해서 늘어나 스토리지 이슈가 발생하기 때문에, 해당 옵션을 설정하지 않으면 Paimon에서는 다음과 같은 예외를 발생시킵니다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Exception in thread "main" java.lang.IllegalArgumentException: consumer.expiration-time should be specified when using consumer-id.  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;consumer.expiration-time&lt;/code&gt;는 쿼리 힌트가 아니라 tblproperties에 명시되어야 정상적으로 동작합니다(참고: &lt;a href="https://github.com/apache/paimon/issues/4305"&gt;관련 Paimon main PR&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;실제 consumer-id 사용 방법은 아래와 같습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE IF NOT EXISTS paimon.default.t_consumer_id_test  
(
    id    INT,
    value STRING
    PRIMARY KEY(`id`) NOT ENFORCED
)
WITH (  
    ...
    'consumer.expiration-time' = '2 d'
    ...
)
;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;먼저 위와 같이 스트리밍 읽기 테이블에 &lt;code&gt;consumer.expiration-time&lt;/code&gt;을 명시합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;INSERT INTO paimon.default.t_consumer_id_test  
SELECT  
    t1.`id`,
    t1.`value`
FROM paimon.default.t_source1 /*+ OPTIONS('consumer-id' = 'test-id') */ AS t1  
LEFT JOIN paimon.default.t_source2 /*+ OPTIONS('consumer-id' = 'test-id') */ AS t2  
ON t1.id = t2.id  
;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이후 consumser-id를 등록하려는 테이블의 쿼리 힌트로 consumer-id 이름을 등록해서 사용하면 됩니다.&lt;/p&gt;

&lt;h4 id="consumeridexactlyonce"&gt;&lt;code&gt;consumer-id&lt;/code&gt; 사용 시 exactly-once를 보장할 수 있을까?&lt;/h4&gt;

&lt;p&gt;consumer-id를 사용하면 진짜 exactly-once를 보장할 수 있는지에 대해 확인하기 위해 아래의 테스트를 진행했습니다.&lt;/p&gt;

&lt;p&gt;첫 번째 실행에서는 각 원본을 스캔하고 조인합니다. 이때 스트리밍 조인 애플리케이션이 각 원본에 consumer-id를 등록합니다. 그 결과, 다음과 같이 원본별로 처리된 레코드 수를 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/23-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;원본 테이블 폴더의 하위에는 &lt;code&gt;consumer&lt;/code&gt;라는 폴더가 생기고, 그 밑에는 consumer-id별로 가리키는 스냅샷 번호가 저장됩니다. 다음은 6번 스냅샷까지 처리했다는 의미입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;{
  "nextSnapshot" : 7
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;원본 테이블의 모든 레코드에 대해 조인을 완료한 뒤 애플리케이션을 종료합니다.&lt;/p&gt;

&lt;p&gt;원본 테이블에 더 유입된 레코드가 없다면, 스트리밍 조인 애플리케이션은 재실행하더라도 consumer-id를 식별하여 마지막으로 읽은 스냅샷의 다음 버전부터 읽기 때문에 새로 조인하는 레코드가 없습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/24-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이와 같이, consumer-id를 사용하면 애플리케이션을 재실행하더라도 exactly-once를 보장할 수 있습니다. 저희 팀에서도 at-least once가 아닌 exactly-once를 보장해야하는 환경에선 consumer-id를 활용하고 있습니다.&lt;/p&gt;

&lt;h3 id="paimonmergeenginehttpspaimonapacheorgdocs10primarykeytablemergeengineaggregation"&gt;&lt;a href="https://paimon.apache.org/docs/1.0/primary-key-table/merge-engine/aggregation/"&gt;실시간 집계(Paimon merge-engine)&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Paimon은 실시간 집계 기능을 지원하기 위해 병합 엔진으로 aggregation 모드를 제공합니다. 해당 기능은 PK 테이블에서만 동작합니다.&lt;/p&gt;

&lt;p&gt;sum 함수와 collect 함수를 예로 살펴보겠습니다.&lt;/p&gt;

&lt;h4 id="1sum"&gt;예 1. sum 함수&lt;/h4&gt;

&lt;p&gt;테이블을 생성할 때 &lt;strong&gt;&lt;code&gt;merge-engine&lt;/code&gt;을 &lt;code&gt;aggregation&lt;/code&gt;으로 설정한 뒤, 원하는 필드에 사용하려는 집계 함수를 설정&lt;/strong&gt;합니다. 이 코드에서는 v 필드를 모두 sum으로 집계합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE IF NOT EXISTS `paimon`.`default`.`log_aggregation_sum` (  
    row_kind STRING,
    k STRING,
    v BIGINT,
    PRIMARY KEY (k) NOT ENFORCED
)
WITH (  
    'merge-engine'='aggregation',
    'fields.v.aggregate-function'='sum',
    'changelog-producer'='lookup',
     'rowkind.field' = 'row_kind'
);

INSERT INTO `paimon`.`default`.`log_aggregation_sum` VALUES ('+I', '1', 1);  
INSERT INTO `paimon`.`default`.`log_aggregation_sum` VALUES ('+I', '1', 2);  
INSERT INTO `paimon`.`default`.`log_aggregation_sum` VALUES ('-D', '1', 1);  
INSERT INTO `paimon`.`default`.`log_aggregation_sum` VALUES ('+I', '2', 3);  
INSERT INTO `paimon`.`default`.`log_aggregation_sum` VALUES ('+I', '2', 2);  
INSERT INTO `paimon`.`default`.`log_aggregation_sum` VALUES ('-D', '2', 2);

-- 예상되는 결과: k: 1은 v: 2, k: 2는 v: 3이 남으면 정상
SELECT * FROM `paimon`.`default`.`log_aggregation_sum`;  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;들어오는 레코드를 순서대로 처리하면, 키 1에 대해 1과 2가 차례대로 INSERT된 후 1이 DELETE되는 경우 최종 합은 2로 유지됩니다. 키 2에 대해 3과 2가 차례대로 INSERT되고 2가 DELETE된 경우 최종 합은 3이 됩니다.&lt;/p&gt;

&lt;p&gt;실제 테스트 결과도 기댓값과 동일합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/25-6.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id="2collect"&gt;예 2. collect 함수&lt;/h4&gt;

&lt;p&gt;마찬가지로 집계 관련 옵션을 DDL에 설정한 후 결과를 확인해 보겠습니다.&lt;/p&gt;

&lt;p&gt;collect 함수의 경우 array 형태로 값을 누적하며, 삭제 시 해당 요소를 제거합니다. 키 1에 대해 [1, 2]가 들어온 뒤 1이 제거되면 [2]가 남고, 키 2에 대해 [3, 2] 중 2가 제거되면 [3]만 남게 됩니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE IF NOT EXISTS `paimon`.`default`.`log_aggregation_collect` (  
    row_kind STRING,
    k STRING,
    v ARRAY&amp;lt;STRING&amp;gt;,
    PRIMARY KEY (k) NOT ENFORCED
)
WITH (  
    'merge-engine'='aggregation',
    'fields.v.aggregate-function'='collect',
    'changelog-producer'='lookup',
     'rowkind.field' = 'row_kind'
);

INSERT INTO `paimon`.`default`.`log_aggregation_collect` VALUES ('+I', '1', array ['1']);  
INSERT INTO `paimon`.`default`.`log_aggregation_collect` VALUES ('+I', '1', array ['2']);  
INSERT INTO `paimon`.`default`.`log_aggregation_collect` VALUES ('-D', '1', array ['1']);  
INSERT INTO `paimon`.`default`.`log_aggregation_collect` VALUES ('+I', '2', array ['3']);  
INSERT INTO `paimon`.`default`.`log_aggregation_collect` VALUES ('+I', '2', array ['2']);  
INSERT INTO `paimon`.`default`.`log_aggregation_collect` VALUES ('-D', '2', array ['2']);

-- 예상되는 결과: k: 1은 v: 2, k: 2는 v: 3이 남으면 정상
SELECT * FROM `paimon`.`default`.`log_aggregation_collect`;  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;다음의 최종 결과를 보면 예상했던 값과 동일한 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/26-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이와 같이 Paimon에선 비교적 적은 비용으로 실시간 집계를 구현할 수 있습니다.&lt;/p&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;h3 id=""&gt;운영 중 겪은 이슈와 개선 사항&lt;/h3&gt;

&lt;p&gt;저희 팀에서 Paimon을 사용하면서 다음과 같은 이슈를 경험했습니다.&lt;/p&gt;

&lt;h4 id="spark"&gt;Spark 배치 접근 오류&lt;/h4&gt;

&lt;p&gt;Paimon 1.0 이전에는 Spark에서 배치 접근 시 특정 필드에서 ArrayIndexOutOfBoundsException 오류가 있었으나, 현재(1.1 버전)는 해당 문제가 해결되었습니다.&lt;/p&gt;

&lt;h4 id="map"&gt;스키마 진화(Map 타입 관련 버그)&lt;/h4&gt;

&lt;p&gt;스트리밍 데이터에 대해 스키마 진화를 적용하려면 Table API를 사용하는 대신 DataStream API를 사용해서 구현해야 합니다. Paimon RichCDCRecord를 기반으로 스트리밍 데이터 ingestion 시에 스키마 진화를 적용하려 했으나 Map 타입 데이터에 대한 버그가 존재하는 것을 확인했습니다. 해당 이슈는 &lt;a href="https://github.com/apache/paimon/pull/4919"&gt;Apache Paimon 공식 GitHub에 기여&lt;/a&gt;한 결과 1.1 버전에서 수정되었습니다.&lt;/p&gt;

&lt;p&gt;이를 통해 현재는 스키마 레지스트리와 연동하여 스키마 변경 발생 시 자동으로 스키마가 변경되도록 하고 있습니다. 다만 Paimon에선 Flink SQL 기반 작업을 권장하므로 DataStream API 사용 시에는 검증이 필요한 부분이 있습니다.&lt;/p&gt;

&lt;h3 id="paimon"&gt;Paimon을 사용하면서 좋았던 부분과 향후 계획&lt;/h3&gt;

&lt;p&gt;Paimon은 Iceberg와 비교했을 때 테이블 관리 작업이 불필요하다는 점이 가장 큰 장점으로 작용했습니다. 별도의 관리 작업 없이 자동으로 compaction, 태그 관리, 파티션 만료 등을 지원하여 운영 부담을 크게 줄일 수 있었습니다.&lt;/p&gt;

&lt;p&gt;또한 Flink와의 궁합이 매우 뛰어나 실시간 처리 요건이 발생할 때마다 유연하게 대응할 수 있었고, 부분 업데이트, rowkind, consumer-id 등 실시간 데이터 처리에 필요한 기능도 잘 갖추고 있어 만족스러웠습니다.&lt;/p&gt;

&lt;p&gt;초기에는 공식 문서 외에 참고할 수 있는 자료가 많지 않아 다소 우려가 있었지만, Alibaba 측에서 문서를 지속적으로 개선하고 있어 현재는 참고할 수 있는 문서가 많이 증가했고, GitHub 커뮤니티를 통한 이슈 대응도 매우 빠른 편이었습니다.&lt;/p&gt;

&lt;p&gt;저희 팀은 현재 레이크하우스 설루션으로 Iceberg와 Paimon을 병행하여 사용하고 있으며 다음과 같은 검토를 진행 중입니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;현재는 Spark 세션 생성 시 Iceberg 카탈로그만 Hive 메타스토어와 연동되는데, Paimon 카탈로그의 Hive 연동에 대한 추가 검토 예정&lt;/li&gt;
&lt;li&gt;Spark 기반의 대규모 배치 처리 시 Iceberg와의 성능 비교 및 검토
&lt;ul&gt;&lt;li&gt;일반적으로 Iceberg가 배치 처리 성능에서는 우위에 있을 것으로 예상되며, 실제 사용 케이스에 따라 적합한 포맷을 사용하려고 합니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apache Paimon을 Flink에서 적용한 내용을 담은 이 글이 스트리밍 레이크하우스 선택 및 운영에 도움이 되기를 바랍니다.&lt;/p&gt;

&lt;p&gt;발표를 준비하며 함께 검토해 주신 저희 광고 성과 최적화 개발1 팀의 모든 구성원분께 진심으로 감사드리며, 추가 문의나 피드백은 언제나 환영합니다.&lt;/p&gt;

&lt;p&gt;긴 글 읽어주셔서 감사합니다.&lt;/p&gt;

&lt;p&gt;관련 발표 영상은 &lt;a href="https://d2.naver.com/helloworld/4678393"&gt;Paimon 겟또다제 ! (w/ ADVoost Shopping)&lt;/a&gt;에서도 살펴보실 수 있습니다.&lt;/p&gt;

&lt;h2 id=""&gt;참고 자료&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://paimon.apache.org/docs/master"&gt;https://paimon.apache.org/docs/master&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.alibabacloud.com/blog/what-is-apache-paimon_601137"&gt;https://www.alibabacloud.com/blog/what-is-apache-paimon_601137&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.alibabacloud.com/blog/building-a-streaming-lakehouse-performance-comparison-between-paimon-and-hudi_601013"&gt;https://www.alibabacloud.com/blog/building-a-streaming-lakehouse-performance-comparison-between-paimon-and-hudi_601013&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jack-vanlightly.com/analyses/2024/7/3/understanding-apache-paimon-consistency-model-part-1"&gt;https://jack-vanlightly.com/analyses/2024/7/3/understanding-apache-paimon-consistency-model-part-1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jack-vanlightly.com/analyses/2024/7/3/understanding-apache-paimon-consistency-model-part-2"&gt;https://jack-vanlightly.com/analyses/2024/7/3/understanding-apache-paimon-consistency-model-part-2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=DEm6uZvqQeA&amp;amp;t=454s"&gt;https://www.youtube.com/watch?v=DEm6uZvqQeA&amp;amp;t=454s&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://flink.apache.org/what-is-flink/roadmap/#towards-streaming-warehouses"&gt;https://flink.apache.org/what-is-flink/roadmap/#towards-streaming-warehouses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/paimon/tree/master/paimon-benchmark/paimon-cluster-benchmark"&gt;https://github.com/apache/paimon/tree/master/paimon-benchmark/paimon-cluster-benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@ipolyzos_/the-majesty-of-apache-flink-and-paimon-d36e73571fc9"&gt;https://medium.com/@ipolyzos_/the-majesty-of-apache-flink-and-paimon-d36e73571fc9&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@ipolyzos_/apache-paimon-introducing-deletion-vectors-584666ee90de"&gt;https://medium.com/@ipolyzos_/apache-paimon-introducing-deletion-vectors-584666ee90de&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebook/rocksdb/wiki/Universal-Compaction"&gt;https://github.com/facebook/rocksdb/wiki/Universal-Compaction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/RoaringBitmap/RoaringBitmap"&gt;https://github.com/RoaringBitmap/RoaringBitmap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jack-vanlightly.com/blog/2024/8/13/table-format-comparisons-append-only-tables-and-incremental-reads"&gt;https://jack-vanlightly.com/blog/2024/8/13/table-format-comparisons-append-only-tables-and-incremental-reads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>
  </entry>
  <entry>
    <title>윈도잉(windowing) 기법을 적용한 고성능 표 컴포넌트 개발기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/1450243" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/1450243</id>
    <updated>2025-07-28T13:53:37Z</updated>
    <content type="html">&lt;p&gt;이 글은 '윈도잉(windowing) 기법'을 적용한 고성능 표 컴포넌트를 개발하여 네이버 사내 로그 시스템의 로그 뷰 성능을 개선한 사례를 공유합니다. &lt;/p&gt;

&lt;p&gt;다음과 같은 순서로 구성되었습니다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="#ch1"&gt;윈도잉 기법이란&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="#ch2"&gt;윈도잉 기법을 기반으로 만들어진 React 오픈소스 라이브러리&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="#ch3"&gt;자체 개발 고성능 표 컴포넌트 Big Table&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id="ch1"&gt;1. 윈도잉 기법이란&lt;/h2&gt;

&lt;p&gt;윈도잉 기법은 데이터 처리나 그래픽스, 운영체제 등에서 데이터를 일정한 '창(window)' 단위로 나눠 처리하는 기술입니다.&lt;/p&gt;

&lt;p&gt;주요 활용 예는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;데이터 스트리밍/시계열 처리에서의 윈도잉&lt;/li&gt;
&lt;li&gt;머신러닝에서의 윈도잉&lt;/li&gt;
&lt;li&gt;컴퓨터 그래픽스에서의 윈도잉&lt;/li&gt;
&lt;li&gt;React에서의 윈도잉(가상화)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;데이터 스트리밍/시계열 처리에서의 윈도잉&lt;/h3&gt;

&lt;p&gt;데이터 스트림을 일정 시간 또는 크기 단위의 구간(window)으로 나눠 처리하는 방식으로 대표적으로 세 종류가 있습니다.&lt;/p&gt;

&lt;h4 id="tumblingwindow"&gt;텀블링 윈도(tumbling window)&lt;/h4&gt;

&lt;p&gt;고정 시간 간격으로 겹치지 않게 데이터 분할. 실시간 로그 분석, 트래픽 모니터링, 센서 데이터 처리 등에 사용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/1-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://docs.confluent.io/platform/current/ksqldb/concepts/time-and-windows-in-ksqldb-queries.html"&gt;Time and Windows in ksqlDB for Confluent Platform&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id="slidingwindow"&gt;슬라이딩 윈도(sliding window)&lt;/h4&gt;

&lt;p&gt;고정 크기의 창을 일정 간격으로 겹치며 이동. 실시간 평균 온도 계산과 같이 5초마다 최근 1분 간의 데이터를 이용한 평균 계산 등에 사용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/2-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://docs.confluent.io/platform/current/ksqldb/concepts/time-and-windows-in-ksqldb-queries.html"&gt;Time and Windows in ksqlDB for Confluent Platform&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id="sessionwindow"&gt;세션 윈도(session window)&lt;/h4&gt;

&lt;p&gt;사용자의 활동 시간을 기준으로 구간을 설정. 사용자 세션과 같이 특정 시간 이상 활동이 없으면 새로운 세션으로 간주할 때 사용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/3-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://docs.confluent.io/platform/current/ksqldb/concepts/time-and-windows-in-ksqldb-queries.html"&gt;Time and Windows in ksqlDB for Confluent Platform&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=""&gt;머신러닝에서의 윈도잉&lt;/h3&gt;

&lt;p&gt;시계열 데이터를 학습하기 위해 데이터를 시퀀스 길이(Window Size)로 나눠서 처리하는 방식입니다. 예를 들어, 다음 그림은 LSTM(Long Short-Term Memory) 모델의 입력으로 사용하기 위해 5개의 시퀀스로 구성된 입력 형태를 보여줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/4-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://velog.io/@lazy_learner/LSTM-%EC%8B%9C%EA%B3%84%EC%97%B4-%EC%98%88%EC%B8%A1-%EB%AA%A8%EB%93%88-%EB%A7%8C%EB%93%A4%EA%B8%B0-1"&gt;LSTM 시계열 예측 모듈 만들기&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=""&gt;컴퓨터 그래픽스에서의 윈도잉&lt;/h3&gt;

&lt;p&gt;렌더링이나 이미지를 처리할 때 전체 화면이 아닌 일부 영역(window)만 선택적으로 처리하는 방식입니다.&lt;/p&gt;

&lt;h4 id="viewport"&gt;뷰포트(viewport)&lt;/h4&gt;

&lt;p&gt;전체 좌표 공간(world coordinates) 중에서 화면에 렌더링할 영역을 정의.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/5-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://www.w3.org/People/chris/SVGtut-WWW9/slide45.htm"&gt;The SVG Viewport&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id="clipping"&gt;클리핑(clipping)&lt;/h4&gt;

&lt;p&gt;객체가 화면 경계를 넘으면 보이지 않게 자르기.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/6-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://slideplayer.com/slide/13926109/"&gt;SlidePlayer&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id="tbr"&gt;타일 기반 렌더링(TBR)&lt;/h4&gt;

&lt;p&gt;모바일 GPU에서 주로 사용. 대역폭을 줄이고, 병렬 처리 가능.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/7-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://ozlael.tistory.com/23"&gt;모바일 기기의 Tile Based Rendering(타일 기반 렌더링)과 유니티에서의 주의 사항 #1 : TBR의 이해&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id="react"&gt;React에서의 윈도잉(가상화)&lt;/h3&gt;

&lt;p&gt;많은 수의 UI 요소를 &lt;strong&gt;화면에 보이는 범위만 렌더링하여 성능을 최적화&lt;/strong&gt;하는 방식입니다.&lt;/p&gt;

&lt;p&gt;React는 컴포넌트를 렌더링할 때 DOM 요소가 많을수록 초기 렌더링 시간이 증가하고, 스크롤 성능이 저하되며, 브라우저 메모리 소비가 증가하는데, 윈도잉 기법을 통해 이 문제를 해결할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/8-4.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://web.dev/articles/virtualize-long-lists-react-window?hl=ko"&gt;react-window를 사용하여 대규모 목록 가상화&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2 id="ch2"&gt;2. 윈도잉 기법을 기반으로 만들어진 React 오픈소스 라이브러리&lt;/h2&gt;

&lt;p&gt;다음은 윈도잉 기법을 기반으로 만들어진 대표적인 React 오픈소스 라이브러리의 특징을 비교한 표입니다.&lt;/p&gt;

&lt;table&gt;  
&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;항목&lt;/th&gt;  
&lt;th&gt;react-virtualized&lt;/th&gt;  
&lt;th&gt;react-window&lt;/th&gt;  
&lt;th&gt;@tanstack/react-virtual&lt;/th&gt;  
&lt;/tr&gt;  
&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;기능 수&lt;/td&gt;  
&lt;td&gt;많음&lt;/td&gt;  
&lt;td&gt;최소&lt;/td&gt;  
&lt;td&gt;최소(사용자 구성 중심)&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;파일 크기&lt;/td&gt;  
&lt;td&gt;무거움&lt;/td&gt;  
&lt;td&gt;가벼움&lt;/td&gt;  
&lt;td&gt;가벼움&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;유연성&lt;/td&gt;  
&lt;td&gt;제한적&lt;/td&gt;  
&lt;td&gt;제한적&lt;/td&gt;  
&lt;td&gt;유연함&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;최신성&lt;/td&gt;  
&lt;td&gt;업데이트 중단&lt;/td&gt;  
&lt;td&gt;유지 관리&lt;/td&gt;  
&lt;td&gt;활발히 개발 중&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;추천 용도&lt;/td&gt;  
&lt;td&gt;기존 프로젝트&lt;/td&gt;  
&lt;td&gt;간단한 UI&lt;/td&gt;  
&lt;td&gt;커스텀 UI&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;p&gt;'react-virtualized -&gt; react-window -&gt; @tanstack/react-virtual' 순으로 개발되었고, 기능 면에서는 'react-virtualized' 라이브러리가 많은 기능을 지원하지만 파일이 무겁습니다. 가장 최신이며 유연한 라이브러리는 '@tanstack/react-virtual'입니다.&lt;/p&gt;

&lt;p&gt;간단한 UI를 빠르게 개발하려면 'react-window', 유연한 커스텀 UI를 개발하려면 '@tanstack/react-virtual'을 추천합니다.&lt;/p&gt;

&lt;p&gt;예제를 통해 각 라이브러리의 사용법과 동작 원리를 살펴보겠습니다.&lt;/p&gt;

&lt;h3 id="reactvirtualized"&gt;react-virtualized&lt;/h3&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;import { InfiniteLoader, List } from "react-virtualized";  
import React from "react";  
import ReactDOM from "react-dom";  
import "react-virtualized/styles.css";

ReactDOM.render(  
  &amp;lt;InfiniteLoader
    isRowLoaded={isRowLoaded}
    loadMoreRows={({ startIndex, stopIndex }) =&amp;gt; {
      return fetch(
        `path/to/api?startIndex=${startIndex}&amp;amp;stopIndex=${stopIndex}`
      ).then((response) =&amp;gt; {
        // Store response data in list
      });
    }}
    rowCount={remoteRowCount}
  &amp;gt;
    {({ onRowsRendered, registerChild }) =&amp;gt; (
      &amp;lt;List
        height={200}
        onRowsRendered={onRowsRendered}
        overscanRowCount={10}
        ref={registerChild}
        rowCount={remoteRowCount}
        rowHeight={20}
        rowRenderer={({ key, index, style }) =&amp;gt; {
          return (
            &amp;lt;div key={key} style={style}&amp;gt;
              {list[index]}
            &amp;lt;/div&amp;gt;
          );
        }}
        width={300}
      /&amp;gt;
    )}
  &amp;lt;/InfiniteLoader&amp;gt;,
  document.getElementById("example")
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;주요 props에 대한 설명은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;height: 뷰포트 높이&lt;/li&gt;
&lt;li&gt;rowHeight: 행의 높이&lt;/li&gt;
&lt;li&gt;rowCount: 행의 개수&lt;/li&gt;
&lt;li&gt;overscanRowCount: 미리 불러올 행의 개수&lt;/li&gt;
&lt;li&gt;rowRenderer: 행 내용을 렌더링하는 함수&lt;/li&gt;
&lt;li&gt;loadMoreRows: 행을 추가로 로드할 때 호출되는 콜백&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="reactwindow"&gt;react-window&lt;/h3&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;import React from "react";  
import { FixedSizeList } from "react-window";  
import InfiniteLoader from "react-window-infinite-loader";

const ListComponent = ({ items, moreItemsLoading, loadMore, hasNextPage }) =&amp;gt; {  
  const Row = ({ index, style }) =&amp;gt; ({
    /* define the row component using items[index] */
  });

  const itemCount = hasNextPage ? items.length + 1 : items.length;

  return (
    &amp;lt;InfiniteLoader
      isItemLoaded={(index) =&amp;gt; index &amp;lt; items.length}
      itemCount={itemCount}
      loadMoreItems={loadMore}
    &amp;gt;
      {({ onItemsRendered, ref }) =&amp;gt; (
        &amp;lt;FixedSizeList
          height={500}
          width={500}
          itemCount={itemCount}
          itemSize={120}
          onItemsRendered={onItemsRendered}
          overscanCount={10}
          ref={ref}
        &amp;gt;
          {Row}
        &amp;lt;/FixedSizeList&amp;gt;
      )}
    &amp;lt;/InfiniteLoader&amp;gt;
  );
};

export default ListComponent;  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;주요 props에 대한 설명은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;height: 뷰포트 높이&lt;/li&gt;
&lt;li&gt;itemSize: 행의 높이&lt;/li&gt;
&lt;li&gt;itemCount: 행의 개수&lt;/li&gt;
&lt;li&gt;overscanCount: 미리 불러올 행의 개수&lt;/li&gt;
&lt;li&gt;Render Prop: 행 내용을 렌더링하는 함수&lt;/li&gt;
&lt;li&gt;loadMoreItems: 행을 추가로 로드할 때 호출되는 콜백&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="tanstackreactvirtual"&gt;@tanstack/react-virtual&lt;/h3&gt;

&lt;pre&gt;&lt;code class="language-tsx"&gt;// https://tanstack.com/virtual/latest/docs/framework/react/examples/table

import * as React from "react";  
import { createRoot } from "react-dom/client";

import { useVirtualizer } from "@tanstack/react-virtual";  
import {  
  flexRender,
  getCoreRowModel,
  getSortedRowModel,
  useReactTable,
} from "@tanstack/react-table";
import { makeData } from "./makeData";  
import type { ColumnDef, Row, SortingState } from "@tanstack/react-table";  
import type { Person } from "./makeData";  
import "./index.css";

function ReactTableVirtualized() {  
  const [sorting, setSorting] = React.useState&amp;lt;SortingState&amp;gt;([]);

  const columns = React.useMemo&amp;lt;Array&amp;lt;ColumnDef&amp;lt;Person&amp;gt;&amp;gt;&amp;gt;(
    () =&amp;gt; [
      {
        accessorKey: "id",
        header: "ID",
        size: 60,
      },
      {
        accessorKey: "firstName",
        cell: (info) =&amp;gt; info.getValue(),
      },
      {
        accessorFn: (row) =&amp;gt; row.lastName,
        id: "lastName",
        cell: (info) =&amp;gt; info.getValue(),
        header: () =&amp;gt; &amp;lt;span&amp;gt;Last Name&amp;lt;/span&amp;gt;,
      },
      {
        accessorKey: "age",
        header: () =&amp;gt; "Age",
        size: 50,
      },
      {
        accessorKey: "visits",
        header: () =&amp;gt; &amp;lt;span&amp;gt;Visits&amp;lt;/span&amp;gt;,
        size: 50,
      },
      {
        accessorKey: "status",
        header: "Status",
      },
      {
        accessorKey: "progress",
        header: "Profile Progress",
        size: 80,
      },
      {
        accessorKey: "createdAt",
        header: "Created At",
        cell: (info) =&amp;gt; info.getValue&amp;lt;Date&amp;gt;().toLocaleString(),
      },
    ],
    []
  );

  const [data, setData] = React.useState(() =&amp;gt; makeData(50_000));

  const table = useReactTable({
    data,
    columns,
    state: {
      sorting,
    },
    onSortingChange: setSorting,
    getCoreRowModel: getCoreRowModel(),
    getSortedRowModel: getSortedRowModel(),
    debugTable: true,
  });

  const { rows } = table.getRowModel();

  const parentRef = React.useRef&amp;lt;HTMLDivElement&amp;gt;(null);

  const virtualizer = useVirtualizer({
    count: rows.length,
    getScrollElement: () =&amp;gt; parentRef.current,
    estimateSize: () =&amp;gt; 34,
    overscan: 20,
  });

  return (
    &amp;lt;div ref={parentRef} className="container"&amp;gt;
      &amp;lt;div style={{ height: `${virtualizer.getTotalSize()}px` }}&amp;gt;
        &amp;lt;table&amp;gt;
          &amp;lt;thead&amp;gt;
            {table.getHeaderGroups().map((headerGroup) =&amp;gt; (
              &amp;lt;tr key={headerGroup.id}&amp;gt;
                {headerGroup.headers.map((header) =&amp;gt; {
                  return (
                    &amp;lt;th
                      key={header.id}
                      colSpan={header.colSpan}
                      style={{ width: header.getSize() }}
                    &amp;gt;
                      {header.isPlaceholder ? null : (
                        &amp;lt;div
                          {...{
                            className: header.column.getCanSort()
                              ? "cursor-pointer select-none"
                              : "",
                            onClick: header.column.getToggleSortingHandler(),
                          }}
                        &amp;gt;
                          {flexRender(
                            header.column.columnDef.header,
                            header.getContext()
                          )}
                          {{
                            asc: " ▲",
                            desc: " ▼",
                          }[header.column.getIsSorted() as string] ?? null}
                        &amp;lt;/div&amp;gt;
                      )}
                    &amp;lt;/th&amp;gt;
                  );
                })}
              &amp;lt;/tr&amp;gt;
            ))}
          &amp;lt;/thead&amp;gt;
          &amp;lt;tbody&amp;gt;
            {virtualizer.getVirtualItems().map((virtualRow, index) =&amp;gt; {
              const row = rows[virtualRow.index];
              return (
                &amp;lt;tr
                  key={row.id}
                  style={{
                    height: `${virtualRow.size}px`,
                    transform: `translateY(${
                      virtualRow.start - index * virtualRow.size
                    }px)`,
                  }}
                &amp;gt;
                  {row.getVisibleCells().map((cell) =&amp;gt; {
                    return (
                      &amp;lt;td key={cell.id}&amp;gt;
                        {flexRender(
                          cell.column.columnDef.cell,
                          cell.getContext()
                        )}
                      &amp;lt;/td&amp;gt;
                    );
                  })}
                &amp;lt;/tr&amp;gt;
              );
            })}
          &amp;lt;/tbody&amp;gt;
        &amp;lt;/table&amp;gt;
      &amp;lt;/div&amp;gt;
    &amp;lt;/div&amp;gt;
  );
}

function App() {  
  return (
    &amp;lt;div&amp;gt;
      &amp;lt;p&amp;gt;
        For tables, the basis for the offset of the translate css function is
        from the row's initial position itself. Because of this, we need to
        calculate the translateY pixel count differently and base it off the
        index.
      &amp;lt;/p&amp;gt;
      &amp;lt;ReactTableVirtualized /&amp;gt;
    &amp;lt;/div&amp;gt;
  );
}

const container = document.getElementById("root");  
const root = createRoot(container!);  
const { StrictMode } = React;

root.render(  
  &amp;lt;StrictMode&amp;gt;
    &amp;lt;App /&amp;gt;
  &amp;lt;/StrictMode&amp;gt;
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;주요 props에 대한 설명은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;뷰포트 높이: 자동 계산됨&lt;/li&gt;
&lt;li&gt;estimateSize: 행의 높이&lt;/li&gt;
&lt;li&gt;count: 행의 개수&lt;/li&gt;
&lt;li&gt;overscan: 미리 불러올 행의 개수&lt;/li&gt;
&lt;li&gt;onScoll: &lt;code&gt;div native&lt;/code&gt; 이벤트&lt;/li&gt;
&lt;/ul&gt;

&lt;p id="props"&gt;각 라이브러리에 사용된 공통 props는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;뷰포트 높이&lt;/li&gt;
&lt;li&gt;행의 높이&lt;/li&gt;
&lt;li&gt;행의 개수&lt;/li&gt;
&lt;li&gt;미리 불러올 행의 개수&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;아래 그림을 살펴보면 공통 props가 필요한 이유를 유추해 볼 수 있습니다. 이 props가 필요한 이유는 이어지는 내용에서 자세히 다루도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/9-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://web.dev/articles/virtualize-long-lists-react-window?hl=ko"&gt;react-window를 사용하여 대규모 목록 가상화&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2 id="ch3"&gt;3. 자체 개발 고성능 표 컴포넌트 Big Table&lt;/h2&gt;

&lt;h3 id=""&gt;개발 배경&lt;/h3&gt;

&lt;p&gt;기존에 react-window를 사용하였지만, 다음과 같은 이유로 고성능 표 컴포넌트인 'Big Table'을 직접 개발하기로 결정했습니다.&lt;/p&gt;

&lt;h4 id="reactwindow"&gt;react-window를 사용하며 발생한 문제점&lt;/h4&gt;

&lt;p&gt;react-window는 &lt;code&gt;div&lt;/code&gt; 기반 레이아웃으로 구현되어 있어 다음과 같은 문제가 있었습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;div&lt;/code&gt;를 절대 좌표로 배치했기 때문에 행에 CSS 스타일을 적용하기 어려움&lt;/li&gt;
&lt;li&gt;동적으로 행 추가/삭제 시 복잡한 좌표 계산 필요&lt;/li&gt;
&lt;li&gt;좌우 스크롤 시 컬럼 헤더의 움직임이 자연스럽지 않음&lt;/li&gt;
&lt;li&gt;&lt;code&gt;colspan&lt;/code&gt;과 같은 표 기능을 사용할 수 없음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/10-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://react-window.vercel.app/#/examples/grid/variable-size"&gt;https://react-window.vercel.app/#/examples/grid/variable-size&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id=""&gt;오픈소스 도입 시의 한계&lt;/h4&gt;

&lt;p&gt;초기에는 @tanstack/react-virtual 오픈소스 라이브러리를 활용하는 방안을 검토했으나, 다음과 같은 이슈가 있었습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;네이버의 로그 시스템에서 제공하는 로그 표현 방식이 접기/펴기, 컨텍스트 검색, 알래스카, 라이브테일 등 다양하고 복잡하여 오픈소스로 대응하기 어렵다고 판단&lt;/li&gt;
&lt;li&gt;스크롤이 페이지의 맨 아래에 도달했을 때 인식에 실패하는 경우가 있는데, 이에 대한 원인 분석에 어려움이 있었음&lt;/li&gt;
&lt;li&gt;문제 발생 시 오픈소스 라이브러리 내부 동작을 파악하는 데 드는 시간과 비용 절약&lt;/li&gt;
&lt;li&gt;커스텀 기능 구현 시 코드 복잡도 증가&lt;/li&gt;
&lt;li&gt;향후 추가될 기획 요구사항에 대응하기 위한 유연성 확보&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="bigtable"&gt;Big Table 컴포넌트 설계 및 구현&lt;/h3&gt;

&lt;p&gt;대용량 데이터를 무한 스크롤 표로 표시하기 위해 다음 2가지 전략을 기반으로 접근했습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;필요한 데이터만 렌더링: 화면에 실제로 표시되는 범위의 데이터만 렌더링한다.&lt;/li&gt;
&lt;li&gt;바닥 감지 후 데이터 새로 적재: 스크롤바가 바닥에 도달하면 데이터를 새로 불러온다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;필요한 데이터만 렌더링&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;key 값을 활용해 불필요한 재렌더링(re-rendering) 방지&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;React는 동일한 타입의 자식 리스트를 업데이트할 때 key 값을 이용합니다. React에서 key는 불필요한 렌더링을 방지하는 중요한 속성입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/11-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;React는 Fiber 트리를 재조정(reconciliation)하는 과정에서 기존 트리와 새로 렌더링하는 트리를 비교합니다. 리스트 형태의 자식 요소에 대해 DOM 요소를 새로 생성할지 아니면 재사용(즉, 속성만 변경)할지는 key 값을 이용하여 판단합니다.&lt;/p&gt;

&lt;p&gt;예를 들어, 다음 그림에서 &lt;code&gt;li&lt;/code&gt; 요소 A, B, C 앞뒤에 새로운 X, Y가 추가되는 경우 key 값을 기준으로 A, B, C는 재사용되고 X, Y는 새로 생성됩니다. 즉, A, B, C DOM 생성 비용을 줄일 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/12-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;2. &lt;strong&gt;렌더링 대상 범위 계산&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;key 값과 함께 알아야 할 필수 정보는 렌더링 대상 범위입니다. 즉, 첫 번째와 마지막 인덱스를 찾아야 하는데요. 이는 '뷰포트 높이, 행의 높이, 행의 개수'를 알고 있다면 계산할 수 있습니다. 앞서 소개한 오픈소스 예제에서 이와 같은 &lt;a href="#props"&gt;공통 props&lt;/a&gt;를 사용한 것도 같은 이유입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/13-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;행의 높이와 전체 행의 개수를 알면 테이블의 전체 높이를 계산할 수 있습니다. 이를 바탕으로 첫 번째 인덱스(First Index)는 ScrollTop보다 큰 첫 번째 행이고, 마지막 인덱스(Last Index)는 'ScrollTop + Viewport + 행의 높이'보다 작은 첫 번째 행이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/14-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;3. &lt;strong&gt;윈도잉(가상화) 적용&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;화면(뷰포트)에 표시되지 않는 행은 상단과 하단 각각 하나의 영역으로 묶어 가상화된 요소로 처리합니다. 이 방식은 실제로 렌더링되는 행의 수를 일정하게 유지하므로, 대용량 데이터도 성능 저하 없이 렌더링할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/15-2.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;앞서 설명한 내용을 실제 코드로 구현한 예제를 살펴보겠습니다.
코드의 중간 부분에서는 화면에 실제로 렌더링되는 행(첫 번째와 마지막 인덱스 범위)이 처리되어 있고, 상단과 하단의 가상 영역은 각각 코드의 앞부분과 마지막 부분에서 하나의 가상 행으로 처리되어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/16-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;4. &lt;strong&gt;깜박임 이슈 발생 및 해결&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;사용자가 빠르게 스크롤할 경우 범위를 계산하고 React에서 이를 렌더링하는 사이 화면 깜박임 현상이 발생할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/17-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이를 방지하기 위해 'Overscan(미리 불러올 행의 개수)'을 통해 화면에 보이는 영역 외에 일정 범위의 행을 미리 렌더링합니다. 즉, 첫 번째 인덱스(First Index)는 'ScrollTop – Overscan'보다 큰 첫 번째 행이고, 마지막 인덱스(Last Index)는 'ScrollTop + Viewport Height + 행의 높이 + Overscan'보다 작은 첫 번째 행이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/18-3.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id=""&gt;바닥 감지 후 데이터 새로 적재: 무한 스크롤 구현 방식&lt;/h4&gt;

&lt;p&gt;무한 스크롤을 구현하는 가장 기본적인 방식은 사용자가 스크롤을 내려 바닥에 도달했을 때 데이터를 추가로 불러오는 것입니다. 이때 ScrollTop과 Viewport Height의 합이 Table Height에 가까워지면, 스크롤이 바닥에 도달했다고 판단할 수 있습니다. 즉, 'Table Height - (ScrollTop + Viewport Height)' 값이 0에 가까워지는 상태입니다.&lt;/p&gt;

&lt;p&gt;그런데 스크롤이 완전히 바닥에 도달한 시점에 데이터를 새로 불러오면 로딩 지연으로 인해 사용자 경험을 저해할 수 있습니다. 따라서 바닥에 도달하기 전에 데이터를 미리 불러오는 방식을 채택했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/19-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이를 위해 Bottom Threshold를 지원하여 이를 기준으로 데이터를 미리 불러올 수 있도록 구현했습니다. Big Table은 'ScrollTop + Viewport Height'와 'Table Height'의 차이가 'Bottom Threshold'보다 작거나 같으면 바닥에 도달했다고 간주하고 데이터를 미리 불러옵니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/20-3.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id=""&gt;컬럼에 대한 가상화&lt;/h4&gt;

&lt;p&gt;컬럼 가상화도 행 가상화와 동일한 방식으로 구현됩니다. 다음 값을 알면 렌더링할 컬럼 범위를 계산할 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;뷰포트 가로 길이&lt;/li&gt;
&lt;li&gt;표 전체 가로 길이&lt;/li&gt;
&lt;li&gt;컬럼의 개수&lt;/li&gt;
&lt;li&gt;각 컬럼의 크기&lt;/li&gt;
&lt;li&gt;Overscan&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/21-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;원본 출처: &lt;a href="https://web.dev/articles/virtualize-long-lists-react-window?hl=ko"&gt;react-window를 사용하여 대규모 목록 가상화&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h4 id=""&gt;고정 헤더, 고정 컬럼 지원&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;고정 헤더 지원&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;고정 헤더는 &lt;code&gt;position: sticky&lt;/code&gt; 속성을 활용해 구현할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/22-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;고정 컬럼 지원&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;고정 컬럼도 &lt;code&gt;position: sticky&lt;/code&gt; 속성을 활용하며, &lt;code&gt;left&lt;/code&gt; 값을 각 컬럼의 너비만큼 누적해서 적용하면 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/23-3.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id=""&gt;행 접기/펴기&lt;/h4&gt;

&lt;p&gt;접기/펴기처럼 행의 높이가 변하는 UI를 구현해야 할 때 기존에는 펼쳐진 행의 높이를 개발자가 직접 계산해서 react-window 컴포넌트의 &lt;code&gt;ref&lt;/code&gt; 객체에 접근한 다음 &lt;code&gt;resetAfterIndices&lt;/code&gt; 높이 업데이트 메서드를 호출해야 했습니다.&lt;/p&gt;

&lt;p&gt;Big Table은 &lt;code&gt;ResizeObserver&lt;/code&gt;를 내장하여 접기/펴기와 같은 상태 변화가 발생했을 때 높이를 자동으로 계산하고 처리하여 개발자의 부담을 줄였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;기존 react-window: 수동 높이 업데이트&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/24-3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Big Table: 자동 높이 감지 처리&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/25-5.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id="bigtable"&gt;Big Table 성능 평가 결과&lt;/h3&gt;

&lt;h4 id=""&gt;컬럼 리사이즈&lt;/h4&gt;

&lt;p&gt;react-window 기반으로 구현된 로그 테이블은 리사이즈 시 프레임 속도가 최저 1 FPS(frames per second)까지 떨어졌지만, Big Table은 55 FPS 이상 안정적으로 유지되는 것을 확인할 수 있었습니다. 이는 react-window가 모든 셀을 &lt;code&gt;position: absolute&lt;/code&gt;를 적용한 &lt;code&gt;div&lt;/code&gt; 요소로 렌더링하기 때문으로 보입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/26-3.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id=""&gt;스크롤&lt;/h4&gt;

&lt;p&gt;react-window 기반과 Big Table에 큰 차이는 없었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/27-3.png" alt="" /&gt;&lt;/p&gt;

&lt;h4 id="30"&gt;30만 건의 데이터 렌더링&lt;/h4&gt;

&lt;p&gt;다음은 Big Table에서 30만 개의 데이터를 렌더링한 화면입니다. 대용량 데이터도 무리 없이 처리되는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/28-3.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;자체 개발의 장점, 한계 및 대안&lt;/h3&gt;

&lt;p&gt;Big Table 자체 개발을 통해 여러 가지 이점을 얻을 수 있었습니다.&lt;/p&gt;

&lt;p&gt;실제 &lt;code&gt;table&lt;/code&gt; 요소를 기반으로 했기 때문에 CSS 스타일을 적용하기 수월했고, 좌우 스크롤 시 컬럼 헤더의 움직임이 자연스러웠고, &lt;code&gt;colspan&lt;/code&gt;과 같은 표 고유 기능을 활용할 수 있었으며, &lt;code&gt;td&lt;/code&gt;만 사용하여 셀 렌더링이 가능했습니다.&lt;/p&gt;

&lt;p&gt;성능 측면에서도 접기/펴기와 같은 다양한 UI 상태 변화에도 평균 55 FPS 이상을 안정적으로 유지했고, 행의 추가/삭제 시에도 별도의 좌표 계산 없이도 매끄럽게 동작했습니다. 무엇보다 변화하는 기획 요구사항에 유연하게 대응할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;하지만 한계도 있었습니다. 아무리 가상화로 렌더링하는 행 수를 줄이더라도, 브라우저에 적재되는 데이터의 양 자체에는 제한이 있었습니다. 무한 스크롤로 많은 데이터를 불러올수록 브라우저 메모리에 부담이 되고 결국 OOM(Out of Memory) 현상이 발생할 수 있습니다. Big Table의 경우 30만 건이 한계였습니다.&lt;/p&gt;

&lt;p&gt;이를 해결하기 위해 몇 가지 방안을 고려해 보았습니다. 첫 번째 방법은 일정한 데이터 이상을 볼러올 경우 IndexDB에 캐시하고 브라우저 메모리를 비우는 방법입니다. 두 번째 방법은 OOM 안전 범위를 테스트하고 페이징을 적용하는 것입니다. 세 번째 방법은 React Query 5.0 버전이 지원하는 &lt;code&gt;maxPage&lt;/code&gt; 옵션을 활용해 캐시된 페이지 수를 일정하게 유지하고 이전 페이지는 필요 시마다 다시 불러오는 방법입니다.&lt;/p&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;p&gt;대용량 표 컴포넌트를 설계하고 구현하는 과정에서 대용량 데이터를 효과적으로 처리하여 렌더링할 수 있는 방법을 고민하고 적용해 보았습니다.&lt;/p&gt;

&lt;p&gt;자체 개발을 통해 기존 오픈소스 라이브러리로는 구현이 어려웠던 문제를 해결할 수 있었으며, 특히 약 30만 건에 달하는 로그 데이터를 무리 없이 렌더링할 수 있었던 점은 유의미한 성과였습니다.&lt;/p&gt;

&lt;p&gt;이 글이 대용량 데이터를 다루는 환경에서 효율적인 데이터 처리와 렌더링 방식을 고민하는 분들께 도움이 되길 바랍니다. 감사합니다.&lt;/p&gt;

&lt;p&gt;관련 발표 영상은 &lt;a href="https://d2.naver.com/helloworld/4706492"&gt;Windowing 기법을 적용한 대용량 고성능 표 컴포넌트 개발기&lt;/a&gt;에서도 살펴보실 수 있습니다.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>레거시 GPU에 날개 달기: 극한의 서빙 최적화 가이드</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/0539348" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/0539348</id>
    <updated>2025-07-24T11:22:22Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/80497668?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;이 세션에서는 BERT기반 모델인 SPLADE모델의 대규모 실시간 서비스를 위한 최적화 방법에 대해서 이야기 합니다.
세상에서 가장 빠른 BertTokenizer 구현체인 FlashTokenizer 의 개발 배경과 성능에 대해 소개합니다.&lt;/p&gt;

&lt;h4 id=""&gt;강의 대상&lt;/h4&gt;

&lt;p&gt;실시간 서빙을 위한 모델 추론 최적화가 필요하신 분들&lt;/p&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;li&gt;Model Simplify&lt;/li&gt;
&lt;li&gt;Inference Optimization(basic)&lt;/li&gt;
&lt;li&gt;Postprocess Optimization&lt;/li&gt;
&lt;li&gt;Preprocess Optimization&lt;/li&gt;
&lt;li&gt;Inference Optimization(advanced)&lt;/li&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Ray를 활용한 GPU Util 100% MLOps: 배치처리부터 모델 서빙까지</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/4348237" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/4348237</id>
    <updated>2025-07-15T11:37:56Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/80335756?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;AI/ML 분산 처리 프레임워크인 Ray를 활용하여 GPU Util 100%를 달성한 배치처리 기법과 확장 가능한 모델 서빙 아키텍처를 소개합니다.&lt;/p&gt;

&lt;h4 id=""&gt;발표 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;배치 파이프라인 설계와 모델 서빙 자동화를 담당하는 분&lt;/li&gt;
&lt;li&gt;Ray 기반 인프라 운영 및 GPU 클러스터 관리 업무를 수행하는 분&lt;/li&gt;
&lt;li&gt;Ray Serve를 활용해 고성능 모델 서빙 API를 설계·배포·운영하는 분&lt;/li&gt;
&lt;li&gt;Ray LLM(vLLM) 기반 LLM 추론 파이프라인을 구성·확장하고, 내부 모델 레지스트리를 연동하는 분&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Introduction to Ray &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;Ray에 대한 소개 및 Core Architecture에 대한 이해&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Ray Data: GPU Util 100% Bach Inference를 위한 수난기 &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;기존 구조와 도입된 구조 비교&lt;/li&gt;
&lt;li&gt;TroubleShooting 4건&lt;/li&gt;
&lt;li&gt;PipelineStep 추상 클래스 소개&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Ray Serve: 배치 + 서빙, 두 마리 토끼를 잡다 &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;Offline Serving UseCase&lt;/li&gt;
&lt;li&gt;GPU 자원 효율성 실험&lt;/li&gt;
&lt;li&gt;ModelInference, BaseDeployment 인터페이스 소개&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Ray LLM: ServeManager를 활용한 LLM 배포 (with vLLM) &lt;br /&gt;
&lt;ul&gt;&lt;li&gt;ServeManager 구조 소개&lt;/li&gt;
&lt;li&gt;TroubleShooting 4건&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Kubernetes GPU 클러스터에서 AI 서비스 오토스케일링하기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/0251755" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/0251755</id>
    <updated>2025-07-11T11:43:24Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/80099083?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;대규모 쿠버네티스 GPU 클러스터에서 자체 HPA 시스템 구축을 통해 글로벌 유저 트래픽에 동적으로 대응하는 AI 서비스 오토스케일링을 적용한 사례를 소개합니다.&lt;/p&gt;

&lt;h4 id=""&gt;발표 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;AI 서비스 운영을 위해 GPU 서버 기반의 Kubernetes 클러스터 도입을 고려하는 엔지니어&lt;/li&gt;
&lt;li&gt;AI 서비스 오토스케일링을 Kubernetes 에서 도입하고자 하는 엔지니어&lt;/li&gt;
&lt;li&gt;기본 HPA 보다 고도화된 방법으로 오토스케일링을 도입하고자 하는 엔지니어&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;왜 SNOW는 GPU orchestration이 필요한가&lt;/li&gt;
&lt;li&gt;GPU 기반 서비스의 오토스케일링이 어려운 이유&lt;/li&gt;
&lt;li&gt;KEDA: Event-Driven Autoscaler&lt;/li&gt;
&lt;li&gt;SNOW의 GPU Orchestration 시스템&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Spring Cloud Config HA 적용을 위한 커스터마이징</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/6269411" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/6269411</id>
    <updated>2025-07-11T11:41:56Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/79961631?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Spring Cloud Config을 도입 및 커스텀하여 서비스 안정성을 높힌 방법을 소개합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;발표 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;배포없이 프로퍼티 동적 변경에 관심있으신 분들&lt;/li&gt;
&lt;li&gt;spring cloud config으로 프로퍼티 동적 변경을 적용하고 싶으나, SPOF 이슈로 꺼려했던 분들&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Spring Cloud Config 소개 
&lt;ul&gt;&lt;li&gt;Spring Cloud Config 란?
&lt;ul&gt;&lt;li&gt;Spring Cloud Config Server&lt;/li&gt;
&lt;li&gt;Spring Cloud Config Client&lt;/li&gt;
&lt;li&gt;Spring Cloud Config Context&lt;/li&gt;
&lt;li&gt;Spring Cloud Config 정리&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Spring Cloud Config 활용&lt;/li&gt;
&lt;li&gt;Spring Cloud Config 커스텀 
&lt;ul&gt;&lt;li&gt;Mysql 저장소 사용&lt;/li&gt;
&lt;li&gt;Kafka 이중화 적용&lt;/li&gt;
&lt;li&gt;Service API 특정 빈만 리프레시&lt;/li&gt;
&lt;li&gt;Service API eagerLoading 적용&lt;/li&gt;
&lt;li&gt;최종 구조&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Spring Cloud Config 동작 예시 
&lt;ul&gt;&lt;li&gt;기능 테스트 
&lt;ul&gt;&lt;li&gt;프로퍼티 값 변경&lt;/li&gt;
&lt;li&gt;eagerLoading 동작&lt;/li&gt;
&lt;li&gt;특정 빈만 리프레시&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;DR 테스트 
&lt;ul&gt;&lt;li&gt;cloud config server 장애&lt;/li&gt;
&lt;li&gt;kafka cluster 장애&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;한계 및 개선 사항&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Docusaurus를 이용한 API 문서 플랫폼의 진화</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/6196427" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/6196427</id>
    <updated>2025-07-07T11:34:40Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/79813814?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Docusaurus와 Typesense를 통해 기존 Redoc 기반 커머스API 문서 사이트를  변경하면서 정리한 Docusaurus 채택 배경과 특징, Typesense 특징 및 인프라 구성, 그리고 배포프로세스 등을 설명합니다. 마지막으로 이러한 변경을 통해 정성적 정량적인 유의미한 결과를 소개하며  개발하면서 겪은 긍정적인 경험 및 남은 과제 등을 공유합니다. &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;발표 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;API 혹은 다른 문서 사이트를 멋지게 커스터마이즈해서 빌드 배포하고 싶은 분들&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;커머스API와 커머스API문서 소개  &lt;/li&gt;
&lt;li&gt;기존 문서 플랫폼의 한계점 &lt;br /&gt;
&lt;ol&gt;&lt;li&gt;Redoc 기반 플랫폼의 특징과 이해&lt;/li&gt;
&lt;li&gt;UX 및 사용성 이슈, 커스터마이징의 어려움&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Docusaurus 채택 배경 &lt;br /&gt;
&lt;ol&gt;&lt;li&gt;오픈소스 선정 배경 및 해외 사례 조사&lt;/li&gt;
&lt;li&gt;Docusaurus와 docusaurus-openapi-docs의 구조와 관계&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Docusaurus 커스터마이징 - swizzle을 중심으로 &lt;br /&gt;
&lt;ol&gt;&lt;li&gt;Docusaurus swizzling에 대한 이해&lt;/li&gt;
&lt;li&gt;커스터마이징 요구사항과 구현&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Typesense로 검색 시스템 구축 &lt;br /&gt;
&lt;ol&gt;&lt;li&gt;Typesense 도입 배경 및 특징&lt;/li&gt;
&lt;li&gt;검색 시스템 구성&lt;/li&gt;
&lt;li&gt;커머스API 문서 크롤링&lt;/li&gt;
&lt;li&gt;커머스API 문서 버전 별 검색 정책&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;문서 배포 프로세스 구축 &lt;br /&gt;
&lt;ol&gt;&lt;li&gt;Nubes를 이용한 정적 자원 배포 전략&lt;/li&gt;
&lt;li&gt;Docusaurus 빌드 및 크롤링 수행 환경 구성&lt;/li&gt;
&lt;li&gt;최종 문서 배포 흐름&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;결과 비교 및 사용자 경험 &lt;br /&gt;
&lt;ol&gt;&lt;li&gt;결과 비교(ui, 다크모드, 검색)&lt;/li&gt;
&lt;li&gt;웹페이지 성능 비교&lt;/li&gt;
&lt;li&gt;사용자 경험 변화&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;마치며 &lt;br /&gt;
&lt;ol&gt;&lt;li&gt;긍정적인 경험&lt;/li&gt;
&lt;li&gt;앞으로 남은 과제&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>FE News 25년 7월 소식을 전해드립니다!</title>
    <link rel="alternate" href="https://d2.naver.com/news/8825314" />
    <category term="news" />
    <id>https://d2.naver.com/news/8825314</id>
    <updated>2025-07-04T18:27:49Z</updated>
    <content type="html">&lt;p&gt;&lt;img src=https://d2.naver.com/content/images/2023/07/-----------2023-07-06------4-16-49.png&gt;&lt;/p&gt;

&lt;h2 id=""&gt;주요소식&lt;/h2&gt;

&lt;p&gt;&lt;img src="/content/images/2025/07/-----------2025-07-03------3-36-34.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;25년 7월 소식에서는 다음과 같은 유용한 정보들을 만나보실 수 있습니다.&lt;/p&gt;

&lt;h4 id=""&gt;링크 &amp;amp; 읽을거리&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Goodbye UseState&lt;/strong&gt;: XState의 창시자 David Khourshid가 useState 사용을 피하는것이 좋은 케이스를 소개합니다. 3년전의 Goodbye UseEffect를 잇는 시리즈 발표입니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Search Params Are State, Beware The URL Type-Safety Iceberg&lt;/strong&gt;: search params를 state로 활용하는것에서 오는 문제들에 대한 글들입니다. react-query로 유명한 tanstack과 nuqs 라이브러리 author들의 다양한 시각을 소개합니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The State of React and the Community in 2025&lt;/strong&gt;: 현재의 React 생태계와 커뮤니티에 대한 분석글입니다. Meta와 Vercel 간의 관계가 React 생태계에 미치는 영향과 개발자들이 앞으로 고려해야 할 사항들을 심도 있게 분석합니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ecma International approves ECMAScript 2025&lt;/strong&gt;: What's new?: 6월 25일 Ecma International 총회에서 ECMAScript 2025 언어 사양이 공식적으로 승인되었습니다. 여러 스펙들이 있지만 그중에서도 Iterator 관련 스펙은 눈여겨 볼만합니다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;튜토리얼&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;No Server, No Database: Smarter Related Posts in Astro with transformers.js&lt;/strong&gt;: 서버나 DB없이 관련 포스트(추천 포스트)를 구현하는 방법에 대한 가이드입니다. Static하게 Serving하는 블로그를 운영하고 있다면 따라해보기를 추천드립니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reactivity is easy&lt;/strong&gt;: React에서 세밀한 반응성(fine-grained reactivity)을 구현하는 방법을 설명하는 튜토리얼입니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;초보자를 위한 Model Context Protocol (MCP) 커리큘럼&lt;/strong&gt;: 마이크로소프트에서 제공하는 Model Context Protocol(MCP) 한국어 학습 자료입니다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;코드와 도구&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;i18n-check&lt;/strong&gt;: React, Next.js 앱에서 잘못된 키, 누락된 키, 사용되지 안않는 키 등을 검출해줍니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Lingo.dev&lt;/strong&gt;: Lingo.dev 컴파일러는 어떤 React 앱이더라도 빌드 시점에 다중 언어를 지원할 수 있도록 만들어 주는 미들웨어로, 기존 React 컴포넌트를 수정할 필요가 전혀 없습니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;AI Version Control&lt;/strong&gt;: YOYO: YOYO는 Vibe Coding을 위한 형성관리 도구입니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;liquid-glass&lt;/strong&gt;: 애플이 WWDC25 행사를 통해 공개한 liquid glass 디자인을 적용할 수 있는 react 컴포넌트입니다. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="fenews257httpsgithubcomnaverfenewsblobmasterissues202507md"&gt;&lt;a href="https://github.com/naver/fe-news/blob/master/issues/2025-07.md"&gt;&gt;&gt; FE News 25년 7월 소식 보러가기&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;br/&gt;  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;◎ FE News란?&lt;/strong&gt;&lt;br/&gt;
  네이버 FE 엔지니어들이 엄선한 양질의 FE 및 주요한 기술 소식들을 큐레이션해 공유하는 것을 목표로 하며, 이를 통해 국내 개발자들에게 지식 공유에 대한 가치 인식과 성장에 도움을 주고자 하는 기술소식 공유 프로젝트 입니다.&lt;/p&gt;
  
  &lt;p&gt;매월 첫째 주 수요일, 월 1회 발행 되고 있으니 많은 관심 부탁드립니다.&lt;br/&gt;
  &lt;a href="https://fenews.substack.com/embed"&gt;▷ 구독하기&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Windowing 기법을 적용한 대용량 고성능 표 컴포넌트 개발기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/4706492" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/4706492</id>
    <updated>2025-07-04T13:46:56Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/79636311?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;웹브라우저에서 대용량 데이터를 높은 성능으로 표현할 수 있는 Windowing 기법에 관해 소개하고 적용 사례를 공유합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;발표 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Windowing 기법에 관심이 있는 개발자&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Windowing 기법이란
&lt;ul&gt;&lt;li&gt;데이터 스트리밍 / 시계열 처리에서의 Windowing&lt;/li&gt;
&lt;li&gt;머신러닝에서의 Windowing&lt;/li&gt;
&lt;li&gt;컴퓨터 그래픽스에서의 Windowing&lt;/li&gt;
&lt;li&gt;React에서의 Windowing / Virtualization 기술&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Windowing 기법을 활용한 오픈소스 라이브러리들
&lt;ul&gt;&lt;li&gt;Windowing기법을 사용하는 오픈소스 라이브러리 비교&lt;/li&gt;
&lt;li&gt;react-virtualized&lt;/li&gt;
&lt;li&gt;react-window&lt;/li&gt;
&lt;li&gt;@tanstack/react-virtual&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;대용량 고성능 표 컴포넌트 Big Table 개발 배경
&lt;ul&gt;&lt;li&gt;Table이 아니기 때문에 발생하는 어려움들&lt;/li&gt;
&lt;li&gt;오픈소스 이슈의 원인 파악의 어려움&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Big Table 컴포넌트의 주요 Windowing 기법
&lt;ul&gt;&lt;li&gt;대용량 데이터를 무한 스크롤 표로 나타내려면 어떻게 해야 할까?&lt;/li&gt;
&lt;li&gt;“Key”를 활용해서 불필요한 Re-rendering을 방지&lt;/li&gt;
&lt;li&gt;주어진 영역에 보여줄 데이터 범위를 구하기&lt;/li&gt;
&lt;li&gt;Windowing (Virtualization) 적용&lt;/li&gt;
&lt;li&gt;Overscan을 통해 미리 그려 놓기&lt;/li&gt;
&lt;li&gt;Bottom Threshold 통해 미리 Fetch하기&lt;/li&gt;
&lt;li&gt;컬럼에 대한 가상화&lt;/li&gt;
&lt;li&gt;고정 헤더/컬럼 지원&lt;/li&gt;
&lt;li&gt;행 접고/펴기&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;성능 / 장점 / 한계
&lt;ul&gt;&lt;li&gt;성능
&lt;ul&gt;&lt;li&gt;Resize&lt;/li&gt;
&lt;li&gt;Scroll&lt;/li&gt;
&lt;li&gt;접고/펴기&lt;/li&gt;
&lt;li&gt;펴고 스크롤&lt;/li&gt;
&lt;li&gt;30만건 데이터 로드&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;자체 개발로 얻은 장점&lt;/li&gt;
&lt;li&gt;한계와 대안&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>AI가 지켜보는 데이터 파이프라인: 노이즈 제거부터 장애 대응까지</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/5251464" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/5251464</id>
    <updated>2025-07-02T11:02:06Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/79492360?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;이 세션에서는 서비스를 운영하는 운영 담당자들이 AI를 활용하여, 운영 피로도를 낮추면서 운영 품질을 향상시키기 위한 방법을 소개합니다.
너무 많은 알림을 받고 있으나, 실제로 장애로 연결되지 않는 Noise 알림때문에 운영 리소스가 낭비되고 있는 상황을 개선하는 방법을 소개합니다. 항상 똑같은 대응을 반복하는 (로그 분석, 원인파악, 장애공유, 대응책 수립, 복구 수행) 운영담당자분들이 AI를 활용해서 더 빠르고 신속하게 장애를 대응할 수 있도록 합니다.&lt;/p&gt;

&lt;h4 id=""&gt;발표 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;데이터 파이프라인을 개발 및 운영하는 운영 담당자분들&lt;/li&gt;
&lt;li&gt;AI를 서비스 운영에 활용하는데 관심이 있는분들&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Intro  &lt;/li&gt;
&lt;li&gt;도입 배경  &lt;/li&gt;
&lt;li&gt;AI를 활용한 장애처리 자동화  &lt;/li&gt;
&lt;li&gt;로그 데이터 전처리  &lt;/li&gt;
&lt;li&gt;Noise 분류 모델  &lt;/li&gt;
&lt;li&gt;AI Assistant  &lt;/li&gt;
&lt;li&gt;적용 사례 공유 및 Future Work&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Thread-safety in C++</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/3078195" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/3078195</id>
    <updated>2025-06-30T13:01:51Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; 
&lt;a href="https://d2.naver.com/helloworld/2774577"&gt;C++에서 안정적인 멀티 스레드 코드를 위한 스레드 안전성 개념 정리&lt;/a&gt; 에서도 살펴보실 수 있습니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/79362382?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;C++ 에서 thread safe 한 프로그램을 만들기 위해 알아야 할 기본 개념인 data race 와 basic thread safety, 연산 간 순서 관계에 대해 설명합니다.&lt;/p&gt;

&lt;h4 id=""&gt;발표 대상&lt;/h4&gt;

&lt;p&gt;동시성 프로그래밍 업무를 수행하는 C++ 개발자&lt;/p&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Data race
&lt;ul&gt;&lt;li&gt;Data race&lt;/li&gt;
&lt;li&gt;연산 간의 선후 관계(Sequenced-before)&lt;/li&gt;
&lt;li&gt;연산 간의 선후 관계(Synchronizes-with)&lt;/li&gt;
&lt;li&gt;연산 간의 선후 관계(happens-before)&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Basic thread safety
&lt;ul&gt;&lt;li&gt;Basic thread safety&lt;/li&gt;
&lt;li&gt;Standard library 의 thread safety&lt;/li&gt;
&lt;li&gt;std::shared_ptr T 의 basic thread safety&lt;/li&gt;
&lt;li&gt;Basic thread safety 보장하지 않는 타입의 예&lt;/li&gt;
&lt;li&gt;Basic thread safety 를 왜 보장해 줘야 하나?&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;External synchronization
&lt;ul&gt;&lt;li&gt;External sychronization&lt;/li&gt;
&lt;li&gt;External sychronization w/ std::mutex&lt;/li&gt;
&lt;li&gt;External sychronization w/ std::atomic&lt;/li&gt;
&lt;li&gt;Synchronizes-with 관계를 제공하는 함수들&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Internally synchronized types
&lt;ul&gt;&lt;li&gt;Internally synchronized types&lt;/li&gt;
&lt;li&gt;Internally synchronized type 만들기 시도&lt;/li&gt;
&lt;li&gt;Synchronization primitives&lt;/li&gt;
&lt;li&gt;Synchronization primitive 사용한 internally synchronized type&lt;/li&gt;
&lt;li&gt;std::atomic 으로 구현하는 mutex&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>C++에서 안정적인 멀티 스레드 코드를 위한 스레드 안전성 개념 정리</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/2774577" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/2774577</id>
    <updated>2025-06-30T13:02:32Z</updated>
    <content type="html">&lt;p&gt;C++ 개발자는 멀티 스레드 환경에서 mutex나 atomic 같은 동기화 도구를 익숙하게 사용합니다. 하지만 이런 도구를 잘 활용해도 동시성 문제가 발생할 수 있으며 이 경우 디버깅에 많은 시간과 노력이 필요합니다.&lt;/p&gt;

&lt;p&gt;데이터 레이스(data race)의 개념을 정확히 이해하면 동기화 도구가 어떤 문제를 해결하는지 어떤 상황에서 계속 데이터 레이스가 발생하는지 알 수 있습니다. 이 글에서는 C++의 동시성(concurrency) 문제와 이를 방지하기 위한 스레드 안전성의 주요 개념을 관련 이론 및 사례와 함께 공유합니다. 안정적인 멀티 스레드 코드 작성에 도움이 되기를 바랍니다.&lt;/p&gt;

&lt;p&gt;관련 발표 영상은 &lt;a href="https://d2.naver.com/helloworld/3078195"&gt;Thread-safety in C++&lt;/a&gt;에서 이어보실 수 있습니다.&lt;/p&gt;

&lt;h2 id=""&gt;데이터 레이스&lt;/h2&gt;

&lt;p&gt;멀티 스레드 환경에서는 서로 다른 스레드가 동시에 같은 데이터에 접근하는데, 이때 접근 방식이 적절하지 않으면 데이터 레이스가 발생할 수 있습니다. 데이터 레이스는 다음 조건을 모두 충족할 때 발생합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;두 개 이상의 스레드가 하나의 메모리 위치(memory location)에 동시에 접근&lt;/li&gt;
&lt;li&gt;하나 이상이 쓰기 연산을 수행&lt;/li&gt;
&lt;li&gt;하나 이상이 atomic 연산이 아님&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서 '메모리 위치'는 int나 bool 같은 기본 타입(primitive type)의 하나로 이해하면 됩니다.(&lt;a href="https://en.cppreference.com/w/cpp/language/memory_model"&gt;표준&lt;/a&gt;에서는 더 엄밀하게 정의하고 있습니다.) '동시에 접근'은 단순히 시간이 겹친다는 의미가 아니라 C++ 메모리 모델에서 연산 간 선후 관계(happens-before)가 정의되지 않았다는 의미입니다.&lt;/p&gt;

&lt;p&gt;C++에서는 데이터 레이스가 발생하면 이를 미정의 행동(undefined behavior)으로 간주합니다. 미정의 행동은 어떤 결과가 나올지 예측할 수 없으며, 코드가 정상 작동할 수도 있고 심각한 오류가 발생할 수도 있으므로 절대로 발생하지 않아야 합니다.&lt;/p&gt;

&lt;h3 id=""&gt;연산 간 선후 관계&lt;/h3&gt;

&lt;h4 id="sequencedbefore"&gt;순차 실행 관계(sequenced-before)&lt;/h4&gt;

&lt;p&gt;C++에서는 같은 스레드 안에서 실행되는 두 연산 사이에 명확한 순서가 존재하면 이 관계를 순차 실행 관계라고 부릅니다. 이 관계는 연산 간 선후 관계의 전제 조건입니다.&lt;/p&gt;

&lt;p&gt;다음 코드를 보겠습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;a = 1;  
b = a;  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;여기서 &lt;code&gt;a = 1&lt;/code&gt; 연산이 먼저 실행되고, 그 다음 줄(&lt;code&gt;b = a&lt;/code&gt;)에서 값을 읽습니다. 이 두 연산은 순차 실행 관계에 있습니다. &lt;code&gt;a = 1&lt;/code&gt;이 반드시 먼저 실행되고, 그 다음에 &lt;code&gt;b = a&lt;/code&gt;가 실행된다는 것이 언어 차원에서 보장됩니다.&lt;/p&gt;

&lt;h4 id="indeterminatelysequenced"&gt;비결정적인 순서(indeterminately-sequenced)&lt;/h4&gt;

&lt;p&gt;코드에 적힌 순서대로 실행이 보장되지 않는 경우도 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;f(a = 1, b = a);  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이런 표현식에서는 &lt;code&gt;a = 1&lt;/code&gt;이 먼저 실행될지 &lt;code&gt;b = a&lt;/code&gt;가 먼저 실행될지 정해져 있지 않습니다. 이런 경우에 순서가 비결정적이라고 합니다. 순서는 있지만 어떤 것이 먼저인지는 알 수 없습니다.&lt;/p&gt;

&lt;h4 id="unsequenced"&gt;순서 보장 없음(unsequenced)&lt;/h4&gt;

&lt;p&gt;다음과 같은 경우도 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;(a = 1) + (b = a);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 경우 두 연산 사이에 순서를 보장하지 않습니다. 실제로 동시에 실행될 수도 있고 컴파일러가 임의로 순서를 정할 수도 있습니다. 이는 데이터 레이스로 분류되지는 않지만 미정의 행동입니다.&lt;/p&gt;

&lt;h4 id=""&gt;멀티 스레드 안전성과의 관계&lt;/h4&gt;

&lt;p&gt;이런 순서 보장은 멀티 스레드 환경에서 안전성을 확보하기 위한 기초 개념입니다. 같은 스레드 내에서는 순차 실행 관계가 있어야만 그 순서가 연산 간 선후 관계로 이어질 수 있습니다. 코드에 순서가 있다고 해도 그것이 명확한 순차 실행 관계가 아니면, 여러 스레드 실행 시 순서를 정하는 데 문제가 될 수 있습니다.&lt;/p&gt;

&lt;h3 id="synchronizedwith"&gt;스레드 간 동기화 관계(synchronized-with)&lt;/h3&gt;

&lt;p&gt;같은 스레드 내에서는 코드 상의 순서대로 실행되는 연산 간에 순차 실행 관계가 있습니다. 서로 다른 스레드 간에도 특정한 조건이 만족되면 동기화 관계(synchronizes-with)가 성립하고, 이것이 순차 실행 관계와 합쳐져서 연산 간 선후 관계로 확장될 수 있습니다.&lt;/p&gt;

&lt;p&gt;동기화 관계는 C++ 표준에서 특정한 라이브러리 호출 쌍에서 명시적으로 정의합니다. atomic이 대표적인 예입니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;한 스레드에서 std::atomic 변수에 대해 &lt;code&gt;store(value, memory_order::release)&lt;/code&gt;를 수행&lt;/li&gt;
&lt;li&gt;다른 스레드에서 같은 변수에 대해 &lt;code&gt;load(memory_order::acquire)&lt;/code&gt;를 수행하여 해당 값을 읽음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 두 연산 사이에는 동기화 관계가 형성됩니다.&lt;/p&gt;

&lt;p&gt;동기화 관계가 생기면, 각 스레드 내의 순차 실행 관계를 이어 붙여서, 결국 하나의 스레드에서 먼저 일어난 일이 다른 스레드에서 나중에 일어난 것처럼 순서를 보장합니다. 이것이 바로 연산 간 선후 관계입니다.&lt;/p&gt;

&lt;p&gt;동기화 관계는 atomic 연산에만 국한되지 않습니다. 예를 들어 한 스레드가 &lt;code&gt;mutex.unlock()&lt;/code&gt;을 호출하고, 다른 스레드가 같은 mutex에 대해 &lt;code&gt;mutex.lock()&lt;/code&gt;을 성공적으로 수행하면 이 두 연산 사이에도 동기화 관계가 성립합니다.&lt;/p&gt;

&lt;p&gt;연산 간 선후 관계는 멀티 스레드 환경에서 안전한 실행 순서를 정의하기 위한 핵심 메커니즘입니다. 이 관계를 통해 어떤 연산의 결과가 다른 스레드에 반영되는 것을 보장할 수 있고 데이터 레이스를 막을 수 있습니다. 멀티 스레드 프로그래밍에서는 동기화 관계를 어떻게 만들고 연결하느냐가 매우 중요합니다.&lt;/p&gt;

&lt;h3 id=""&gt;연산 간 선후 관계의 시각적 이해&lt;/h3&gt;

&lt;p&gt;연산 간 선후 관계가 어떤 원리로 형성되는지 시각적으로 정리해보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/1-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;두 개의 스레드가 나란히 표시되어 있고, 각 스레드 내에서의 연산은 위에서 아래로 흐른다고 가정합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Thread 1의 연산들은 순차 실행 관계&lt;/li&gt;
&lt;li&gt;atomic-store-release와 atomic-load-acquire는 동기화 관계&lt;/li&gt;
&lt;li&gt;Thread 2의 연산들은 순차 실행 관계&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 모든 관계가 이어져서 Thread 1 처음의 'A에 3을 쓰기'와 Thread 2 마지막의 'A에서 3을 읽기' 간에 연산 간 선후 관계가 완성됩니다.&lt;/p&gt;

&lt;p&gt;이것이 C++에서 여러 스레드에서 접근하는 동일 메모리 위치에 대한 연산 간 순서를 정하는 방식입니다. 이런 순서 관계가 명확히 성립하지 않으면, 값이 제대로 전달되지 않거나 동기화가 되지 않아서 데이터 레이스, 즉 미정의 행동이 발생할 수 있습니다.&lt;/p&gt;

&lt;h3 id=""&gt;퀴즈: 다음 연산은 데이터 레이스일까?&lt;/h3&gt;

&lt;p&gt;기본 타입에 대한 다음 연산이 데이터 레이스인지 살펴보겠습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;같은 변수에 대한 읽기와 읽기 → 데이터 레이스 아님&lt;/li&gt;
&lt;li&gt;다른 변수에 대한 쓰기와 읽기 → 데이터 레이스 아님&lt;/li&gt;
&lt;li&gt;다른 변수에 대한 쓰기와 쓰기 → 데이터 레이스 아님&lt;/li&gt;
&lt;li&gt;같은 변수에 대한 연산 간 선후 관계에 있는 쓰기와 읽기 → 데이터 레이스 아님&lt;/li&gt;
&lt;li&gt;같은 변수에 대한 연산 간 선후 관계에 있는 쓰기와 쓰기 → 데이터 레이스 아님&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이는 앞에서 설명한 데이터 레이스의 조건에서, 동시에 발생하는 두 메모리 접근 중 적어도 하나가 쓰기여야 하고, 둘 사이에 연산 간 선후 관계가 없어야 한다는 조건을 만족하지 않기 때문입니다.&lt;/p&gt;

&lt;h2 id="basicthreadsafety"&gt;기본 스레드 안전성(basic thread safety)&lt;/h2&gt;

&lt;p&gt;지금까지 이야기한 데이터 레이스의 정의는 주로 int, bool 같은 기본 타입에 국한된 이야기였습니다. 하지만 실제로 우리가 작성하거나 사용하는 코드는 대부분 클래스나 구조체 같은 사용자 정의 타입을 훨씬 많이 사용합니다.&lt;/p&gt;

&lt;p&gt;사용자 정의 타입의 스레드 안전성은 어떻게 판단해야 할까요? 기본 스레드 안전성은 기본 타입에서의 데이터 레이스 방지 조건을 사용자 정의 타입에도 확장해서 적용할 수 있도록 정리한 원칙으로, 다음과 같은 다섯 가지 상황에서 데이터 레이스가 발생하지 않아야 한다는 조건으로 정의할 수 있습니다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;같은 변수에 대한 읽기와 읽기  &lt;/li&gt;
&lt;li&gt;다른 변수에 대한 쓰기와 읽기  &lt;/li&gt;
&lt;li&gt;다른 변수에 대한 쓰기와 쓰기  &lt;/li&gt;
&lt;li&gt;같은 변수에 대한 연산 간 선후 관계에 있는 쓰기와 읽기  &lt;/li&gt;
&lt;li&gt;같은 변수에 대한 연산 간 선후 관계에 있는 쓰기와 쓰기&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위 5가지 조건 중 4번과 5번은 자동으로 성립하는 조건입니다. 타입을 어떻게 정의하든 C++ 메모리 모델이 이미 순서를 보장해 주기 때문입니다. 따라서 우리가 실제로 신경 써야 할 부분은 앞의 1, 2, 3번 조건입니다. 타입이 이 세 가지를 만족하면 기본 스레드 안전성을 보장한다고 말합니다.&lt;/p&gt;

&lt;p&gt;여기서 말하는 읽기와 쓰기는 단순히 멤버 변수에 직접 접근하는 것만을 뜻하지 않습니다. 일반적으로 const 멤버 함수를 통해 멤버 함수를 호출하는 경우는 읽기, non-const 멤버 함수를 통한 호출은 쓰기로 간주됩니다.&lt;/p&gt;

&lt;h3 id=""&gt;표준 라이브러리의 기본 스레드 안전성&lt;/h3&gt;

&lt;p&gt;사용자 정의 타입에서 기본 스레드 안전성의 개념을 살펴봤다면, 이제 표준 라이브러리 타입은 어떤지 확인해보겠습니다.&lt;/p&gt;

&lt;p&gt;결론부터 말하면, 기본 타입과 표준 라이브러리의 모든 타입은 기본 스레드 안전성을 보장합니다.&lt;/p&gt;

&lt;p&gt;다만, 컨테이너 타입의 경우 한 가지 조건이 있습니다. 표준 라이브러리 타입이 다른 타입 T를 포함하는 컨테이너라면, 그 T 역시 기본 스레드 안전성을 만족해야 전체 컨테이너가 안전해집니다. 이것이 사용자 정의 타입에서도 기본 스레드 안전성을 고려해야 하는 중요한 이유입니다.&lt;/p&gt;

&lt;p&gt;몇 가지 구체적인 예를 통해 살펴보겠습니다:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;std::vector&amp;lt;int&amp;gt;&lt;/code&gt;는 기본 스레드 안전성을 보장합니다.  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;std::optional&amp;lt;float&amp;gt;&lt;/code&gt;은 기본 스레드 안전성을 보장합니다.  &lt;/li&gt;
&lt;li&gt;T가 기본 스레드 안전성을 보장하면 &lt;code&gt;std::map&amp;lt;std::string, T&amp;gt;&lt;/code&gt;는 기본 스레드 안전성을 보장합니다.  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;std::shared_ptr&amp;lt;T&amp;gt;&lt;/code&gt;는 기본 스레드 안전성을 보장합니다(shared_ptr은 T가 아니라 T*를 포함한다고 이해해야 함).  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;std::vector&amp;lt;std::shared_ptr&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt;는 기본 스레드 안전성을 보장합니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;std::vector&amp;lt;int&amp;gt;&lt;/code&gt;나 &lt;code&gt;std::optional&amp;lt;float&amp;gt;&lt;/code&gt; 같은 경우, 내부 타입이 기본 타입이므로 문제없이 기본 스레드 안전성을 보장합니다(1, 2번). &lt;code&gt;std::map&amp;lt;std::string, T&amp;gt;&lt;/code&gt;의 경우에는 T가 기본 스레드 안전성을 만족해야만 전체 map이 안전합니다(3번). &lt;code&gt;std::shared_ptr&amp;lt;T&amp;gt;&lt;/code&gt;는 특별한 케이스입니다. shared_ptr은 내부에서 T에 대한 포인터를 관리하는 구조이므로, T 자체의 스레드 안전성과는 무관하게 shared_ptr 객체 자체는 기본 스레드 안전성을 보장합니다(4번). 따라서, &lt;code&gt;std::vector&amp;lt;std::shared_ptr&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt;처럼 shared_ptr을 담은 컨테이너도 안전하게 사용할 수 있습니다(5번).&lt;/p&gt;

&lt;h3 id="stdshared_ptrt"&gt;&lt;code&gt;std::shared_ptr&amp;lt;T&amp;gt;&lt;/code&gt;의 기본 스레드 안전성&lt;/h3&gt;

&lt;p&gt;C++ 표준 라이브러리 문서를 읽을 때 기본 스레드 안전성 관점으로 해석하면 더 명확하게 이해할 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;All member functions (including copy constructor and copy assignment) can be called by multiple threads on different shared_ptr objects without additional synchronization even if these objects are copies and share ownership of the same object.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;서로 다른 shared_ptr 객체에 대해, 모든 멤버 함수(복사 생성자와 복사 대입 연산자 포함)는 여러 스레드가 동시 호출해도 추가 동기화 없이 안전하게 사용할 수 있습니다. 이때 해당 shared_ptr 객체들이 동일한 자원을 공유하는 복사본이라도 마찬가지입니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If multiple threads of execution access the same shared_ptr object without synchronization and any of those accesses uses a non-const member function of shared_ptr then a data race will occur.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여러 스레드가 동일한 shared_ptr 객체에 동기화 없이 접근하고 그 중 하나라도 shared_ptr의 non-const 멤버 함수를 사용한다면 데이터 레이스가 발생합니다.&lt;/p&gt;

&lt;p&gt;cppreference.com 에서는 shared_ptr의 동기화 보장에 대해 다음과 같이 설명하고 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;서로 다른 shared_ptr 객체는 동기화 없이 동시에 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;동일한 shared_ptr 객체를 여러 스레드에서 동시에 수정하는 것은 데이터 레이스이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 두 가지 설명이 왜 함께 언급되는지 처음에는 이해하기 어려울 수 있습니다. 하지만 기본 스레드 안전성 조건을 떠올려보면 그 맥락을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;첫 번째 조건부터 살펴보겠습니다. 서로 다른 shared_ptr 객체라면 이는 서로 다른 변수이므로, 서로 다른 객체에 대한 읽기/쓰기 상황에 해당합니다. 이는 기본 스레드 안전성 조건에서 안전한 연산입니다. 심지어 이 두 shared_ptr이 동일한 객체를 가리키고 있더라도 마찬가지입니다. 중요한 것은 서로 다른 shared_ptr 객체라는 점입니다.&lt;/p&gt;

&lt;p&gt;두 번째 조건을 보면, 동일한 shared_ptr 객체를 여러 스레드에서 동시에 reset()이나 operator= 같은 non-const 연산으로 변경하려는 경우는 같은 변수에 대해 연산 간 선후 관계 없이 동시에 쓰기를 하는 상황입니다. 이는 데이터 레이스 조건에 정확히 해당합니다.&lt;/p&gt;

&lt;p&gt;결국 shared_ptr 문서의 이 두 문장은 단순한 동작 설명을 넘어서 기본 스레드 안전성 원칙에 기반한 설계 의도를 드러내는 부분입니다. 이런 관점으로 표준 라이브러리 문서를 읽으면 각 타입의 스레드 안전성 특성을 더 체계적으로 이해할 수 있습니다.&lt;/p&gt;

&lt;h3 id=""&gt;기본 스레드 안전성을 위반하는 사용자 정의 타입&lt;/h3&gt;

&lt;p&gt;그렇다면 기본 스레드 안전성을 만족하는 사용자 정의 타입은 어떻게 만들어야 할까요? 이에 대한 이해를 돕기 위해, 먼저 기본 스레드 안전성을 만족하지 않는 타입의 예를 살펴보겠습니다. 어떤 점이 문제인지 아는 것만으로도 자연스럽게 기본 스레드 안전성을 만족하도록 만들 수 있습니다.&lt;/p&gt;

&lt;h4 id="1"&gt;문제가 되는 예 1&lt;/h4&gt;

&lt;p&gt;다음과 같은 클래스 A를 살펴보겠습니다. 내부에 &lt;code&gt;mutable std::optional&amp;lt;int&amp;gt; x&lt;/code&gt;가 있고, &lt;code&gt;get_x()&lt;/code&gt; 함수에서는 x의 값이 없으면 계산해서 x에 값을 채우고 반환합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;class A {  
    mutable std::optional&amp;lt;int&amp;gt; x;
    int do_heavy_calculation() const;

public:  
// 여러 스레드가 하나의 변수에 대해 get_x()를 동시에 호출하는 경우 데이터 레이스 발생
// '같은 변수에 대한 읽기와 읽기에 데이터 레이스 없어야 함' 위반
    int get_x() const {
        if (!x.has_value())
            x = this-&amp;gt;do_heavy_calculation();
        return x.value();
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;데이터 레이스 발생 상황&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;문제는 여러 스레드가 동일한 A 객체에서 &lt;code&gt;get_x()&lt;/code&gt;를 동시에 호출하는 상황입니다. 이때 x에 대한 동시 접근이 발생하면서, 선후 관계가 없는 읽기-쓰기, 혹은 쓰기-쓰기 조건이 되어 데이터 레이스가 발생합니다.&lt;/p&gt;

&lt;p&gt;하지만 &lt;code&gt;get_x()&lt;/code&gt;는 const 멤버 함수이기 때문에, 호출하는 쪽에서 이 연산은 읽기로 간주됩니다. 따라서 이 클래스는 기본 스레드 안전성의 조건 중 하나인 "같은 변수에 대한 읽기와 읽기에서 데이터 레이스가 없어야 한다"를 위반하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;해결 방안&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이 문제를 해결하려면, x에 대한 접근에 mutex 등을 이용한 외부 동기화(external synchronization)가 필요합니다.&lt;/p&gt;

&lt;h4 id="2"&gt;문제가 되는 예 2&lt;/h4&gt;

&lt;p&gt;기본 스레드 안전성을 만족하지 않는 또 다른 예를 살펴보겠습니다. 이번에는 내부 자원 공유로 인한 문제입니다.&lt;/p&gt;

&lt;p&gt;클래스 A는 내부에 A_impl이라는 구조체를 shared_ptr로 갖고 있고, &lt;code&gt;f()&lt;/code&gt; 함수는 이 impl 객체의 &lt;code&gt;f_impl()&lt;/code&gt;을 호출합니다. A_impl은 기본 스레드 안전성까지만 보장하는 타입이라고 가정해 봅시다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;class A {  
    struct A_impl { // A_impl은 기본 스레드 안전성만 보장한다고 가정
        void f_impl();
    };
    std::shared_ptr&amp;lt;A_impl&amp;gt; p;

public:  
// 여러 스레드가 각자 A 의 다른 객체에 대해 f()를 동시에 호출하더라도
// p가 가리키는 A_impl이 공유된 동일 객체이면 데이터 레이스 발생 가능.
// '다른 변수에 대한 쓰기와 쓰기에 대해 데이터 레이스 없어야 함' 위반
    void f() {
        p-&amp;gt;f_impl();
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;숨겨진 데이터 레이스&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;여러 스레드가 서로 다른 A 객체를 사용하더라도, 그 내부의 shared_ptr이 동일한 A_impl 인스턴스를 공유하고 있다면 문제가 발생할 수 있습니다. 이때 각 스레드에서 동시에 &lt;code&gt;f()&lt;/code&gt;를 호출하면 결국 동일한 A_impl 인스턴스에 대해 &lt;code&gt;f_impl()&lt;/code&gt;이 동시에 호출됩니다.&lt;/p&gt;

&lt;p&gt;특히 중요한 건, &lt;code&gt;f_impl()&lt;/code&gt;이 non-const 멤버 함수라는 점입니다. 즉, 쓰기 연산일 수 있다는 뜻입니다. A_impl이 기본 스레드 안전성까지만 보장한다면, 동시에 쓰기가 발생하는 상황은 데이터 레이스로 이어질 수 있습니다.&lt;/p&gt;

&lt;p&gt;이는 '다른 변수에 대한 쓰기와 쓰기에 대해 데이터 레이스가 없어야 한다'는 기본 스레드 안전성의 조건을 위반하는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;주의해야 할 패턴&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;겉으로 보기엔 각각 다른 객체처럼 보여도 내부에서 자원이 공유될 수 있는 패턴에서 이런 문제를 조심해야 합니다. shared_ptr을 멤버 데이터로 사용할 때 이런 구조가 되기 쉽습니다.&lt;/p&gt;

&lt;p&gt;shared_ptr을 멤버 데이터로 쓰고 있다면 가리키는 대상이 스레드 간에 공유가 되고 있는지, 또 그 대상이 얼마나 강한 수준의 스레드 안전성을 보장하는지를 잘 따져 보아야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;해결 방안&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이런 구조에서는 다음과 같은 방식으로 해결할 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A_impl 내부에서 더 강한 수준의 스레드 안전성을 보장하기&lt;/li&gt;
&lt;li&gt;A_impl이 const 멤버 함수만 호출하도록 &lt;code&gt;shared_ptr&amp;lt;const A_impl&amp;gt;&lt;/code&gt;을 사용하기&lt;/li&gt;
&lt;li&gt;A를 move-only 타입으로 만들어 A_impl에 대한 공유 자체를 막기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;방법은 각자 상황에 따라 적절히 선택할 수 있습니다.&lt;/p&gt;

&lt;h3 id=""&gt;기본 스레드 안전성의 필요성과 책임 범위&lt;/h3&gt;

&lt;p&gt;사용자 정의 타입에서 기본 스레드 안전성을 꼭 보장해야 할까요? 이에 대한 답을 찾기 위해 구체적인 예를 살펴보겠습니다.&lt;/p&gt;

&lt;h4 id="1"&gt;예 1&lt;/h4&gt;

&lt;p&gt;다음과 같은 &lt;code&gt;sum_of_sizes&lt;/code&gt; 템플릿 함수를 살펴보겠습니다. 벡터 안에 있는 모든 요소의 size를 더해서 합을 구하는 함수입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;// 다음 코드는 스레드 안전한가?

template &amp;lt;typename T&amp;gt;  
int sum_of_sizes(const std::vector&amp;lt;T&amp;gt;&amp;amp; v) {  
    int sum = 0;
    for (const T&amp;amp; x : v) {
        sum += x.size(); // OK?
    }
    return sum;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 함수가 스레드 안전할까요? 즉, 하나의 vector 객체를 인자로 주고 여러 스레드가 동시에 이 함수를 호출하면 안전할까요?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;타입 T의 스레드 안전성에 따른 결과&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이에 대한 답은 T가 기본 스레드 안전성을 보장하느냐에 따라 갈립니다.&lt;/p&gt;

&lt;p&gt;만약 벡터 안에 들어 있는 타입 T가 기본 스레드 안전성을 보장하지 않는 타입이라면 어떨까요? 예를 들어 T가 내부 동기화 없이 mutable 멤버를 건드리는 타입이라면, 여러 스레드에서 동시에 &lt;code&gt;x.size()&lt;/code&gt;를 호출할 때 이 부분에서 데이터 레이스가 발생할 수 있습니다.&lt;/p&gt;

&lt;p&gt;반면에 T가 기본 스레드 안전성을 보장하는 타입이라면 &lt;code&gt;sum_of_sizes&lt;/code&gt; 함수는 스레드 안전합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;설계 철학의 차이&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;여기서 중요한 질문이 생깁니다. T가 기본 스레드 안전성을 만족하기를 요구하고 이 함수는 스레드 안전하다고 말해도 될까요? 아니면 템플릿 함수의 입장에서 보면 T의 내부를 알 수 없기 때문에 이 함수는 스레드 안전하지 않다고 말해야 할까요?&lt;/p&gt;

&lt;p&gt;이 질문은 우리가 타입 설계에서 책임의 범위를 어디까지 둘 것인지에 대한 문제이기도 합니다. 각 타입이 기본 스레드 안전성을 보장한다면, 이를 조합한 상위 레벨 코드의 스레드 안전성을 더 쉽게 추론할 수 있습니다. 이것이 바로 기본 스레드 안전성이 중요한 이유 중 하나입니다.&lt;/p&gt;

&lt;h4 id="2"&gt;예 2&lt;/h4&gt;

&lt;p&gt;이번에는 &lt;code&gt;run_parallel&lt;/code&gt;이라는 템플릿 함수를 살펴보며 스레드 안전성을 따져보겠습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;// 다음 코드는 스레드 안전한가?

template &amp;lt;typename HandleFactory&amp;gt;  
void run_parallel(HandleFactory create_handle, int n) {  
    std::vector&amp;lt;std::thread&amp;gt; thrds;
    for (int i = 0; i &amp;lt; n; ++i) {
        auto h = create_handle();
        thrds.emplace_back([h = std::move(h)] mutable {
            h.run(); // OK?
        });
    }
    for (auto&amp;amp; t : thrds) t.join();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 함수는 핸들을 생성하는 팩토리인 &lt;code&gt;create_handle&lt;/code&gt;을 받습니다. 그리고 각 스레드마다 하나씩 핸들을 생성해서 거기서 &lt;code&gt;run()&lt;/code&gt;을 호출합니다. 스레드마다 별도로 생성된 핸들을 사용하고 있기 때문에, 얼핏 보면 별 문제 없어 보입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;숨겨진 의존성&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;그런데 이 함수가 안전하다고 말하려면, 중요한 전제가 깔려 있어야 합니다. 바로 각 스레드가 생성한 핸들을 외부 동기화 없이 사용할 수 있어야 한다는 점입니다. 그런데 이 전제가 성립하려면, 핸들 타입이 기본적으로 기본 스레드 안전성을 갖추고 있어야 합니다.&lt;/p&gt;

&lt;p&gt;만약 핸들들 사이에 공유된 어떤 내부 객체가 있고, 그 접근이 동기화되지 않은 상태라면 즉, 기본 스레드 안전성이 깨져 있다면 이 &lt;code&gt;run_parallel&lt;/code&gt; 함수는 더 이상 스레드 안전하지 않습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;설계 관점에서의 고민&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;여기서도 다시 생각해볼 수 있습니다. 핸들 타입이 기본 스레드 안전성을 보장한다고 가정하고, 이 함수가 안전하다고 해도 괜찮을까요? 아니면, 외부 동기화 없이는 안전하지 않다고 보는 게 맞을까요?&lt;/p&gt;

&lt;p&gt;이런 질문을 통해 우리는 각 컴포넌트가 기본 스레드 안전성을 보장했을 때 얻을 수 있는 합성성(composability)의 가치를 알 수 있습니다. 하위 레벨 타입이 기본 스레드 안전성을 보장하면 상위 레벨에서 이들을 조합한 코드의 스레드 안전성을 더 쉽게 추론할 수 있습니다.&lt;/p&gt;

&lt;h3 id=""&gt;기본 스레드 안전성을 왜 보장해야 하나?&lt;/h3&gt;

&lt;p&gt;앞에서 본 두 가지 예에서 어느 쪽 의견이 맞을까요?&lt;/p&gt;

&lt;p&gt;C++ 커뮤니티의 공통된 의견은 이런 코드가 기본적으로 스레드 안전했으면 좋겠다는 것입니다. 즉, 템플릿에 넣는 타입은 기본 스레드 안전성을 보장할 것이라고 가정하겠다는 것입니다. 이러한 철학에는 몇 가지 중요한 이유가 있습니다.&lt;/p&gt;

&lt;p&gt;첫째, C++에서는 사용자 정의 타입도 기본 타입처럼 동작하길 기대합니다. 기본 타입은 기본 스레드 안전성을 보장하니까 사용자 정의 타입도 마찬가지로 그렇게 동작하길 기대하는 것입니다. 그래야 기본 타입이든 사용자 정의 타입이든 같은 템플릿 함수에서 문제 없이 다룰 가능성이 높아집니다. 표준 라이브러리의 타입이 기본 스레드 안전성을 보장하는 것도 이러한 바탕에서 설계된 것이라고 이해할 수 있습니다.&lt;/p&gt;

&lt;p&gt;둘째, 기본 스레드 안전성을 보장하지 않는 타입을 사용하면, 그걸 쓰는 쪽에서 외부 동기화를 직접 처리해야 합니다. 그러면 코드가 복잡해지고 비직관적으로 흐를 수 있습니다. 예를 들어 &lt;code&gt;run_parallel()&lt;/code&gt;처럼 스레드마다 독립된 핸들을 사용하는 구조에서 외부 동기화가 필요하다고 하면 대부분 의아해 할 것입니다. 이걸 동기화하려면 global lock을 쓰는 수밖에 없기 때문에 받아들이기 어려워하는 사람도 많을 것입니다.&lt;/p&gt;

&lt;p&gt;가능한 한 타입 자체가 기본 스레드 안전성을 보장해 주는 편이, 사용하는 사람 입장에서는 훨씬 단순하고 안전합니다. 그리고 기존에 이미 작성된 코드를 변경하지 않고도 스레드 안전하게 만들 가능성이 높아집니다.&lt;/p&gt;

&lt;p&gt;물론, 그렇다고 해서 외부 동기화가 전혀 필요 없다는 이야기는 아닙니다. 외부 동기화는 여전히 필요하며, 이에 대해서는 다음에서 조금 더 자세히 이야기해 보겠습니다.&lt;/p&gt;

&lt;h2 id="externalsynchronization"&gt;외부 동기화(external synchronization)&lt;/h2&gt;

&lt;p&gt;지금까지는 타입이 기본 스레드 안전성을 보장하는 경우에 대해서 이야기해 왔습니다. 하지만 이 경우에도 모든 상황이 자동으로 안전해지는 건 아닙니다.&lt;/p&gt;

&lt;p&gt;예를 들어, 기본 스레드 안전성만을 보장하는 타입의 동일한 객체에 여러 스레드가 접근한다고 가정해봅시다. 이 중 한 스레드가 non-const 멤버 함수를 호출하고 있고 다른 스레드도 동시에 같은 객체에 접근하고 있다면 문제가 생길 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 상황을 안전하게 만들기 위해서는, 그 non-const 함수 호출이 다른 호출과 시간이 겹치지 않음을 보장해야 합니다. 즉, 호출 간에 명확한 연산 간 선후 관계가 성립해야 합니다.&lt;/p&gt;

&lt;p&gt;이런 식으로 호출하는 쪽에서 동기화를 책임지고 보장하는 것을 외부 동기화(external synchronization)라고 합니다. 타입 자체가 내부에서 동기화를 하지 않기 때문에, 사용하는 쪽에서 mutex 등을 사용해서 실행 순서가 명확하도록 해야 합니다.&lt;/p&gt;

&lt;p&gt;기본 스레드 안전성을 만족하는 타입을 포함해서 모든 타입에 대해 다음과 같은 연산은 데이터 레이스가 없다는 것이 항상 보장됩니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;같은 변수에 대한 연산 간 선후 관계에 있는 쓰기와 읽기&lt;/li&gt;
&lt;li&gt;같은 변수에 대한 연산 간 선후 관계에 있는 쓰기와 쓰기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, 연산 간 선후 관계만 잘 만들어 준다면 그 자체로 데이터 레이스는 방지할 수 있습니다.&lt;/p&gt;

&lt;h3 id="stdmutex"&gt;std::mutex를 통한 동기화&lt;/h3&gt;

&lt;p&gt;외부 동기화를 하기 위해서는, 호출의 연산 간 선후 관계를 명확하게 만들어 줄 수 있는 수단이 필요합니다. 이때 가장 자주 사용되는 도구가 바로 &lt;code&gt;std::mutex&lt;/code&gt;입니다.&lt;/p&gt;

&lt;p&gt;C++ 메모리 모델에서 &lt;code&gt;std::mutex&lt;/code&gt;의 &lt;code&gt;unlock()&lt;/code&gt;과 &lt;code&gt;lock()&lt;/code&gt;은 특별한 관계입니다. 한 스레드에서 &lt;code&gt;unlock()&lt;/code&gt;을 호출하고, 다른 스레드가 같은 mutex에 대해 &lt;code&gt;lock()&lt;/code&gt;을 성공적으로 수행하면, 이 두 연산 사이에는 동기화 관계가 성립합니다. 동기화 관계와 순차 실행 관계가 연결되면 연산 간 선후 관계가 만들어집니다. 이에 따르면 한 스레드에서 &lt;code&gt;unlock()&lt;/code&gt; 이전에 실행된 모든 연산은, 다른 스레드에서 &lt;code&gt;lock()&lt;/code&gt; 이후에 실행되는 연산보다 먼저 실행됨이 보장됩니다. 즉, 이 두 스레드 간에 명확한 연산 간 선후 관계가 만들어지는 것입니다. 이렇게 해서 외부 동기화가 달성됩니다.&lt;/p&gt;

&lt;p&gt;mutex가 크리티컬 섹션(critical section) 간 실행이 겹치지 않게 하는 도구 역할을 하는 이면에는 이와 같이 C++ 메모리 모델 관점에서 연산 간 선후 관계를 만드는 매우 중요한 메커니즘이 동작하고 있습니다.&lt;/p&gt;

&lt;h3 id="stdmutex"&gt;std::mutex를 통한 연산 간 선후 관계 형성&lt;/h3&gt;

&lt;p&gt;다음 그림은 &lt;code&gt;std::mutex&lt;/code&gt;를 사용할 때 C++ 메모리 모델에서 연산 간 선후 관계가 어떻게 형성되는지 보여줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/2-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;앞에서 본 atomic을 사용했을 때의 그림과 일치합니다. 단지 atomic-store-release와 atomic-load-acquire 대신 &lt;code&gt;mutex.unlock()&lt;/code&gt;과 &lt;code&gt;mutex.lock()&lt;/code&gt;이 사용된 것이 다릅니다.&lt;/p&gt;

&lt;p&gt;Thread 1이 &lt;code&gt;mutex.unlock()&lt;/code&gt;을 호출하고, Thread 2가 같은 mutex에 대해 &lt;code&gt;lock()&lt;/code&gt;을 성공하면, 이 두 연산 사이에 동기화 관계가 생깁니다. 이것 때문에 Thread 1에서 A에 3을 쓴 것과 Thread 2에서 이를 3으로 읽는 것 사이에 연산 간 선후 관계가 완성됩니다.&lt;/p&gt;

&lt;p&gt;이것이 C++에서 여러 스레드에서 접근하는 동일 메모리 위치에 대한 연산 간의 순서를 정하는 방식입니다. 이런 순서 관계가 명확히 성립하지 않으면, 값이 제대로 전달되지 않거나 동기화가 되지 않아서 데이터 레이스, 즉 미정의 행동이 발생할 수 있습니다.&lt;/p&gt;

&lt;h3 id="stdatomic"&gt;std::atomic을 통한 외부 동기화&lt;/h3&gt;

&lt;p&gt;이번에는 &lt;code&gt;std::mutex&lt;/code&gt; 대신 &lt;code&gt;std::atomic&lt;/code&gt;을 써서 외부 동기화 효과를 달성하는 방법을 살펴보겠습니다. 앞의 예와 비슷한 패턴인데, 변수명을 좀 더 와 닿게 지어봤습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/3-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;왼쪽 스레드는 payload를 준비한 후 ready 플래그를 설정하고, 오른쪽 스레드는 ready 플래그가 설정될 때까지 기다렸다가 payload를 읽습니다. payload에 대한 쓰기-읽기 간에 실행 순서를 정해 주는 것이 외부 동기화입니다.&lt;/p&gt;

&lt;p&gt;이 두 스레드는 ready라는 플래그를 통해 서로의 작업 순서를 조율하는데, 핵심은 바로 이 &lt;code&gt;ready = true&lt;/code&gt; 쓰기가 atomic-store-release이고 &lt;code&gt;while (!ready) {}&lt;/code&gt; 읽기가 atomic-load-acquire라는 것입니다. 이 사이에는 atomic 연산의 동기화 관계가 형성되고, 그로 인해 payload에 대한 쓰기와 읽기 사이에도 연산 간 선후 관계가 만들어집니다.&lt;/p&gt;

&lt;p&gt;그런데 이 연산 간 선후 관계는 payload에 직접 작용하는 게 아니라, ready라는 제3의 atomic 변수를 통해 간접적으로 만들어진다는 게 포인트입니다. 따라서 payload는 &lt;code&gt;std::atomic&lt;/code&gt;일 필요도 없고, 동기화 자체는 ready를 중심으로 이루어집니다.&lt;/p&gt;

&lt;p&gt;이처럼 &lt;code&gt;std::atomic&lt;/code&gt;은 단순히 동시 접근해도 안전한 기본 타입 정도가 아니라, 외부 동기화의 기준점으로도 아주 효과적으로 사용될 수 있습니다. 그리고 이런 식의 동기화 패턴은 실제 멀티 스레드 코드에서 자주 쓰이는 기본기 중 하나입니다.&lt;/p&gt;

&lt;h3 id="memory_orderrelaxed"&gt;memory_order::relaxed 사용 시 주의 사항&lt;/h3&gt;

&lt;p&gt;만약 &lt;code&gt;ready.store()&lt;/code&gt;, &lt;code&gt;ready.load()&lt;/code&gt;에 &lt;code&gt;memory_order::relaxed&lt;/code&gt;를 넣으면 어떻게 될까요?&lt;/p&gt;

&lt;p&gt;이 경우에는 store와 load 사이에 동기화 관계가 성립하지 않게 됩니다. 그 결과, ready를 중심으로 한 연산 간 선후 관계가 만들어지지 않고, 자연히 payload에 대한 쓰기와 읽기 사이에도 연산 간 선후 관계가 사라집니다. 즉, 두 스레드가 payload에 대해 순서 관계가 정의되지 않은 쓰기와 읽기를 수행한 것이 되기 때문에, 이는 데이터 레이스에 해당합니다. 그리고 C++에서 데이터 레이스는 곧 미정의 행동입니다.&lt;/p&gt;

&lt;p&gt;많은 사람이 atomic 변수에 대한 load, store 연산에 &lt;code&gt;memory_order::relaxed&lt;/code&gt; 옵션을 사용하는데, 그냥 빨라져서 좋은 거다 정도로 생각하고 마구잡이로 쓰면 안 됩니다. 물론 단독 변수로서 다른 데이터와 관련이 없는 경우에는 유용한 옵션입니다. 실제로 사용하기 전에 해당 atomic 변수를 쓰고 읽을 때 이전에 실행했던 내용이 이후에 영향을 미치려는 의도가 있는지 확인해 보는 것이 좋습니다.&lt;/p&gt;

&lt;p&gt;이번 예에서, ready에 대한 쓰기와 읽기가 relaxed이더라도 payload가 atomic 변수였다면 데이터 레이스로 이어지지는 않았을 것입니다. 그렇지만 순서 관계가 없기 때문에 왼쪽 스레드에서 payload에 쓴 7이라는 값을 오른쪽 스레드에서 읽게 된다는 보장은 없고, 그 이전의 어떤 값을 읽게 될 수도 있습니다. 이건 의도한 상황이 아닐 테니까, ready에 relaxed 옵션을 쓰기 전에 이런 상황이 발생하지 않을지 확인을 해 보는 게 좋겠습니다.&lt;/p&gt;

&lt;h3 id="synchronizeswith"&gt;동기화 관계(synchronizes-with)를 제공하는 함수&lt;/h3&gt;

&lt;p&gt;지금까지 동기화 관계에 대해 설명했는데, 사실 cppreference.com에서도 많이 언급되는 용어입니다. 몇 가지 예를 발췌해 왔습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;std::mutex::lock()
&lt;ul&gt;&lt;li&gt;Prior unlock() operations on the same mutex &lt;em&gt;synchronize-with&lt;/em&gt; (as defined in std::memory_order) this operation.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;std::async()
&lt;ul&gt;&lt;li&gt;the associated thread completion &lt;em&gt;synchronizes-with&lt;/em&gt; the successful return from the first function that is waiting on the shared state...&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;std::thread::join()
&lt;ul&gt;&lt;li&gt;The completion of the thread identified by *this &lt;em&gt;synchronizes with&lt;/em&gt; the corresponding successful return from join().&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;std::call_once()
&lt;ul&gt;&lt;li&gt;The return from the returning call &lt;em&gt;synchronizes-with&lt;/em&gt; the returns from all passive calls on the same flag.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;가장 익숙한 예는 &lt;code&gt;std::mutex::lock()&lt;/code&gt;입니다. 한 스레드에서 &lt;code&gt;unlock()&lt;/code&gt;을 호출하면, 그 이후 다른 스레드가 같은 mutex에 대해 &lt;code&gt;lock()&lt;/code&gt;을 수행하는 그 순간, 두 연산 사이에 동기화 관계가 만들어진다고 설명하고 있습니다.&lt;/p&gt;

&lt;p&gt;두 번째는 &lt;code&gt;std::async()&lt;/code&gt;입니다. 문서 설명에 따르면, 백그라운드에서 실행된 스레드의 완료 시점은 그 결과를 기다리는 함수의 반환과 동기화 관계를 형성합니다. 이 말은 즉, &lt;code&gt;future.get()&lt;/code&gt;을 호출하면, 이는 async로 실행된 함수의 작업이 모두 끝난 뒤라는 보장이 생기는 것입니다.&lt;/p&gt;

&lt;p&gt;세 번째는 &lt;code&gt;std::thread::join()&lt;/code&gt;입니다. 어떤 스레드가 완료되면, &lt;code&gt;join()&lt;/code&gt;을 호출한 쪽은 그 스레드의 작업이 모두 끝났다는 것을 보장받습니다. 그래서 &lt;code&gt;join()&lt;/code&gt; 호출 이후에는 그 스레드가 수행한 메모리 연산 결과를 안전하게 관찰할 수 있습니다.&lt;/p&gt;

&lt;p&gt;마지막으로, &lt;code&gt;std::call_once()&lt;/code&gt;도 있습니다. 여러 스레드가 동시에 진입하려고 해도 단 한 번만 실행됨을 보장해주는 도구인데, 최초로 실행을 완료한 스레드가 메모리에 변경했던 내용이, 이후 모든 passive call이 반환한 후에도 다 보인다는 말입니다.&lt;/p&gt;

&lt;p&gt;synchronizes-with는 단순히 atomic 연산에서만 등장하는 개념이 아니라, C++ 표준 라이브러리의 다양한 동기화 도구에서 폭넓게 사용되는 개념입니다.&lt;/p&gt;

&lt;h2 id="internallysynchronizedtype"&gt;내부 동기화 타입(internally synchronized type)&lt;/h2&gt;

&lt;p&gt;지금까지는 외부 동기화, 즉 객체 바깥에서 동기화하는 방식을 설명했습니다. 그러면 이제 '아예 타입 자체가 스레드 안전하면 안 되나?'라는 질문이 나올 수 있습니다.&lt;/p&gt;

&lt;p&gt;예를 들어 어떤 사용자 정의 타입이 있는데, 그 타입의 non-const 멤버 함수를 여러 스레드에서 동시에 호출하고 싶다고 해봅시다. 그리고 그런 동시 호출이 전혀 문제가 없게 만들고 싶다면 어떻게 해야 할까요?&lt;/p&gt;

&lt;p&gt;이럴 때 우리가 만들고자 하는 타입이 바로 내부 동기화 타입입니다. 말 그대로, 내부에서 자체 동기화를 수행하는 타입입니다. 즉, 객체의 사용자가 별도로 mutex나 atomic 변수를 활용하지 않아도 되게끔 설계된 타입입니다. 흔히 말하는 스레드 안전 타입(thread safe type)입니다.&lt;/p&gt;

&lt;p&gt;물론 내부 동기화 타입을 제대로 만드는 건 쉽지 않은 일입니다. 경쟁 조건(race)이 없도록 인터페이스를 설계해야 하고, 데드락 위험 등도 고려해야 합니다. 여기에서는 이런 타입을 만드는 기법에 대해서는 다루지 않고, 그보다는 내부 동기화 타입이 만들어지는 이론적인 원리에 중점을 두어 설명하겠습니다.&lt;/p&gt;

&lt;h3 id=""&gt;기본 스레드 안전성만 보장하는 타입으로 내부 동기화 타입 만들기 시도(실패)&lt;/h3&gt;

&lt;p&gt;내부 동기화 타입을 만들어보려는 첫 번째 시도를 살펴보겠습니다. 하지만 이 시도는 실패했습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;class thread_safe_counter {  
    bool locked = false;
    int id = 0;
public:  
    int next_id() { // non-const 멤버 함수를 데이터 레이스가 없도록 만들어야 함
        while (locked) // (1) 읽기
            ;
        locked = true; // (2) 쓰기
        int x = id++;
        locked = false; // (3) 쓰기
        return x;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 &lt;code&gt;thread_safe_counter&lt;/code&gt; 클래스는 고유한 ID를 생성하는 &lt;code&gt;next_id()&lt;/code&gt; 함수를 제공합니다. 여러 스레드가 동시에 호출할 수 있기 때문에 내부 동기화가 필요하다고 판단해서, locked라는 플래그를 만들어 사용했습니다. 하지만 이 코드는 제대로 동작하지 않습니다. 왜 그럴까요?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(1)과 (2)가 원자적으로 실행되지 않음&lt;/li&gt;
&lt;li&gt;(1)-(2), (2)-(2), (2)-(3), (1)-(3), (3)-(3) 연산 간 데이터 레이스 발생&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;첫 번째 문제는 (1)과 (2) 사이에 틈이 있다는 것입니다. 한 스레드가 locked가 false임을 확인한 직후에, 다른 스레드가 끼어들어서 locked를 true로 바꿀 수 있습니다. 그러면 두 스레드가 모두 크리티컬 섹션에 들어가는 문제가 생깁니다.&lt;/p&gt;

&lt;p&gt;두 번째는 더 근본적인 문제입니다. locked 변수 자체가 bool 타입인데, 이는 C++에서 기본 스레드 안전성만 보장하는 타입입니다. 즉, 여러 스레드가 동시에 locked를 읽고 쓰는 것 자체가 데이터 레이스를 일으킵니다.&lt;/p&gt;

&lt;p&gt;예전에는 'bool 같은 간단한 타입은 여러 스레드가 동시에 접근해도 괜찮을 거야'라고 생각하는 경우가 많았습니다. 하지만 C++에서 메모리 모델과 데이터 레이스가 정의된 이후로는, 이런 접근 방식은 모두 미정의 행동이 되었습니다.&lt;/p&gt;

&lt;p&gt;결국 이 문제를 해결하려면 더 강력한 스레드 안전성을 보장하는 타입이 필요합니다.&lt;/p&gt;

&lt;h3 id=""&gt;내부 동기화 타입 구현의 핵심 원리&lt;/h3&gt;

&lt;p&gt;앞의 예에서 보듯, bool과 int 같은 기본 스레드 안전성만을 보장하는 타입만으로는 내부 동기화 타입을 만들 수 없습니다.&lt;/p&gt;

&lt;p&gt;왜 그럴까요? non-const 멤버 함수가 동시에 호출될 수 있는 상황에서, 이런 타입은 그 자체로 동시 접근에 대한 충분한 보호를 제공하지 않기 때문입니다. 내부에서 동기화를 책임져야 하는데, 그걸 기본 스레드 안전성까지만 보장하는 타입만으로 구현하려다 보면 결국 데이터 레이스에 빠지게 됩니다.&lt;/p&gt;

&lt;p&gt;그래서 중요한 결론이 나옵니다. 내부 동기화 타입을 만들고 싶다면, 그 내부 구성 요소 중에도 이미 내부 동기화 타입이 필요하다는 것입니다.&lt;/p&gt;

&lt;h3 id=""&gt;내부 동기화 타입 만들기 시도(성공)&lt;/h3&gt;

&lt;p&gt;앞에서 본 &lt;code&gt;thread_safe_counter&lt;/code&gt; 구현을 다시 시도해 봅시다. 이번에는 &lt;code&gt;thread_safe_queue&lt;/code&gt;라는 클래스가 있어서 이걸 사용해 보겠습니다. 이 클래스는 이미 내부 동기화 타입입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;class thread_safe_counter {  
    thread_safe_queue&amp;lt;int&amp;gt; q {0}; // 내부 동기화 사용
public:  
    int next_id() { // non-const 멤버 함수를 데이터 레이스가 없도록 만들어야 함.
        std::optional&amp;lt;int&amp;gt; x;
        while (!x.has_value())
            x = q.pop_if_not_empty(); // (1)
        int y = x.value() + 1;
        q.push(y); // (2)
        return x.value();
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이전에는 단순히 bool 변수만 가지고 동기화를 시도했기 때문에 여러 스레드가 동시에 접근할 때 데이터 레이스가 발생했습니다. 하지만 이번에는 &lt;code&gt;thread_safe_queue&lt;/code&gt;가 내부 동기화를 제공하기 때문에, 이 큐를 기반으로 한 &lt;code&gt;next_id()&lt;/code&gt; 함수는 동시에 여러 스레드가 호출하더라도 안전하게 동작할 수 있습니다.&lt;/p&gt;

&lt;p&gt;구조를 보면, &lt;code&gt;pop_if_not_empty()&lt;/code&gt;를 사용해서 숫자를 꺼내는 방식으로 ID를 생성하고 있는데, 이 과정에서 여러 스레드가 동시에 접근해도 (1)-(1), (1)-(2), (2)-(2) 사이에 데이터 레이스가 발생하지 않도록 보장됩니다.&lt;/p&gt;

&lt;p&gt;그런데 여기서 한 가지 궁금증이 생깁니다. 그렇다면 thread_safe_queue는 어떻게 구현되어 있을까요? 이 타입은 스스로 내부 동기화를 제공한다고 했는데, 그 내부에서는 뭔가 다른 더 하위의 동기화 메커니즘, 즉 또 다른 내부 동기화 타입이 필요할 것입니다.&lt;/p&gt;

&lt;p&gt;이는 마치 닭과 달걀의 문제 같아 보일 수 있습니다. 하지만 다행히 C++ 표준 라이브러리에서는 이미 내부 동기화 타입을 제공합니다. 대표적으로 &lt;code&gt;std::atomic&lt;/code&gt;과 &lt;code&gt;std::mutex&lt;/code&gt; 같은 타입이 그런 역할을 합니다. 이런 기본 블록을 활용해서 더 복잡한 내부 동기화 타입을 만들어나갈 수 있는 것입니다.&lt;/p&gt;

&lt;h3 id="synchronizationprimitive"&gt;동기화 기본 요소(synchronization primitive)&lt;/h3&gt;

&lt;p&gt;앞에서 &lt;code&gt;thread_safe_queue&lt;/code&gt; 같은 타입을 만들려면, 그 내부에 또 다른 내부 동기화 타입이 필요하다고 했습니다.&lt;/p&gt;

&lt;p&gt;그럼 이제 질문이 생깁니다. '맨 아래까지 내려가면, 결국 무엇을 기반으로 동기화를 구현하는가?' 바로 그 역할을 하는 것이 동기화 기본 요소입니다. 여기에는 여러분이 잘 아는 &lt;code&gt;std::atomic&lt;/code&gt;, &lt;code&gt;std::mutex&lt;/code&gt;, &lt;code&gt;std::condition_variable&lt;/code&gt;, 그리고 &lt;code&gt;std::future&lt;/code&gt; 같은 것이 포함됩니다.&lt;/p&gt;

&lt;p&gt;이런 기본 요소는 그 자체로 내부 동기화 타입이거나, 그런 타입을 내부 구현에 포함하고 있습니다. 예를 들어 mutex의 &lt;code&gt;lock()&lt;/code&gt;과 &lt;code&gt;unlock()&lt;/code&gt; 모두 non-const 멤버 함수인데, 여러 스레드가 동시에 호출해도 데이터 레이스가 발생하지 않습니다.&lt;/p&gt;

&lt;p&gt;이 기본 요소들이 더 고수준의 동기화 타입을 구현하는 데 사용되고, 이 고수준의 동기화 타입을 조합해서 또 더 고수준의 동기화 타입을 만들 수 있는 것입니다.&lt;/p&gt;

&lt;p&gt;다음은 앞에서 본 &lt;code&gt;thread_safe_queue&lt;/code&gt;를 구현할 때 내부에 &lt;code&gt;std::mutex&lt;/code&gt; 같은 동기화 기본 요소를 사용해서 구현하는 예입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;template &amp;lt;typename T&amp;gt;  
class thread_safe_queue {  
    std::mutex mtx; // std::mutex는 C++가 제공하는 그 자체로 내부 동기화 타입이다.
    std::queue&amp;lt;T&amp;gt; base;
public:  
    void push(const T&amp;amp; x) {
        mtx.lock();
        base.push(x);
        mtx.unlock();
    }
    std::optional&amp;lt;T&amp;gt; pop_if_not_empty() {
        std::optional&amp;lt;T&amp;gt; ret;
        mtx.lock();
        if (!base.empty()) {
            ret = base.front();
            base.pop();
        }
        mtx.unlock();
        return ret;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;여기서 &lt;code&gt;std::mutex&lt;/code&gt;는 이 타입 자체가 이미 C++에서 보장하는 내부 동기화 타입이기 때문에, 우리가 따로 이를 동기화할 필요가 없습니다. 그냥 &lt;code&gt;lock()&lt;/code&gt;과 &lt;code&gt;unlock()&lt;/code&gt;을 적절히 호출하기만 하면 됩니다.&lt;/p&gt;

&lt;p&gt;코드를 보면 &lt;code&gt;push()&lt;/code&gt; 함수와 &lt;code&gt;pop_if_not_empty()&lt;/code&gt; 함수가 있는데, 단순히 함수 앞뒤로 &lt;code&gt;lock()&lt;/code&gt;과 &lt;code&gt;unlock()&lt;/code&gt;을 넣어서 보호를 하고 있습니다. 그러면 이 멤버 함수 호출 간에 연산 간 선후 관계가 만들어지고, 여러 스레드가 동시에 접근해도 데이터 레이스가 발생하지 않습니다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;std::mutex&lt;/code&gt;부터는 더 이상 바닥으로 내려갈 고민을 하지 않아도 됩니다. 하지만 사실 mutex도 또 다른 내부 동기화 타입인 &lt;code&gt;std::atomic&lt;/code&gt;으로 구현하는 것이 가능합니다. 다음에서 살펴보겠습니다.&lt;/p&gt;

&lt;h3 id="stdatomicmutex"&gt;std::atomic을 사용한 mutex 구현&lt;/h3&gt;

&lt;p&gt;다음은 &lt;code&gt;std::atomic&lt;/code&gt;을 사용해 mutex를 구현한 예입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-cpp"&gt;class mutex {  
// mutex를 다른 내부 동기화 타입인 std::atomic으로 구현할 수 있다.
    std::atomic&amp;lt;bool&amp;gt; locked = false;
public:  
    void lock() {
        while (locked.exchange(true, std::memory_order::acquire))
            // 참고: busy loop를 피하려면 'locked.wait(true);'를 써도 된다.
            ;
    }
    void unlock() {
        locked.store(false, std::memory_order::release);
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;std::atomic&lt;/code&gt;도 동기화 기본 요소로서 내부 동기화 타입이기 때문에 이런 구현이 가능합니다.&lt;/p&gt;

&lt;p&gt;이 구현은 일종의 spinlock 형태의 mutex인데, locked라는 &lt;code&gt;std::atomic&amp;lt;bool&amp;gt;&lt;/code&gt; 변수를 가지고 있습니다. &lt;code&gt;lock()&lt;/code&gt; 함수는 이 locked 값을 true로 바꾸고 이전 상태가 false인지 확인합니다. 이미 다른 스레드가 true로 설정해 놓은 상태라면, 계속 루프를 돌면서 기다립니다. 물론 여기서 atomic &lt;code&gt;wait()&lt;/code&gt; 함수를 사용하면 busy loop를 피할 수도 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;unlock()&lt;/code&gt;에서는 단순히 locked를 false로 바꿉니다. 그러면 &lt;code&gt;lock()&lt;/code&gt;을 실행하는 다른 스레드 중 하나가 이것을 읽고 루프에서 빠져나올 수 있습니다. 이런 식으로 mutex로서 동작할 수 있습니다.&lt;/p&gt;

&lt;p&gt;그리고 &lt;code&gt;exchange()&lt;/code&gt;에서 사용한 &lt;code&gt;memory_order::acquire&lt;/code&gt;과 &lt;code&gt;store()&lt;/code&gt;에서 사용한 &lt;code&gt;memory_order::release&lt;/code&gt;는 mutex가 동기화 관계를 제공하기 위해 필요한 것입니다.&lt;/p&gt;

&lt;h3 id=""&gt;동기화 기본 요소의 상호 구현 가능성&lt;/h3&gt;

&lt;p&gt;앞에서 mutex를 atomic으로 구현해 보았습니다. 반대로 atomic을 mutex로 구현하는 것도 당연히 가능합니다. 어렵지 않을 것입니다.&lt;/p&gt;

&lt;p&gt;사실 이런 동기화 기본 요소들은 서로를 이용해서 구현할 수 있습니다. 그래서 어떤 것이 더 근본적(primitive)인가 하는 질문은 큰 의미가 없습니다.&lt;/p&gt;

&lt;p&gt;많은 언어에는 동시성 문제를 해결하기 위한 각자의 패러다임이 있습니다. 어떤 언어는 기본 요소로 mutex가 아니라 스레드 간 메시지 채널을 사용하기도 합니다. 이 또한 서로를 이용해 구현할 수 있습니다. 결국 다 같은 문제를 해결하려는 서로 다른 방법일 뿐이지 논리적으로 동등하다는 것을 이해하면 좋겠습니다.&lt;/p&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;p&gt;지금까지 C++에서 스레드 안전성을 보장하는 방법에 대해 살펴봤습니다. 주요 내용을 정리하면 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;데이터 레이스 개념에서 출발하여 기본 타입에 대한 기본 스레드 안전성 조건을 살펴보며 데이터 레이스가 발생하지 않게 하는 조건을 이해했습니다.&lt;/li&gt;
&lt;li&gt;기본 스레드 안전성 조건을 사용자 정의 타입에도 확장할 수 있으며, C++ 표준 라이브러리 타입은 모두 이 조건을 만족하고 있습니다. 사용자 정의 타입도 이 조건을 만족해야 표준 라이브러리와 잘 섞어 쓸 수 있습니다.&lt;/li&gt;
&lt;li&gt;외부 동기화에서는 단순히 잠금이나 atomic을 사용하는 것보다 더 본질적으로, 동기화 관계를 만들어야 한다는 점이 중요합니다. 이를 통해 연산 간 선후 관계를 보장하고 데이터 레이스를 방지할 수 있습니다.&lt;/li&gt;
&lt;li&gt;내부 동기화 타입은 기본 스레드 안전성 수준을 넘어서, non-const 멤버 함수도 동시 호출이 가능한 타입입니다.&lt;/li&gt;
&lt;li&gt;내부 동기화 타입을 만들기 위해서는 결국 다른 내부 동기화 타입이 필요하며, 맨 바닥까지 내려가면 atomic, mutex, condition_variable 같은 동기화 기본 요소를 사용해야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇게 계층적으로 구성된 스레드 안전성 개념을 이해하면 멀티 스레드 환경에서 안전하고 효율적인 C++ 코드를 작성할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 글이 C++에서 스레드 안전성을 체계적으로 이해하는 데 도움이 되었기를 바랍니다. 감사합니다.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>서비스 조직에서 Kafka를 사용할 때 알아 두어야 할 것들 (4)</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/1025526" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/1025526</id>
    <updated>2025-06-30T16:40:07Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; 
&lt;a href="https://d2.naver.com/helloworld/2472336"&gt;서비스 조직에서 Kafka를 사용할 때 알아 두어야 할 것들 (3)&lt;/a&gt;을 보고 오시면 좋습니다.
1,2편은 사내용으로 발표되어 아쉽지만 외부 공개는 어려운 점 양해 부탁드립니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/79196054?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;Kafka 프로듀서 최적화하기 + 압축 기능 활용하기&lt;/p&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;배경: Kafka 자료 구조
&lt;ul&gt;&lt;li&gt;Kafka 자료 구조는 어떻게 생겼는가?&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;프로듀서 동작 방식 및 최적화 방법
&lt;ul&gt;&lt;li&gt;프로듀서와 브로커는 어떻게 메시지를 주고받는가? &lt;/li&gt;
&lt;li&gt;linger.ms, batch.size, buffer.memory 사용법&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;압축 동작 방식 및 최적화 방법
&lt;ul&gt;&lt;li&gt;(재)압축은 어떻게 이루어지는가?&lt;/li&gt;
&lt;li&gt;compression.type, compression.{type}.level 사용법&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>서비스 조직에서 Kafka를 사용할 때 알아 두어야 할 것들 (3)</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/2472336" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/2472336</id>
    <updated>2025-06-30T16:40:00Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; 
&lt;a href="https://d2.naver.com/helloworld/1025526"&gt;서비스 조직에서 Kafka를 사용할 때 알아 두어야 할 것들 (4)&lt;/a&gt;에서 이어집니다.
1,2편은 사내용으로 발표되어 아쉽지만 외부 공개는 어려운 점 양해 부탁드립니다.&lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/79195901?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;  
&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;Kafka Client는 어떻게 클러스터의 전체 상태를 알 수 있는가? 서비스를 개발하는 입장에서 관련 옵션을 어떻게 잡아 주면 좋은가? 에 대해 설명합니다.&lt;/p&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Kafka metadata란 무엇인가?&lt;/li&gt;
&lt;li&gt;동작 매커니즘
&lt;ul&gt;&lt;li&gt;브로커 - 클라이언트 간 metadata 교환&lt;/li&gt;
&lt;li&gt;브로커 간 metadata 교환&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;결론
&lt;ul&gt;&lt;li&gt;... 그리고 하나 더&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Yappi로 Python에서도 성능을 챙겨보자</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/4394645" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/4394645</id>
    <updated>2025-06-26T16:52:09Z</updated>
    <content type="html">&lt;p&gt;Python은 높은 개발 생산성으로 많이 사랑받는 프로그래밍 언어 중 하나입니다. 하지만 높은 생산성의 대가로 성능에 대해 많은 비용을 지불해야 한다는 것이 정설로 여겨지고 있었습니다.&lt;/p&gt;

&lt;p&gt;그러나 &lt;a href="https://docs.python.org/3/whatsnew/3.11.html#summary-release-highlights"&gt;Python 3.11&lt;/a&gt;을 시작으로, 이제는 Python에서도 성능을 챙기려는 노력이 이어지고 있습니다. 그 연장선으로 이 글에서는 프로파일링 도구 중 하나인 &lt;a href="https://github.com/sumerc/yappi"&gt;Yappi&lt;/a&gt;를 활용해서 Python 서버의 성능 개선을 이루어낸 사례를 소개하고자 합니다. 이 글이 Python 애플리케이션의 성능을 더 쉽게 분석하고 최적화하는 데에 도움이 되었으면 좋겠습니다.&lt;/p&gt;

&lt;h2 id=""&gt;배경 지식&lt;/h2&gt;

&lt;p&gt;저희가 당면한 문제에 대해 이야기하기 위해, 먼저 주요 용어와 구조를 간단히 설명하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://d2.naver.com/helloworld/6754228"&gt;서치피드&lt;/a&gt; 등 최근 네이버에서 새롭게 출시되는 많은 피드의 뒤에는 수많은 컴포넌트가 존재합니다. 피드를 구성하기 위해서는 일련의 과정이 필요합니다. 가장 간단하게 피드를 구성한다고 가정하면 필요한 과정은 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;주어진 질의와 연관된 문서를 DB에서 100개 가져온다.  &lt;/li&gt;
&lt;li&gt;가져온 문서의 피처(feature)를 종합해 순위(랭킹)를 매긴다.  &lt;/li&gt;
&lt;li&gt;가장 높은 랭킹을 얻은 문서 10개를 차례로 노출한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;피처란?&lt;/strong&gt;&lt;/p&gt;
  
  &lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)"&gt;"In machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a data set."&lt;/a&gt;&lt;/p&gt;
  
  &lt;p&gt;어떤 개체에 대한 정보, 특징을 이야기하며 보통 ML 모델의 입력값으로 사용됩니다. 블로그 문서를 예로 들면, 20대 남성이 해당 문서를 좋아하는 정도를 [0, 1] 사이의 값으로 나타낸 것도 피처라고 할 수 있고, 문서에 포함된 사진의 개수도 피처가 될 수 있습니다. 메타 정보와의 경계성은 모호하나, 저희 팀에서는 한 단계 이상의 정제 과정을 거친 값을 피처로 취급하자'라는 기준을 공유하고 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;고품질의 피처는 곧 고품질의 서비스로 이어집니다. 네이버에서는 더 좋은 사용자 경험을 위해 다양한 피처를 활용해 랭킹을 하고 있으며, 다양한 서비스에서 활용할 수 있게 피처 정보를 제공하는 별도의 서버(Feature Serving Agent, 이하 FSA)를 마련했습니다. 그런데 이 구조는 효과적이지만 성능이 만족스럽지 않다는 문제가 있었습니다.&lt;/p&gt;

&lt;h2 id=""&gt;대량의 단순 조회가 너무 느리다는 문제&lt;/h2&gt;

&lt;h3 id="fsa"&gt;FSA란&lt;/h3&gt;

&lt;p&gt;FSA는 Redis와 같은 일종의 키-값 저장소입니다. 블로그/카페 문서의 피처를 계산해 DB에 적재하고, 문서의 ID로 피처를 조회할 수 있게 합니다. 이때 고품질 피처를 계산하기 위해 ML 모델을 사용해 배치로 계산합니다.&lt;/p&gt;

&lt;p&gt;FSA의 기본 동작은 최대 800개의 문서 ID를 받아 각 문서의 피처 정보를 제공하는 것입니다. Redis와 같은 기존 솔루션을 이용하면 빠르게 개발할 수 있지만 FSA를 사용하게 된 2가지 이유가 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;무한대의 scale-out 필요성: 최대 800개의 문서에 대해서 &lt;code&gt;mget&lt;/code&gt; 수행 시 CPU 사용, 응답 시간의 측면에서 성능이 더 뛰어나며, 무엇보다 '이론상' 무한대로 scale-out이 가능한 인하우스 분산 DB를 사용하고자 했습니다. Redis 클러스터는 안정성을 이유로 scale-out 상한이 존재합니다.&lt;/li&gt;
&lt;li&gt;운영 유연성 확보: 다양한 곳에서 쉽게 사용하고 신뢰성 있는 서비스를 제공하기 위해서는 호출처 트래킹, 트래픽 컨트롤, 비즈니스 로직 추가 등의 추가 기능이 필요합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=""&gt;성능 테스트 결과&lt;/h3&gt;

&lt;p&gt;FSA 개발이 완료되고 &lt;a href="https://github.com/naver/ngrinder"&gt;nGrinder&lt;/a&gt;를 이용해 성능을 테스트했습니다. 정확한 성능을 측정하고자 캐시는 사용하지 않았습니다.&lt;/p&gt;

&lt;p&gt;자세한 성능 테스트 환경은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;서버 인스턴스 1대 - 16 CPU 코어(AMD genoa/milan)&lt;/li&gt;
&lt;li&gt;테스트 대상 문서 ID의 개수는 10K, 한 번의 호출당 랜덤으로 800개를 뽑아서 사용&lt;/li&gt;
&lt;li&gt;호출 QPS(query per second)는 85 → 175&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;테스트 결과는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/fc715527-0bd5-4393-90eb-557a3836e6e1.png" alt="d2-1" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/8f9eafca-fb76-4aeb-85da-5bc645694fed.png" alt="d2-2" /&gt;&lt;/p&gt;

&lt;p&gt;성능 테스트에서 살펴보는 지표는 다양하지만, 가장 기본이며 핵심적인 CPU 사용률과 응답 시간을 살펴보겠습니다. CPU 사용률로 적절한 인스턴스 수를 산정할 수 있고, 응답 시간은 곧 서비스 품질로 이어지기 때문입니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CPU 사용률은 17.8%(85qps), 36%(175qps)&lt;/li&gt;
&lt;li&gt;평균 응답 시간은 약 44ms, p99 응답 시간은 약 87ms&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;FSA는 2500qps의 요청을 받을 예정이었기 때문에 이를 바탕으로 필요한 서버 인스턴스 수를 산정해 보겠습니다. 저희 팀은 안정적인 서비스를 위해서 인스턴스당 CPU 사용률을 30% 이하로 맞추고 있습니다. CPU 사용률 1%당 약 4.8qps를 받을 수 있으며, 30%의 사용률은 약 144qps입니다. 인스턴스 1대당 144qps를 받을 수 있으므로 필요한 서버는 최소 17대 이상입니다. CPU 코어로 계산하면 272코어가 됩니다.&lt;/p&gt;

&lt;p&gt;272코어의 리소스는 절대 작은 수치가 아니며, 팀 내 다른 서버의 리소스 사용률과 비교해서 판단해보면 FSA의 로직은 너무 무거웠습니다. 또한, 하위 1% 응답 시간이 87ms임을 보아 분명히 어딘가에 병목이 존재한다고 생각했습니다.&lt;/p&gt;

&lt;h3 id=""&gt;병목 지점 찾기&lt;/h3&gt;

&lt;p&gt;병목 지점을 찾기에 앞서, 왜 병목 지점을 찾는 것이 중요한지 간단하게 짚고 넘어가겠습니다.&lt;/p&gt;

&lt;p&gt;암달의 법칙(Amdahl's law)에 따르면 병렬화 등에 따른 성능 향상은 결국 순차 실행되는 코드의 비율에 제한됩니다. 병렬화를 떠나 실행 시간 관점에서 다시 쉽게 풀어본다면, 이론적으로 얻을 수 있는 최대 속도 향상은 전체 실행 시간 중에서 차지하는 비율로 제한됩니다. 쉽게 말해, 전체 실행 시간의 10%를 차지하는 부분을 최적화해서 2배 빨라졌다고 하더라도 전체를 보면 단 5% 빨라지는 셈입니다.&lt;/p&gt;

&lt;p&gt;결국, 들이는 노력에 비해 크게 성능을 향상시키려면 실행 시간의 대부분을 차지하는 지점을 찾아야 합니다. 이러한 병목 지점을 찾아내는 것이 '프로파일링'입니다. 개발자들은 프로파일링에 다양한 방법을 사용합니다. 여기서는 Python을 기준으로 몇 가지 방법을 소개합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;각 함수의 시작과 끝에서 타임스탬프를 기록해서 확인하기&lt;/p&gt;

&lt;p&gt;가장 원시적이고 적용하기 쉬운 방법입니다. 소규모 프로젝트에서는 꽤 빠르고 효과적일 수 있지만, 불필요하게 코드가 길어지며 프로덕션 환경에서는 수행되지 않아야 하기에 번거로울 수 있습니다. 그뿐 아니라 타임스탬프를 기록하는 부분을 놓칠 수도 있다는 단점이 존재합니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Python에서 기본으로 제공하는 cProfile 라이브러리 사용하기&lt;/p&gt;

&lt;p&gt;Python에서 기본으로 제공하므로 신뢰성이 높으며, C로 구현되어 있어 프로파일러로 인한 오버헤드가 매우 낮다는 장점이 있습니다. 하지만 같이 제공되는 패키지이다 보니 기능이 부족하며, 특히 멀티 스레드 환경에서 취약한 모습을 보입니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://github.com/pyutils/line_profiler"&gt;line_profiler&lt;/a&gt;, &lt;a href="https://github.com/benfred/py-spy"&gt;py-spy&lt;/a&gt;, &lt;a href="https://github.com/sumerc/yappi"&gt;Yappi&lt;/a&gt; 등의 서드파티 라이브러리 사용하기&lt;/p&gt;

&lt;p&gt;각자 사용성에 맞는 프로파일러 라이브러리를 선택할 수 도 있습니다. 어떤 라이브러리를 사용할지 고민하기까지 비용이 든다는 점이 단점으로 작용하나, 큰 효과를 낼 수 있습니다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각 방법의 장단점을 분석한 결과 Yappi를 선택했습니다. 다른 방법을 선택하지 않은 이유는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;cProfile은 메인 스레드만 프로파일링합니다. 따라서 멀티 스레드 환경에서 사용하려면 직접 모든 스레드를 프로파일링하고 결과를 합쳐야 합니다.&lt;/li&gt;
&lt;li&gt;line_profiler는 애너테이션 기반으로, 프로파일링하려는 곳마다 &lt;code&gt;@profile&lt;/code&gt; 코드를 삽입해야 하는 불편함이 존재합니다.&lt;/li&gt;
&lt;li&gt;py-spy는 샘플링 기반의 프로파일러로, &lt;a href="https://docs.python.org/ko/3.13/library/profile.html#what-is-deterministic-profiling"&gt;결정론적 프로파일링&lt;/a&gt;이 지원되지 않습니다. 저희는 서비스 환경에서 사용하진 않기 때문에 후보에서 제외했습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;정리하면 다음과 같습니다.&lt;/p&gt;

&lt;table&gt;  
&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;방법/도구&lt;/th&gt;  
&lt;th&gt;장점&lt;/th&gt;  
&lt;th&gt;단점&lt;/th&gt;  
&lt;th&gt;결정론적 프로파일링&lt;/th&gt;  
&lt;th&gt;멀티 스레드 지원&lt;/th&gt;  
&lt;th&gt;사용 편의성&lt;/th&gt;  
&lt;/tr&gt;  
&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;수동 타임스탬프 삽입&lt;/td&gt;  
&lt;td&gt;구현이 간단함, 빠른 실험에 적합&lt;/td&gt;  
&lt;td&gt;코드가 지저분해짐, 번거로움, 실수할 가능성 있음&lt;/td&gt;  
&lt;td&gt;예(수동)&lt;/td&gt;  
&lt;td&gt;가능(수동)&lt;/td&gt;  
&lt;td&gt;낮음&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;cProfile&lt;/td&gt;  
&lt;td&gt;표준 라이브러리, 오버헤드 적음, 신뢰성 높음&lt;/td&gt;  
&lt;td&gt;멀티 스레드 지원 미흡, 기능 제한 있음&lt;/td&gt;  
&lt;td&gt;예&lt;/td&gt;  
&lt;td&gt;제한적&lt;/td&gt;  
&lt;td&gt;중간&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;line_profiler&lt;/td&gt;  
&lt;td&gt;라인 단위 상세 정보 제공&lt;/td&gt;  
&lt;td&gt;@profile 삽입 필요, 코드 수정 필요&lt;/td&gt;  
&lt;td&gt;예&lt;/td&gt;  
&lt;td&gt;미지원&lt;/td&gt;  
&lt;td&gt;낮음&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;py-spy&lt;/td&gt;  
&lt;td&gt;비침습적, 라이브 환경에서 사용 가능, 설치 쉬움&lt;/td&gt;  
&lt;td&gt;샘플링 기반, 결정론적 프로파일링 미지원&lt;/td&gt;  
&lt;td&gt;아니오&lt;/td&gt;  
&lt;td&gt;예&lt;/td&gt;  
&lt;td&gt;높음&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;Yappi&lt;/td&gt;  
&lt;td&gt;멀티 스레드 완전 지원, 결정론적, 설치 쉬움&lt;/td&gt;  
&lt;td&gt;외부 패키지 설치 필요&lt;/td&gt;  
&lt;td&gt;예&lt;/td&gt;  
&lt;td&gt;예&lt;/td&gt;  
&lt;td&gt;높음&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;h2 id="yappifastapi"&gt;Yappi를 접목한 FastAPI 프로파일링&lt;/h2&gt;

&lt;p&gt;그럼 이제 실제로 Yappi를 설정하고 프로파일링해보겠습니다. 기본적인 설치 방법 및 사용 방법은 &lt;a href="https://github.com/sumerc/yappi"&gt;Yappi GitHub&lt;/a&gt;를 참고합니다. 여기서는 FastAPI에 적용하는 방법을 설명하겠습니다.&lt;/p&gt;

&lt;p&gt;FastAPI의 미들웨어 기능을 이용하면 쉽고 깔끔하게 적용할 수 있습니다. 아래는 실제로 사용되는 코드입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-python"&gt;# middleware/yappi_profile.py
import os  
from contextvars import ContextVar

import yappi  
from starlette.middleware.base import BaseHTTPMiddleware  
from starlette.responses import Response

ctx_id: ContextVar[int] = ContextVar("yappi_context")


def get_context_id() -&amp;gt; int:  
    try:
        return ctx_id.get()
    except LookupError:
        return -1


yappi.set_tag_callback(get_context_id)


class YappiProfileMiddleware(BaseHTTPMiddleware):  
    async def dispatch(self, request, call_next) -&amp;gt; Response:
        ctx_id.set(id(request))
        with yappi.run():
            result = await call_next(request)

        stats = yappi.get_func_stats(tag=ctx_id.get())
        stats.sort(sort_type="ttot")
        stats.strip_dirs()
        if not stats.empty():
            if "YAPPI_PROFILE_CONSOLE" in os.environ:
                stats.print_all()
            stats.save("yappi.prof", type="pstat")

        return result
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;멀티 스레드 환경을 위해 &lt;code&gt;get_func_stats&lt;/code&gt; 함수를 사용했고, 프로파일링한 결과물을 &lt;code&gt;yappi.prof&lt;/code&gt; 파일로 저장하거나 별도의 환경 변수(&lt;code&gt;YAPPI_PROFILE_CONSOLE&lt;/code&gt;)로 콘솔에 출력하도록 했습니다.&lt;/p&gt;

&lt;p&gt;미들웨어는 다음과 같이 등록합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-python"&gt;# main.py
import os

from fastapi import FastAPI


app = FastAPI()

if "YAPPI_PROFILE_ENABLE" in os.environ and os.environ["YAPPI_PROFILE_ENABLE"] == "1":  
    from middleware.yappi_profile import YappiProfileMiddleware

    app.add_middleware(YappiProfileMiddleware)


if __name__ == "__main__":  
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8080)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;저희는 Yappi를 필요에 따라 쉽게 활성화하거나 비활성화하길 원했습니다. 실 서비스 환경이나 부하 테스트 환경에서는 프로파일링으로 인한 영향이 발생하지 않아야 합니다. 환경 변수로 제어하여 필요할 때만 Yappi를 활성화하도록 설정했습니다.&lt;/p&gt;

&lt;p&gt;다음과 같이 실행하면 Yappi를 활성한 채로 서버를 실행할 수 있고, 마지막 API 요청에 대한 프로파일링 결과를 &lt;code&gt;yappi.prof&lt;/code&gt; 파일로 확인할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-shell"&gt;$ YAPPI_PROFILE_ENABLE=1 YAPPI_PROFILE_CONSOLE= python -m main
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href="https://github.com/jiffyclub/snakeviz"&gt;SnakeViz&lt;/a&gt;와 같은 시각화 도구를 이용하면 프로파일링 결과를 더 쉽게 확인할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-shell"&gt;$ snakeviz yappi.prof
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/559f0d3f-f954-47d6-a876-a3e521027825.png" alt="d2-3" /&gt;&lt;/p&gt;

&lt;p&gt;이로써 프로파일링할 준비는 모두 완료된 셈입니다. 이제 프로파일링로 실제 성능 개선을 이뤄낸 사례를 소개하겠습니다.&lt;/p&gt;

&lt;h2 id="yappi"&gt;Yappi 프로파일링을 이용한 최적화 결과&lt;/h2&gt;

&lt;p&gt;먼저 처음 프로파일링을 시도했을 때의 결과를 살펴보겠습니다. 프로파일링을 하고 가장 상위 흐름인 &lt;code&gt;APIRouter.__call__&lt;/code&gt;부터 살펴보면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/08cb64e8-2f1d-4867-b544-6144add32174.png" alt="d2-4" /&gt;&lt;/p&gt;

&lt;p&gt;이 결과를 보고 API 응답 결과를 만들어내는 곳인 &lt;code&gt;serialize_response&lt;/code&gt; 부분이 가장 큰 병목이라고 판단했습니다. 해당 부분을 살펴보니 Python 딕셔너리 타입으로 반환하는 것이 확인되었고 &lt;a href="https://fastapi.tiangolo.com/advanced/custom-response/#use-orjsonresponse"&gt;FastAPI&lt;/a&gt; 가이드에 따라 &lt;code&gt;ORJsonResponse&lt;/code&gt;로 변경했습니다.&lt;/p&gt;

&lt;p&gt;그 결과, JSON으로 직렬화할 수 있는지 확인하는 &lt;code&gt;jsonable_encoder&lt;/code&gt; 부분이 없어진 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/799a4cfa-c45d-46ae-af70-6368a8a6f59c.png" alt="d2-5" /&gt;&lt;/p&gt;

&lt;p&gt;변경 후 다시 로컬에서 테스트 해봤을 때 응답 시간이 약 12% 정도 개선되는 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;위의 프로파일링 결과만 보면 이제 더 이상 최적화할 만한 구석이 없을 것처럼 느껴지겠지만, 주의해야 할 점이 있습니다. &lt;code&gt;async&lt;/code&gt;로 선언된 함수를 &lt;code&gt;await&lt;/code&gt;로 기다리는 경우, 자식 함수의 실행 시간이 부모보다 더 긴 것처럼 나타날 수 있습니다. 따라서 실제 우리가 작성한 비동기 로직의 호출 시점부터 살펴볼 필요가 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/346a26db-25c4-4bc4-a9a5-c59303db3ff3.png" alt="d2-6" /&gt;&lt;/p&gt;

&lt;p&gt;실제로 async/await로 감싼 부분에서 &lt;code&gt;cumtime&lt;/code&gt;이 연결되지 않는 것을 확인할 수 있었습니다(SnakeViz는 기본적으로 &lt;code&gt;cumtime&lt;/code&gt; 기준으로 시각화).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
  &lt;li&gt;cumtime (cumulative time) = 해당 함수 자체 실행 시간 + 그 함수가 호출한 모든 하위 함수 실행 시간의 총합&lt;/li&gt;
  &lt;li&gt;tottime (total time) = 해당 함수 자체 실행 시간(하위 함수 호출 시간은 제외)&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;다시 돌아와서, 위의 결과를 토대로 계속 최적화해보면 &lt;code&gt;render_docs&lt;/code&gt; 부분에서 의미없는 deepcopy가 수행되는 것을 볼 수 있습니다. DB 칼럼명을 응답의 필드명으로 바꾸는 과정에서 간편하게 바꾸고자 &lt;code&gt;asdict&lt;/code&gt;를 사용한 것이 원인이었습니다.&lt;/p&gt;

&lt;p&gt;실제 필요한 필드를 정의하고 하드 코딩해, 비싼 연산인 deepcopy의 수행을 막고 다시 프로파일링했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/dbffb937-a6a0-4e21-ac8a-c12048e6dcaa.png" alt="d2-7" /&gt;&lt;/p&gt;

&lt;p&gt;로컬에서 테스트해본 결과 응답 시간은 약 50%가 단축되었습니다. 특히나 FSA는 많은 개수의 아이템을 반환했기에 이 최적화는 큰 효과를 볼 수 있었습니다. 그뿐 아니라 정말 필요한 필드만 남기고 모두 제외하여 네트워크 사용량을 줄이는 효과도 조금이나마 얻을 수 있었습니다.&lt;/p&gt;

&lt;p&gt;이제 정말로 끝난 줄 알았지만... 아직 주의해야 할 부분이 하나 더 남았습니다. &lt;code&gt;asyncio.gather()&lt;/code&gt;로 호출되는 부분은 아예 caller-callee 사이에 호출 그래프가 끊긴다는 점을 주의해야 합니다.&lt;/p&gt;

&lt;p&gt;실제 프로젝트 코드에서는 다음과 같은 부분이 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-python"&gt;async def retrieve_items(self):  
    # 편의상 생략
    retrievers = [
        BlogRetriever(ids).retrieve(),
        CafeRetriever(ids).retrieve(),
    ]
    results = await asyncio.gather(*retrievers)
    return list(chain.from_iterable(results))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 코드의 프로파일링 결과를 보면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/1f425464-24ba-4793-89f4-8708906a3c1a.png" alt="d2-8" /&gt;&lt;/p&gt;

&lt;p&gt;유심히 살펴보면 &lt;code&gt;retrieve()&lt;/code&gt; 부분이 존재하지 않습니다. 아쉽게도 &lt;code&gt;asyncio.gather()&lt;/code&gt;를 사용하면 호출 스택 lineage가 끊기므로, 이 부분은 따로 확인하거나 프로파일링할 때만이라도 &lt;code&gt;await&lt;/code&gt;으로 바꿔야 합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-python"&gt;async def retrieve_items(self):  
    # 편의상 생략
    return await BlogRetriever(ids, verbose=self.service_context.is_debug).retrieve() + \
        await CafeRetriever(ids, verbose=self.service_context.is_debug).retrieve()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이렇게 바꾸면 다음과 같이 프로파일링 결과가 풍부해진 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/20373e31-b5a1-43b9-9f27-194285c2172b.png" alt="d2-9" /&gt;&lt;/p&gt;

&lt;p&gt;이를 바탕으로 최적화한 부분은 DB 조회 결과를 Python 딕셔너리 자료 구조로 변경하는 부분입니다. 기존 코드는 다음과 같았습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-python"&gt;from google.protobuf.json_format import MessageToJson

parsed_row = json.loads(MessageToJson(response))  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;저희가 사용하는 인하우스 분산 DB는 gRPC 프로토콜로 데이터를 주고 받는데, 이때 DB를 호출하는 레이어에서 protobuf → JSON → Python 딕셔너리의 단계를 거쳤는데 JSON은 사용되지 않았습니다. 따라서 JSON 변환을 건너뛰고 다음과 같이 바로 Python 딕셔너리로 변환을 시도했습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-python"&gt;from google.protobuf import json_format

parsed_row = json_format.MessageToDict(response)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;그 결과, 다음과 같이 확연하게 개선되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/0333a183-62b1-43ab-a912-2ec11a8c12d2.png" alt="d2-10" /&gt;&lt;/p&gt;

&lt;p&gt;간단하게 로컬에서 테스트한 결과, 응답 시간이 절반으로 줄어들었습니다.(환경에 따라 응답 시간은 달라질 수 있기에 절대적인 수치는 참고만 하시기 바랍니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/ad067748-fe06-4adb-a7b4-fa099ec711ee.png" alt="로컬" /&gt;&lt;/p&gt;

&lt;p&gt;위의 개선된 결과를 바탕으로 다시 높은 트래픽으로 성능을 테스트했습니다. 기존과 환경은 동일하게 구성하고 같은 양의 부하 발생기를 사용했습지만, 응답 시간이 짧아짐에 따라서 더 많은 트래픽이 발생했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/e24407e9-783a-42d3-9317-659348e9e6d7.png" alt="d2-11" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/7604d10c-30b7-4af9-9832-d08bf7d7fd6f.png" alt="d2-12" /&gt;&lt;/p&gt;

&lt;p&gt;실험 결과를 정리해보면 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CPU 사용률은 약 17%(234qps)&lt;/li&gt;
&lt;li&gt;평균 응답 시간은 약 14ms, p99 응답 시간은 약 37ms&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이를 바탕으로 서빙에 필요한 리소스를 다시 산정해 보겠습니다. 해당 서버가 받아야 하는 트래픽은 위에 언급했듯이 2500qps이고, 인스턴스당 CPU 사용률 기준은 30% 이하입니다. CPU 사용률 1%당 약13.8qps를 받을 수 있으며, 30%의 사용률은 약 414qps입니다. 인스턴스 1대당 414 qps를 받을 수 있으므로 필요한 서버는 최소 6대 이상입니다. CPU 코어로 계산하면 96코어가 됩니다.&lt;/p&gt;

&lt;p&gt;기존의 성능 테스트 결과와 비교해 보겠습니다.&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;  
&lt;tr&gt;  
&lt;th&gt;구분&lt;/th&gt;  
&lt;th&gt;최적화 전&lt;/th&gt;  
&lt;th&gt;최적화 후&lt;/th&gt;  
&lt;th&gt;감소량&lt;/th&gt;  
&lt;/tr&gt;&lt;/thead&gt;  
&lt;tbody&gt;  
&lt;tr&gt;  
&lt;td&gt;필요 CPU 코어&lt;/td&gt;  
&lt;td&gt;272&lt;/td&gt;  
&lt;td&gt;96&lt;/td&gt;  
&lt;td&gt;64.7%&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;평균 응답 시간&lt;/td&gt;  
&lt;td&gt;44ms&lt;/td&gt;  
&lt;td&gt;14ms&lt;/td&gt;  
&lt;td&gt;68.2%&lt;/td&gt;  
&lt;/tr&gt;  
&lt;tr&gt;  
&lt;td&gt;p99 응답 시간&lt;/td&gt;  
&lt;td&gt;87ms&lt;/td&gt;  
&lt;td&gt;37ms&lt;/td&gt;  
&lt;td&gt;57.5%&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/tbody&gt;  
&lt;/table&gt;

&lt;p&gt;결과를 나란히 두고 비교해보니 최적화 전후로 상당히 많이 개선된 걸 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;프로파일링을 진행하며 알게된 주의 사항을 다시 정리하고 글을 마치겠습니다.&lt;/p&gt;

&lt;h3 id="yappi"&gt;Yappi 적용 시 주의 사항&lt;/h3&gt;

&lt;h4 id=""&gt;프로파일러 오버헤드&lt;/h4&gt;

&lt;p&gt;Yappi 자체 오버헤드는 작지만, 실시간 트래픽이 몰리는 프로덕션에서는 꺼 두는 편이 안전합니다. 따라서 &lt;code&gt;YAPPI_PROFILE_ENABLE&lt;/code&gt; 같은 플래그로 손쉽게 토글할 수 있도록 미리 설계하는 것이 좋습니다.&lt;/p&gt;

&lt;h4 id="async"&gt;&lt;code&gt;async&lt;/code&gt; 호출 스택 왜곡&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;await&lt;/code&gt; 구간에서 상위 함수보다 하위 함수 &lt;code&gt;cumtime&lt;/code&gt;이 길게 표시될 수 있습니다. 특히 &lt;code&gt;asyncio.gather()&lt;/code&gt;는 호출 그래프 단절을 일으키므로 필요하면 프로파일링 세션에서는 순차 &lt;code&gt;await&lt;/code&gt;로 임시 교체하는 것이 좋습니다.&lt;/p&gt;

&lt;h2 id=""&gt;마치며&lt;/h2&gt;

&lt;p&gt;Yappi를 사용함으로써 빠른 시간 안에 성능을 최적화할 수 있다는 사실이 놀라웠습니다. 단 50여 줄짜리 미들웨어로 숨어있던 비효율을 빠르게 찾아냈고, 불과 20여 줄의 코드 수정만으로 리소스 사용 약 65% 절감, 응답 시간 약 60% 단축 등 드라마틱한 개선을 얻었습니다. 실제로 코드 작성, 프로파일링 결과 분석, 성능 테스트까지 최적화에 시간은 이틀도 걸리지 않았습니다.(사실 이 글을 작성하는 시간이 더 오래 걸렸습니다.)&lt;/p&gt;

&lt;p&gt;Python은 간결한 문법 덕에 아이디어를 곧바로 코드로 옮길 수 있어 많이 주목받고 있습니다. 하지만 그만큼 무심코 작성한 한 줄로 인해 예상치 못한 병목이 되기 쉽습니다.&lt;/p&gt;

&lt;p&gt;Python으로 빠르게 만들었다면 Yappi로 빠르게 개선해보는 건 어떨까요? JetBrains의 PyCharm이 Yappi를 기본 프로파일러로 채택했을 만큼, 신뢰성과 안정성은 이미 검증되었습니다. 여러분도 최소한의 노력과 시간만으로도 예상 이상의 성과를 얻을 수 있습니다.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>홈피드: 네이버의 진입점에서 추천 피드를 외치다! 추천 피드 도입 고군분투기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/0207214" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/0207214</id>
    <updated>2025-06-26T16:55:00Z</updated>
    <content type="html">&lt;p&gt;네이버 홈피드는 검색 홈 하단에서 사용자에게 개인화된 콘텐츠를 추천하는 피드 서비스입니다. 이 글에서는 사용자에게 보다 나은 추천을 제공하기 위해 고민하고 구현한 핵심 기술을 다루고자 합니다. 주요 내용은 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;홈피드 서비스 톺아보기&lt;/strong&gt;: 홈피드 전반의 구조와 구성 요소, 다양한 콘텐츠 재료, 그리고 대규모 언어 모델(LLM, large language model)을 활용한 개인화 추천 시스템  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;홈피드 추천 랭킹 로직 구성&lt;/strong&gt;: 다양한 특징의 콘텐츠를 효과적으로 조합하는 방법, 클릭 외에도 고려해야 할 만족도 지표, 추천의 다양성을 확보하기 위한 전략  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;사용자 맞춤형 첫 번째 콘텐츠 선정 방법&lt;/strong&gt;: 첫 번째 노출 콘텐츠(Rank1)의 중요성과 사용자 행동 및 관심사 기반 리트리버 모델의 최적화 방안&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;홈피드 개발 과정에서 마주했던 기술적 도전과 그에 대한 해결 방안을 함께 살펴보겠습니다.&lt;/p&gt;

&lt;h2 id="1"&gt;1. 홈피드 서비스 톺아보기&lt;/h2&gt;

&lt;h3 id=""&gt;네이버의 홈피드 서비스는?&lt;/h3&gt;

&lt;p&gt;홈피드는 사용자의 채널 구독, 읽은 문서, 검색 이력 등 네이버 내 활동을 기반으로 맞춤 콘텐츠를 제공하는, 네이버 검색 홈 하단에 위치한 개인화 추천 서비스입니다. 다양한 콘텐츠를 사용자 맞춤으로 제공하여, 검색 홈의 가치를 높이고 네이버의 여러 서비스로 이어지는 연결 고리 역할을 수행합니다.&lt;/p&gt;

&lt;p&gt;네이버의 첫인상인 검색 홈에서 즐길 수 있는 콘텐츠 경험을 풍부하게 만드는 것이 홈피드의 궁극적인 목표입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;현재 홈피드에서는 블로그, 카페, 포스트뿐 아니라 네이버TV, 인플루언서, 프리미엄 콘텐츠, 클립 등 다양한 콘텐츠를 개인화해 제공하고 있으며, 사용자의 취향에 맞춘 콘텐츠 묶음 형태로도 제공하고 있습니다.&lt;/p&gt;

&lt;p&gt;처음 출시된 2023년 11월 이후 사용자 반응도 긍정적입니다. 일간 사용자 수는 출시 시점 대비 약 6배, 클릭 수는 약 8배 증가하며 꾸준히 성장하고 있습니다.&lt;/p&gt;

&lt;h3 id=""&gt;맛있는 피드를 위한 재료&lt;/h3&gt;

&lt;p&gt;홈피드 추천은 두 가지 핵심 재료를 바탕으로 다양한 콘텐츠 중 무엇을 보여줄지 결정합니다.&lt;/p&gt;

&lt;p&gt;먼저 블로그, 카페, 네이버TV, 포스트, 클립 등 다양한 콘텐츠를 모은 &lt;strong&gt;콘텐츠 풀(content pool)&lt;/strong&gt;이 있으며, 개인화의 기반이 되는 사용자의 클릭 로그, 구독 정보, 검색 이력, 주제 선호도, 피드백 반응 등으로 구성된 &lt;strong&gt;사용자 컨텍스트(user context)&lt;/strong&gt;가 함께 활용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/2.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이 두 가지 정보를 바탕으로, &lt;strong&gt;리트리버(retriever)&lt;/strong&gt;가 사용자에게 적합한 콘텐츠 후보를 수집하고, &lt;strong&gt;랭커(ranker)&lt;/strong&gt;가 이들에 순위를 매깁니다. 특히, 홈피드에서 가장 먼저 노출되는 Rank1 콘텐츠는 사용자 만족도에 큰 영향을 주기 때문에, 기존 랭킹 모델과는 별도로 &lt;strong&gt;Rank1 최적화 도구(Rank1 optimizer)&lt;/strong&gt;를 활용해 더욱 정교하게 선정합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/3.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;위 흐름 중 '리트리버'를 조금 더 자세히 살펴보겠습니다. 홈피드에서는 목적에 따라 다양한 리트리버를 활용합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;구독 기반&lt;/strong&gt;: 사용자가 구독한 채널이나 카페 게시판의 문서 추천&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;키워드 기반&lt;/strong&gt;: 클릭·검색 이력으로 추출한 관심 키워드 또는 주제군에 해당하는 인기 문서 추천&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;인기도 기반&lt;/strong&gt;: 사용자의 주제 선호도와 유사한 성별·연령대 사용자에게 인기 있는 문서 추천&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;소비 이력 기반&lt;/strong&gt;: 사용자가 클릭한 문서와 유사한 콘텐츠를 찾기 위해 EASE(Embarrassingly Shallow Autoencoders), two-tower 모델 등 활용&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;검색 이력 기반&lt;/strong&gt;: 사용자의 최근 검색어와 직접적으로 관련된 문서 추천&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;키워드 기반 리트리버는 사용자들에게 인기가 있는 키워드와 그에 매칭되는 인기 문서들을 후보 풀로 사용하고, 검색 이력 리트리버는 사용자가 검색을 통해 직접적인 사용성을 보였던 주제와 연관된 문서를 사용한다는 점이 차이가 있습니다.&lt;/p&gt;

&lt;h3 id=""&gt;신선한 제철 재료 추가하기 - 최근 검색/소비 반영&lt;/h3&gt;

&lt;p&gt;'신선한 제철 재료 추가하기'라는 제목처럼, 이번에는 &lt;strong&gt;사용자의 가장 최근 사용성을 고려해 행동에 즉각 반응하는 리트리버&lt;/strong&gt; 구축 사례를 소개하겠습니다.&lt;/p&gt;

&lt;p&gt;사용자는 네이버 앱에 접속해 콘텐츠를 소비하거나 검색하는 등 다양한 활동을 합니다. 이러한 실시간 사용성을 홈피드에 즉시 반영하면 더욱 만족스러운 개인화 결과를 제공할 수 있지 않을까 고민하며 리트리버 고도화를 진행했습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;After Search&lt;/strong&gt;: 사용자가 최근에 검색한 키워드와 연관된 문서 추천&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Click2Click&lt;/strong&gt;: 사용자가 가장 최근에 클릭한 문서와 유사한 콘텐츠를 content-based 방식으로 추천&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="aftersearch"&gt;After Search&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;After Search&lt;/strong&gt;는 사용자가 하루 이내에 검색한 키워드와 연관된 문서를 추천합니다. 실시간 검색 로그를 기반으로, 검색 직후 수 초 이내에 관련 콘텐츠가 홈피드에 노출될 수 있도록 구성했습니다.&lt;/p&gt;

&lt;p&gt;전체 추천 파이프라인은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/5.png" alt="" /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;검색 로그에서 주요 키워드 추출&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;p&gt;사용자별 검색 로그에서 추천에 적합한 탐색형 또는 시의성 높은 키워드를 식별합니다. 초기에는 모든 검색어를 seed로 사용했지만, 날씨 등 일상 정보성 키워드는 추천 문서 품질이 낮다는 한계가 있었습니다. 이를 개선하기 위해 네이버 검색의 쿼리 베이스 데이터를 연동해 키워드의 주제 및 검색 의도를 분류하고, 탐색형/시의성 질의에 한해 문서를 선정하도록 필터링합니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;사용자 선호도를 반영하여, 사용자가 꾸준히 소비하는 키워드는 순위를 높이고 이미 충분히 소비했거나 관심이 낮은 키워드는 페널티를 부여합니다.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;세션 내에서 이미 노출된 키워드나 이미 노출된 문서에서 추출된 키워드는 제외해 노출 피로도를 줄입니다.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;연관 문서 선정&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;키워드에 대한 연관 문서는 TF-IDF와 TSDAE 모델을 활용해 선정합니다. 단, 이 모델들은 키워드-문서 간 연관성(relevance)만을 기준으로 하기 때문에, 추천 품질이 낮은 문서가 추출된다는 한계가 있습니다.&lt;/li&gt;
&lt;li&gt;사용자 피드백 기반 피처, 검색어별 사용자 반응이 좋았던 문서 정보를 함께 반영해 이를 보완합니다.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;정리하자면, After Search는 검색 사용성을 활용하지만, 단순 검색 결과가 아니라 사용자 선호 키워드를 중심으로 피드 내 선호 문서를 추출한다는 것이 차별화된 강점입니다.&lt;/p&gt;

&lt;p&gt;현재 사용 중인 TF-IDF, TSDAE 기반 연관 문서 선정 로직은 향후 LLM 기반 임베딩 모델로 고도화할 계획입니다.&lt;/p&gt;

&lt;h4 id="click2click"&gt;Click2Click&lt;/h4&gt;

&lt;p&gt;Click2Click은 사용자가 하루 이내에 클릭한 문서 중 가장 최근 이력과 연관된 콘텐츠를 추천합니다.&lt;/p&gt;

&lt;p&gt;최신 클릭 이력에 즉각 반응하는 추천을 실시간으로 홈피드에 제공하기 위해 문서의 제목과 본문을 활용하는 content-based 리트리버를 도입하고, 홈피드 문서 풀 전체에 대해 임베딩을 생성한 뒤, 사용자의 최신 클릭 문서를 seed로 삼아 가장 유사한 N개의 문서를 추천 후보군으로 구성합니다.&lt;/p&gt;

&lt;p&gt;문서 임베딩에는 네이버 뉴스 서비스에서도 사용 중인 NRMS(Neural News Recommendation with Multi-head Self-attention) 모델을 활용하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/6.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;NRMS 모델은 다음과 같은 방식으로 학습합니다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;각 문서 제목에서 주요 의미를 함축하는 단어를 self-attention 방식으로 포착하여 문서 임베딩을 생성합니다.  &lt;/li&gt;
&lt;li&gt;사용자의 소비 이력에서는 선호도를 반영하는 핵심 문서를 포착해 사용자 임베딩을 구성합니다.  &lt;/li&gt;
&lt;li&gt;그 결과, 연관성이 높은 문서일수록 내부에서 중요한 단어에 더 높은 가중치가 반영되도록 임베딩이 학습됩니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Click2Click은 사용자 벡터를 따로 생성하지 않고, 최근 클릭한 문서의 아이템 벡터를 기준으로 ANN(Approximate Nearest Neighbor) 검색을 수행하여 유사 문서를 추천합니다.&lt;/p&gt;

&lt;h4 id=""&gt;각 리트리버 도입에 따른 사용자 지표 변화&lt;/h4&gt;

&lt;p&gt;After Search와 Click2Click은 모두 홈피드 내 사용자 행동 변화를 이끌어냈지만, 서로 다른 타겟 사용자군에서 효과를 발휘했다는 점을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;네이버 내부에서는 사용자를 홈피드 이용 정도에 따라 &lt;strong&gt;light&lt;/strong&gt;, &lt;strong&gt;medium&lt;/strong&gt;, &lt;strong&gt;heavy&lt;/strong&gt; 그룹으로 나누어 지표를 분석하고 있는데, After Search는 특히 클릭 사용성이 거의 없던 light 사용자군에서 지표가 유의미하게 상승하는 결과를 얻었습니다. 클릭 기반 피처가 부족한 사용자에게 &lt;strong&gt;검색 사용성&lt;/strong&gt;을 활용해 추천 경험을 개선할 수 있었다는 점에서 의미 있는 결과였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/7.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;반면 Click2Click은 이미 홈피드 사용성이 있는 사용자군, 특히 활발하게 이용하는 사용자에게서 지표 향상 효과가 두드러지게 나타났습니다. After Search와는 상반된 타겟 효과를 보이며, 사용자 그룹별로 상이한 전략이 필요함을 시사합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/8.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이처럼 두 리트리버 사례에서, 사용자가 하루 이내에 보여준 최신 사용성을 적극적으로 반영함으로써 홈피드 개인화 경험을 효과적으로 향상시킬 수 있음을 확인했습니다.&lt;/p&gt;

&lt;h3 id="llm"&gt;적절한 익힘 정도를 위해 LLM 활용하기&lt;/h3&gt;

&lt;p&gt;마지막으로, LLM을 활용해 홈피드 모델을 고도화한 사례를 소개합니다.&lt;/p&gt;

&lt;h4 id="llmairscout"&gt;LLM을 활용한 사용자 태그 생성 - AiRScout&lt;/h4&gt;

&lt;p&gt;네이버에서는 AiRScout라는 프로젝트를 진행하고 있습니다. 이 프로젝트명은 추천 시스템 이름인 AiRS와 사용자 맥락(context of user tag)을 결합해 만든 것으로, 사용자의 맥락을 담은 태그 정보를 생성하는 것을 목표로 합니다. 이를 위해서 LLM을 활용해 더욱 풍부한 사용자 맥락을 추출하는 실험을 진행했습니다.&lt;/p&gt;

&lt;p&gt;AiRScout의 로직은 사용자의 검색 로그를 수집하는 것에서 시작됩니다. 예를 들어, 사용자가 "뉴진스"라는 키워드를 검색한 후 세 개의 문서를 클릭했다고 가정해보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/9.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;이 클릭 이력을 기반으로 LLM에 프롬프트를 입력해, 사용자의 직접적인 관심사를 반영한 새로운 키워드를 생성합니다. 예시에서는 LLM이 "뉴진스 supernatural 뮤비"라는, 기존 검색어보다 더 구체적이고 선호도가 반영된 키워드를 생성합니다. 이렇게 생성된 사용자 태그 정보는 앞서 소개한 After Search의 입력 재료로 활용할 수 있습니다. 기존 After Search 로직에서는 단순히 "뉴진스"라는 키워드만을 기반으로 연관 문서를 추천했다면, 이제는 AiRScout를 통해 생성된 맥락 기반 키워드를 함께 활용함으로써 사용자의 관심사를 더욱 정밀하게 반영한 추천이 가능해집니다.&lt;/p&gt;

&lt;h4 id="llm"&gt;LLM을 활용한 주제 분류기&lt;/h4&gt;

&lt;p&gt;두 번째 사례는 홈피드에 적용한 주제 분류기에 대한 내용입니다.&lt;/p&gt;

&lt;p&gt;홈피드에서 사용되는 문서의 수는 매우 방대하며, 다양한 서비스에서 유입되기 때문에 모든 문서에 동일한 주제 체계를 일관되게 적용하기 어려운 구조였습니다. 따라서, 인터랙티브 광고 협회(Interactive Advertising Bureau)에서 제안하는 IAB 주제 체계를 도입하고, 모든 홈피드 문서에 대해 LLM 기반의 주제 분류 모델을 적용했습니다.&lt;/p&gt;

&lt;p&gt;문서의 제목과 본문을 입력값으로 활용하고, LLM이 해당 문서에 적합한 주제를 출력하도록 학습합니다. 이때, 주제 값만을 정확히 생성하도록 하기 위해 생성 가능한 토큰의 범위를 제한하여 모델이 특정한 범주 내에서 탐색하도록 구성했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/10.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;위 내용의 자세한 분류 방식과 모델 구조에 대해서는 &lt;a href="https://d2.naver.com/helloworld/5152301"&gt;검색과 피드의 만남: LLM으로 완성하는 초개인화 서비스&lt;/a&gt;에서 더 깊게 다루고 있습니다.&lt;/p&gt;

&lt;h2 id="2"&gt;2. 홈피드 추천 랭킹 로직 구성하기&lt;/h2&gt;

&lt;p&gt;이제 홈피드 추천 랭킹 로직을 구성하면서 직면했던 어려움과 이를 해결하기 위해 적용한 접근 방식을 모아 소개하겠습니다. 주요 과제는 다음과 같았습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;홈피드에 포함되는 콘텐츠가 매우 다양함&lt;/strong&gt;: 홈피드는 600개 이상의 카테고리, 20여 종의 리트리버, 10여 개의 서비스에서 유입된 콘텐츠로 구성되어 있으며, 이를 하나의 피드 안에서 통합된 기준으로 랭킹하는 것이 중요한 문제였습니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;사용자의 클릭 확률뿐 아니라, 콘텐츠에 대한 만족 확률까지 함께 예측해야 함&lt;/strong&gt;: 클릭 기반 학습만으로는 사용자 경험을 충분히 설명하기 어려웠기 때문에, 만족도를 함께 고려한 랭킹이 필요했습니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;정확한 추천과 함께 콘텐츠의 다양성까지 확보해야 함&lt;/strong&gt;: 사용자의 탐색을 유도하면서도 다양한 주제와 유형의 콘텐츠가 균형 있게 노출되어야 했습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이러한 과제를 어떻게 해결했는지 각 항목별로 설명하겠습니다.&lt;/p&gt;

&lt;h3 id="dcn"&gt;다양한 특징의 콘텐츠를 어떻게 섞어줄까? - DCN 랭커&lt;/h3&gt;

&lt;p&gt;홈피드에는 다양한 콘텐츠가 포함되어 있기 때문에, 사용자 선호도 및 콘텐츠 특성을 함께 반영할 수 있는 랭커가 필요했습니다. 이를 위해 사용자 피처(선호/비선호 등)와 콘텐츠 피처(인기도, 품질 등)를 추출한 뒤, 이를 효과적으로 학습할 수 있는 모델로 DCN 랭커를 도입했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/11.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;DCN 랭커는 2020년 Google Research 논문에서 제안된 구조로, 피처 간의 상호작용을 학습하여 새로운 피처를 생성하고 이를 통해 더욱 정교한 예측을 가능하게 하는 랭커입니다. DCN 구조는 다음과 같이 두 가지 버전으로 나뉩니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Stacked 버전: 피처를 교차하여 각 레이어를 통과시킨 후, deep neural layer를 거쳐 임베딩을 생성하고 학습&lt;/li&gt;
&lt;li&gt;Parallel 버전: 피처를 교차하는 레이어와 기존 피처를 그대로 학습하는 deep neural layer를 병렬로 처리한 뒤, 임베딩을 병합(concatenate)하여 학습에 활용&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/12.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;DCN V2: Improved Deep &amp;amp; Cross Network and Practical Lessons for Web-scale Learning to Rank Systems ‘20&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;두 구조를 비교해보고 더 높은 성능을 보이는 Stacked 구조를 기반으로 온라인 A/B 테스트를 진행했고, 테스트 결과 클릭 수, 클릭률(CTR) 등 주요 지표가 기존 리니어 랭커 대비 유의미하게 상승하는 것을 확인했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/13.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id="mde"&gt;피드의 만족도가 클릭뿐인가요? - MDE 랭커&lt;/h3&gt;

&lt;p&gt;클릭 확률만으로 학습된 랭커는 종종 유머성 콘텐츠처럼 클릭률은 높지만 만족도가 낮은 콘텐츠의 노출량을 증가시키는 문제가 있었습니다. 이에 따라, 사용자의 만족도까지 함께 예측하는 모델이 필요하다는 요구가 생겼고 이를 해결하기 위해 MDE(Multi Deep Experts) 랭커를 개발했습니다.&lt;/p&gt;

&lt;p&gt;MDE 랭커는 사용자의 클릭 확률과 함께 만족 확률도 함께 예측하는 모델입니다. 여기서 '만족'은 체류 시간이 긴 경우로 정의했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/14.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;MDE 랭커의 기본 구조는 MMoE(Multi-gate Mixture of Expert) 아키텍처에서 차용했습니다. MMoE는 다중 목적(Multi-objective) 학습을 위한 모델로, 2019년 YouTube 추천 시스템에 적용되어 논문으로 발표된 구조입니다. 각 태스크(task)에 대해 별도의 레이어를 두고, 게이트(gate) 레이어에서 각 태스크에 대한 학습 가중치를 조절하는 방식입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/15.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class="caption"&gt;Recommending what video to watch next: a multitask ranking system ‘19&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;MDE 개발 과정에서는 다음과 같은 다양한 아키텍처를 비교 실험했습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;① DCN 기반 multi-head 구조: DCN 모델에서 click과 duration을 각각 학습&lt;/li&gt;
&lt;li&gt;② MMoE 구조 기반 shared bottom 위에 expert layer를 vanilla DNN 으로 학습하는 모델&lt;/li&gt;
&lt;li&gt;③ shared bottom 없이 expert layer만 DCN으로 학습한 모델(&lt;strong&gt;MDE 랭커&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/16.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;③ shared bottom 없이 expert layer만 DCN으로 학습한 모델이 오프라인 실험에서 가장 뛰어난 성능을 보여 MDE 랭커 모델로 채택했으며, 이후 실행한 온라인 A/B 테스트에서도 기존 DCN 랭커 대비 신규 사용자 수, 클릭 사용자 비율, 클릭률(CTR) 등 주요 지표가 상승했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/17.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id=""&gt;다양하게 추천해보자&lt;/h3&gt;

&lt;p&gt;정확한 추천 외에도, 사용자가 다양한 주제의 콘텐츠를 발견하고 탐색할 수 있도록 하는 것이 중요합니다. 이를 위해 추천 결과의 분포를 조정하는 calibration 로직을 도입했습니다.&lt;/p&gt;

&lt;p&gt;일반적으로 랭커는 학습 데이터의 특성에 따라 특정 주제의 콘텐츠가 과다 노출되는 경향이 있으며, 실제 사용자 소비 비율과 추천 결과의 비율이 일치하지 않는 경우가 자주 발생합니다. 예를 들어, 랭커가 패션과 여행 카테고리를 50:50으로 추천하더라도, 실제 사용자의 소비 비율이 패션 70%, 여행 30%라면 이러한 불균형을 조정해줄 필요가 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/18.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;calibration은 Netflix에서 제안한 방식으로, 랭커가 제공한 점수에 (1 - λ)의 가중치를, 실제 소비 분포와 추천 결과 간의 쿨백-라이블러 발산(Kullback–Leibler divergence, KLD)을 기반으로 λ의 페널티를 반영하여 최종 점수를 조정하는 방식입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/19.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;역시 온라인 A/B 테스트 결과, calibration 적용 후 CTR, 1인당 평균 클릭 수, 체류 시간 등의 정량 지표와 정성 평가 모두에서 개선이 확인되어 홈피드에 전면 적용했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/20.png" alt="" /&gt;&lt;/p&gt;

&lt;h3 id="transact"&gt;향후 고도화 방향: TransAct 모델 도입&lt;/h3&gt;

&lt;p&gt;앞서 소개한 개선 외에도, 사용자 세분화와 장단기 관심사 반영을 위한 추가 고도화 계획을 수립하고 있습니다. 이를 위해 Pinterest에서 2023년에 발표한 TransAct 모델 도입을 준비 중입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/21.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;TransAct는 사용자 시계열 행동을 학습하는 모델로, 장기 이력은 PinnerFormer, 단기 이력은 TransAct로 각각 학습하여 두 결과를 결합한 임베딩을 랭커에 입력합니다. 이 모델은 긍정 피드백뿐 아니라 부정 피드백도 함께 학습할 수 있으며, 사용자군을 세분화하고 다양한 관심사를 반영하는 데 효과적인 구조입니다. 해당 모델을 적용함으로써, 사용자별 관심사에 정밀하게 대응하고, 더욱 만족도 높은 피드 추천이 가능할 것으로 기대하고 있습니다.&lt;/p&gt;

&lt;h2 id="3"&gt;3. 사용자 맞춤형 첫 번째 콘텐츠 노출하기&lt;/h2&gt;

&lt;h3 id=""&gt;홈피드 첫 번째 콘텐츠의 중요성&lt;/h3&gt;

&lt;p&gt;네이버 앱의 다양한 서비스 사이에서 홈피드가 사용자의 이목을 끌게 만드는 첫 번째 콘텐츠(Rank1 콘텐츠)를 잘 선정하는 것은 매우 중요합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;앱 진입 사용자는 모두 홈피드 첫 번째 콘텐츠를 봅니다.&lt;/li&gt;
&lt;li&gt;홈피드에서 발생하는 클릭 중 약 23%가 첫 번째 콘텐츠에서 발생합니다.&lt;/li&gt;
&lt;li&gt;사용자가 홈피드 첫 번째 콘텐츠를 클릭한 경우, 두 번째 이상의 하단 영역에서 클릭률이 45% 가량 더 높아집니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;심지어 앱 메인에서 진행했던 홈피드 노출 방식 변경 A/B 테스트에서, 홈피드 첫 번째 콘텐츠가 약간 더 위에 위치하는 차이만으로도 사용자 수와 클릭 수가 40% 가량 상승하고 체류 시간도 10% 상승하는 결과가 있기도 했습니다.&lt;/p&gt;

&lt;h3 id="rank1"&gt;행동 및 관심사 기반의 Rank1 리트리버&lt;/h3&gt;

&lt;p&gt;이렇게 중요한 Rank1 영역을 고도화하기 위해, 사용자의 행동 및 관심사를 기반으로 콘텐츠를 추천하는 모델을 Rank1 리트리버에 적용했습니다.&lt;/p&gt;

&lt;p&gt;사용자 행동 기반의 리트리버로는 사용자의 최근 검색어와 유사한 콘텐츠를 Rank1에 추천하는 After Search와 최근에 클릭한 것과 유사한 콘텐츠를 추천하는 Click2Click이 있습니다.&lt;/p&gt;

&lt;p&gt;After Search는 컨텍스트가 적은 사용자에게 효과적이었습니다. 컨텍스트가 적은 사용자는 홈피드에 대한 인식이 낮은 경우가 많고, 그렇기 때문에 사용자의 현재 관심사인 검색 결과로 Rank1 추천을 했을 때 긍정적인 반응을 보이는 경향이 있었습니다.&lt;/p&gt;

&lt;p&gt;반대로, 최근 클릭과 유사한 콘텐츠를 추천하는 Click2Click은 컨텍스트가 충분한 사용자에게 효과적이었습니다. 이 사용자군은 홈피드를 긍적적으로 인식하고 있으며 선호도를 파악할 수 있다는 이점이 있습니다. 이 경우 최근 클릭한 콘텐츠와 유사한 콘텐츠를 Rank1에 추천했을 때 좋은 반응을 보여주곤 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/22.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;사용자 관심사 기반의 리트리버로는 밴딧(bandit) 리트리버와 MDE 랭커가 있습니다.&lt;/p&gt;

&lt;p&gt;밴딧 리트리버에는 멀티암드 밴딧(multi-armed bandit) 중 일정 확률에 의해 랜덤하게 선택하는 엡실론-그리디(Epsilon-Greedy) 알고리즘을 사용했습니다.&lt;/p&gt;

&lt;p&gt;행동(arm)은 컨텍스트가 충분한 사용자에 대해서 '자동차&gt;차종'과 같은 카테고리를 선택해 카테고리와 연관된 문서를 첫 번째에 추천합니다. 최근 클릭의 가중치를 높여서 최근 클릭한 카테고리가 선택될 확률이 높아지게 모델링했고, 엡실론-그리디 알고리즘을 적용했기 때문에 일정 확률로 선택된 카테고리가 변화해 사용자가 탐색을 할 수 있도록 했습니다.&lt;/p&gt;

&lt;p&gt;카테고리는 500개 이상의 선택지가 존재하기 때문에 어떤 행동이 최적인지 결정하기까지는 많은 비용이 듭니다. 따라서 컨텍스트가 적은 사용자에게는 블로그, 카페 등의 서비스로 행동을 변경하여, 적은 비용으로 최적의 결과를 제공하도록 모델링했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/23.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;MDE 랭커는 여러 컨텍스트를 함께 사용해 사용자가 만족할 만한 콘텐츠를 추천합니다.&lt;/p&gt;

&lt;p&gt;위 4개의 리트리버에 A/B 테스트를 진행하며 적합한 행동, 사용자군에 적용하여 휴리스틱하게 규칙을 만들었습니다. 하지만 사용자의 입장에서 봤을 때, '언제까지 관심이 유지될까?', '어느 정도의 비율로 언제 추천해야 할까?', '예외 사용자 혹은 상황도 있지 않을까?' 하는 고민이 생겼습니다.&lt;/p&gt;

&lt;p&gt;휴리스틱한 로직으로는 사용자의 특성을 모두 반영하는 데 한계가 있다는 생각으로, 휴리스틱한 규칙 기반이 아니라 사용자의 행동 패턴과 컨텍스트를 잘 모델링해서 Rank1 리트리버를 선정하는 모델을 만들어보기로 했습니다.&lt;/p&gt;

&lt;h3 id="rank1"&gt;사용자 맞춤형 Rank1 콘텐츠 선정&lt;/h3&gt;

&lt;p&gt;리트리버 밴딧(retriever bandit)은 사용자 특성(user feature) 등을 입력으로 받고, 앞에서 설명한 4개의 Rank1 리트리버 중 현재 사용자에게 맞는 리트리버를 선택합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/24.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;앞에서 고민한 지점을 사용자 행동 패턴 특성으로 모델링했습니다. N시간 이내 검색/클릭 횟수, 경과 시간, 클릭한 콘텐츠 등의 사용자 행동 패턴을 반영하고, 사용자의 클릭 빈도, 세대, 성별, 구독, 선호도 등의 사용자 컨텍스트도 반영되게 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/25.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;리트리버 밴딧 모델로는 컨텍스트 밴딧(contextual bandit)을 사용했고, 컨텍스트 기반으로 가장 높은 보상을 줄 행동을 선택하는 LinUCB(linear upper confidence bound)를 적용했습니다. 행동은 앞에서 설명한 4개의 Rank1 리트리버 중 하나를 선택하는 것으로, 사용자의 행동과 컨텍스트를 특성화하고 클릭 여부를 보상으로 사용했습니다.&lt;/p&gt;

&lt;p&gt;여기에서 콘텐츠를 직접 선택하지 않고 Rank1 리트리버를 선택하도록 모델링한 것은 다른 서비스 영역의 실험 결과를 참고한 것입니다. Rank1 영역에서는 행동으로 아이템을 선택하는 경우 효과가 좋지 않다는 것을 확인한 사례가 있어, 행동을 줄여 사용자의 행동 및 관심사 기반으로 모델링한 Rank1 리트리버를 선택하도록 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/26.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;Rank1에서 리트리버 밴딧 모델을 적용한 결과를 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;컨텍스트가 적은 light 사용자&lt;/strong&gt;의 경우에는 즉각적인 반응을 활용해 After Search 등이 주요 리트리버로 작용했고, 결과적으로 신규 사용자를 홈피드로 끌어들여 Rank1 CTR이 증가하는 효과를 얻을 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;컨텍스트가 적당한 medium 사용자&lt;/strong&gt;의 경우에는 단기간 컨텍스트를 잘 활용해 카테고리 밴딧(Category bandit) 등이 주요하게 사용되었고, 전체 클릭 수가 증가하는 등의 홈피드 사용성이 높아지는 결과를 얻었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;컨텍스트가 충분한 heavy 사용자&lt;/strong&gt;의 경우에는 기존 컨텍스트를 잘 유지하고 사용하며 Click2Click 등이 주요 리트리버로 동작해 노출 문서 수가 증가하는 등 다양한 콘텐츠를 접할 수 있는 추천을 제공하게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="/content/images/2025/06/27.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;첫 번째 콘텐츠는 서비스의 첫 이미지인 만큼 앞으로도 눈길이 가는, 만족할 수 있는 추천을 제공할 수 있도록 고도화해 나아가겠습니다.&lt;/p&gt;

&lt;h2 id=""&gt;마무리&lt;/h2&gt;

&lt;p&gt;지금까지 추천 피드 도입을 위해 고군분투한 팀의 노력을 설명드렸습니다.&lt;/p&gt;

&lt;p&gt;저희가 공유드린 내용 이외에도 여러 고도화 방안을 고민 중인데, 사용자 모델링 고도화를 위해 사용자가 트렌드 파악을 위해서 왔는지, 혹은 정보 획득을 위해서 왔는지, 혹은 관심사와 관련한 콘텐츠를 보기 위해서 왔는지 등 어떤 목적을 가지고 진입했는지 파악하여 알맞은 추천을 제공하고자 하는 방향성이 있습니다. 또한, 랭킹 개선을 위해서 TransAct 모델 도입 등도 실험 중이고, 사용자 맞춤형 Rank1 콘텐츠를 제공하기 위해서도 신규 Rank1 리트리버 모델 추가를 고민하고 있고 리트리버 밴딧에 신규 컨텍스트를 추가하는 등 여러 시도를 계속하고 있습니다.&lt;/p&gt;

&lt;p&gt;앞으로도 네이버의 여러 콘텐츠를 즐길 수 있는 홈피드를 만들 수 있도록 노력하겠습니다.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>늘어가는 조회트래픽 Elasticsearch로 분산시키기</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/3675627" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/3675627</id>
    <updated>2025-06-26T16:56:04Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/79065128?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;점점 늘어가던 플레이스 조회트래픽을 메인DB로부터 Elasticsearch(Opensearch)로 분산한 경험을 공유합니다. &lt;br/&gt;
(#Elasticsearch #Opensearch #트래픽 분산 #CQRS #slow query #feature toggle #feature flag #자동 fallback)&lt;/p&gt;

&lt;h4 id=""&gt;강의 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;트래픽 분산 및 Elasticsearch(Opensearch)에 관심이 있으신 분들&lt;/li&gt;
&lt;li&gt;난이도 : 하~중하 (트래픽 분산경험 / ES 운용경험이 없으신 주니어 개발자분들도 이해하시기 좋은 정도)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;조회 DB 도입 배경
&lt;ul&gt;&lt;li&gt;기존 리뷰조회 flow&lt;/li&gt;
&lt;li&gt;호출량이 점점 늘어가던 플랫폼, 증가하는 조회필터 / 정렬조건 &lt;/li&gt;
&lt;li&gt;DB 인덱스 추가의 한계&lt;/li&gt;
&lt;li&gt;조회용 DB를 도입한다면?&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Elasticsearch를 조회DB로 선택한 이유
&lt;ul&gt;&lt;li&gt;조회용 DB로 도입하기 위한 조건들 &lt;/li&gt;
&lt;li&gt;조회용 DB 후보들, ES 선택 이유&lt;/li&gt;
&lt;li&gt;ES 개념정리 - 역인덱스 구조, 실제 예시, 도입 시 고려해야 할 점, 사내 운영지원, 장단점 정리&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;조회DB 도입과정 및 결과
&lt;ul&gt;&lt;li&gt;ES 필드매핑&lt;/li&gt;
&lt;li&gt;DB와의 데이터 동기화, 리뷰 작성 및 조회 flow&lt;/li&gt;
&lt;li&gt;CQRS 측면&lt;/li&gt;
&lt;li&gt;점진적 도입 w/ feature toggle, 자동 fallback 시스템&lt;/li&gt;
&lt;li&gt;ES 도입결과 및 운용현황&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ES 운영 tips 및 Opensearch로의 전환
&lt;ul&gt;&lt;li&gt;매핑 tip: keyword vs text, object vs nested, _id의 별도 매핑&lt;/li&gt;
&lt;li&gt;샤드 tip: 권장 샤드 크기 및 replica 수, _routing 활용&lt;/li&gt;
&lt;li&gt;Opensearch 소개 및 ES와의 성능 비교
&lt;br/&gt;&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY 2025(5월)의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Paimon 겟또다제 ! (w/ ADVoost Shopping)</title>
    <link rel="alternate" href="https://d2.naver.com/helloworld/4678393" />
    <category term="hello world" />
    <id>https://d2.naver.com/helloworld/4678393</id>
    <updated>2025-06-26T10:58:02Z</updated>
    <content type="html">&lt;p&gt;네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY 2025(5월)에서 발표되었던 세션을 공개합니다.&lt;br/&gt; &lt;/p&gt;

&lt;div style="position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;"&gt;

&lt;iframe width="800" height="450" src="https://tv.naver.com/embed/78942484?autoPlay=true" frameborder="0" allowfullscreen="" style="position: absolute; position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;

&lt;/div&gt;  

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=""&gt;발표 내용&lt;/h4&gt;

&lt;p&gt;ADVoost Shopping에서 실시간 유효 광고 선정을 위해 Apache Flink와 Paimon을 활용한 architecture에 대해 소개합니다. Apache Paimon의 주요 기능과 다양한 옵션들에 대해 소개합니다.&lt;/p&gt;

&lt;h4 id=""&gt;강의 대상&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;실시간 처리를 위해 고민하고 있는 데이터 엔지니어&lt;/li&gt;
&lt;li&gt;Paimon, Iceberg와 같은 lakehouse format을 운영하거나 도입하려는 데이터 엔지니어&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;목차&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Episode 1: ADVoost Shopping에서 실시간 유효 광고 선정을 처리하는 법&lt;br/&gt;
&lt;ul&gt;&lt;li&gt;Apache Paimon을 활용한 실시간 유효 광고 선정 Architecture&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;실시간 유효 광고 선정에서 Apache Flink + Paimon을 도입한 이유&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Apache Paimon 소개&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Episode 2: Apache Paimon Deep Dive&lt;br/&gt;
&lt;ul&gt;&lt;li&gt;Apache Paimon 주요 기능&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Paimon vs Iceberg&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;알아두면 쓸모있는 Paimon options&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Episode 3: Lessons Learned
&lt;br/&gt;&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h5 id="naverengineeringdaybr"&gt;&lt;strong&gt;◎ NAVER ENGINEERING DAY란?&lt;/strong&gt;&lt;br/&gt;&lt;/h5&gt;
  
  &lt;p&gt;NAVER에서는 사내 개발 경험과 기술 트렌드를 교류를 할 수 있는 프로그램이 많이 있습니다. 그중 매회 평균 70개 이상의 발표가 이루어지는 NAVER ENGINEERING DAY를 빼놓을 수 없는데요. &lt;br /&gt;
  2016년부터 시작된 ENGINEERING DAY는 실무에서의 기술 개발 경험과 새로운 기술과 플랫폼 도입 시 유용하게 활용될 수 있는 팁 등을 공유하며 서로 배우고 성장하는 네이버의 대표적인 사내 개발자 행사입니다. &lt;br /&gt;
  올해 진행된 NAVER ENGINEERING DAY 2025(5월)의 일부 세션을 공개합니다.&lt;/p&gt;
&lt;/blockquote&gt;</content>
  </entry>
</feed>
